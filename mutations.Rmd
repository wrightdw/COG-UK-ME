---
title:  "COG-UK Mutations"
output: html_notebook
params: 
  latest:           TRUE # TRUE to copy latest files on CLIMB to working directory, overrides dataset_date with today()
  dataset_date:     "" # Used if latest == FALSE. if empty, defaults to today's date, otherwise enter date string
  spike_csv:        "spike_escape_info.csv"
  spike_extra_csv:  "spike_escape_extra.csv"
  tcell_csv:        "tcell_long.csv"
  deletions_tsv:    "cog.deletions.tsv"
  predictions_tsv:  "Prediction_from_Morten.txt"
  spike_fasta:      "sequence.fasta"
  vui_voc_csv:      "VUI and VOC.csv"
  remdesivir_dir:   "Remdesivir Mutants" 
  nirmatrelvir_dir: "Nirmatrelvir Mutants" 
  isaric_csv:       "Isaric_list.csv"
  insertions_tsv:   "cog.insertions.tsv"
  functional_csv:   "tcell_functional_mutations.csv"
  deletions_mapping_csv: "deletion_mapping.csv"
  insertions_mapping_csv: "insertion_mapping.csv"
---
# Setup
```{r setup}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(magrittr))
library(wesanderson)
library(RColorBrewer)
suppressPackageStartupMessages(library(lubridate))
library(fuzzyjoin)
library(htmltools)
suppressPackageStartupMessages(library(jsonlite))
# also require seqinr - loaded later on to avoid name clash of dplyr count function
library(UpSetR)

# Helper function
# Construct a regular expression for replacement of the sublineages of a lineage using gsub
sublineage_regex_gsub <- function(lineage){
  str_replace_all(lineage, "\\.", "\\\\\\.") %>% 
    paste0("^", ., "\\..*")
}
```
```{r climb}
Sys.setenv(TZ="Europe/London")

if(params$latest){ # copy today's files to working directory on CLIMB, stop if process run previously or today's files not available yet
  
  # check files exist
  params$dataset_date <- today()
  latest_dir <- "/cephfs/covid/bham/results/msa/latest"
  consortium_csv <- str_c("cog_global_", params$dataset_date, "_consortium.csv")
  consortium_today_msa <- file.path(latest_dir, "metadata", consortium_csv)
  
  if(!file.exists(consortium_csv) && # file not already copied
     file.exists(consortium_today_msa)){ # MSA file exists
    
    # copy consortium and deletions to working directory
    message("Copying latest consortium and deletions files")
    file.copy(consortium_today_msa, getwd())
    
    # deletions and insertions files not named by date so overwrite previous
    file.copy(file.path(latest_dir, "cog", params$deletions_tsv), getwd(), overwrite = TRUE) 
    file.copy(file.path(latest_dir, "cog", params$insertions_tsv), getwd(), overwrite = TRUE) 
  } else {
    stop(str_c(consortium_today_msa, " does not exist or already copied")) # terminate script
  }  
  
} else {
  if(params$dataset_date == ""){
    params$dataset_date <- today()
  } else {
    params$dataset_date %<>% as.Date
  }
  
  consortium_csv <- str_c("cog_global_", params$dataset_date, "_consortium.csv")
}

dir.create(str_c("COG-UK/", params$dataset_date))
```

# Consortium
## Read
```{r consortium_read, include=FALSE}
message("Reading ", consortium_csv)
consortium_uk <- 
  read_csv((consortium_csv), col_types = cols(.default = col_character())) %>% 
  filter(country == "UK" & !is.na(adm1) & adm1 %in% (c("England", "Scotland", "Wales", "Northern_Ireland"))) %>% # exclude Crown dependencies and British Overseas Territories
  select(-gisaid_id, -submission_org_code, -root_sample_id, -(adm2:travel_history), NUTS1,
         -lineages_version, -country,
         -received_date, -collection_date, -published_date, -starts_with("scorpio"),
         -lineage_conflict, -lineage_ambiguity_score, -sequencing_org_code, -submission_user
         ) %>% # remove unused columns
  relocate(NUTS1,.after = adm1) %>% 
  type_convert 

consortium_uk
```
```{r consortium_clean, include=FALSE}
# Data cleaning:
# Exclude duplicate Delta sequences with incorrect dates in April 2020
# NUTS1 cleanup - correct NUTS1 missing or incorrect values
# Correct to 2nd December
  # England/PHEP-YYNQW43/2021	2021-11-02	97	2021-10-31	B.1.1.529
  # to sample_date 2021-12-02 epi_week 101
dodgy_delta <- 
  consortium_uk %>% 
  filter(lineage == "B.1.617.2" & epi_week %in% c(16, 17))

# Exclude Omicron sequences with erroneous dates before November 2021
dodgy_omicron <- 
  consortium_uk %>% 
  filter( (lineage == "BA.1" | str_starts(lineage, fixed("BA.1."))) & sample_date < "2021-11-20")

consortium_uk %<>% 
  anti_join(dodgy_delta) %>% 
  anti_join(dodgy_omicron) %>% 
  mutate( 
    NUTS1 = case_when(
      adm1 == "Scotland" ~ "Scotland",
      adm1 == "Wales" ~ "Wales",
      adm1 == "Northern_Ireland" ~ "Northern_Ireland",
      TRUE ~ NUTS1
    )
  ) %>%
  rows_update(tibble(sequence_name = "England/PHEP-YYNQW43/2021", sample_date = as.Date("2021-12-02"), epi_week = 101))
  
# Epidemic week / Sunday date conversion
epi_lookup <-
  tibble(
    epi_date = seq(from = ymd("2020-01-26"), to = consortium_uk %$% max(sample_date), by = "week"),
    epi_week = seq(consortium_uk %$% min(epi_week), consortium_uk %$% max(epi_week))
  ) 

epi_levels <- min(consortium_uk$epi_week):max(consortium_uk$epi_week) %>% as.character

consortium_uk %<>% 
  inner_join(epi_lookup) %>% 
  relocate(epi_date, .after = epi_week) %>% 
  mutate(across(c(epi_week, adm1, NUTS1), as_factor)) %>%
  mutate(epi_week = fct_expand(epi_week, epi_levels) %>% fct_inseq) # expand factor levels to include any missing weeks

consortium_uk
```
## 28 days
```{r consortium_constants, include=FALSE}
sample_date_28 <- max(consortium_uk$sample_date) - days(27) # calculate 28 day period up to and including latest sample date
message("28 days date: ", sample_date_28)
```
## Alias
```{r consortium_alias, include=FALSE}
message("Looking up PANGO designation lineage alias key on GitHub")
# reconstruct lineage full names from alias JSON
alias_key <- fromJSON("https://raw.githubusercontent.com/cov-lineages/pango-designation/master/pango_designation/alias_key.json")

alias_key %<>% 
  keep(~ length(.x) == 1) %>% # drop recombinants
  purrr::discard(~ .x == "") # drop top level lineages

# copy lineage column
consortium_uk %<>% 
  mutate(lineage_full = lineage, .after = lineage)

# overwrite aliases with full lineage names
for (i in 1:length(alias_key)) {
  consortium_uk <<- 
    consortium_uk %>% 
    mutate(lineage_full = str_replace(lineage_full, str_c("^", names(alias_key)[i], "(?=\\.)"), str_c(alias_key[[i]])))
}

consortium_uk
```
## Sample
```{r consortium_sample, eval=FALSE, include=TRUE}
# Sample of full dataset for development purposes
consortium_uk %<>% slice_sample(n = 100000)
consortium_uk
```

## Write
```{r consortium_write}
mutations_uk <- 
  consortium_uk %>% 
  select(sequence_name, cog_id, sample_date, epi_week, epi_date, lineage, lineage_full, adm1, NUTS1, mutations) %>% 
  distinct # get rid of identical variant calls

message("Writing consortium_uk.rds")
consortium_uk %<>% 
  select(-mutations) %>% 
  distinct %T>% # remove duplicates
  write_rds(str_c("COG-UK/", params$dataset_date, "/consortium_uk.rds"))

consortium_uk
```
# Mutations
```{r mutations_consortium}
mutations_uk %<>%    
  separate_rows(mutations, sep = '\\|') %>% 
  separate(mutations, into = c("gene", "variant"), sep = ':') %>% 
  drop_na(-NUTS1) %>% # don't drop missing geographical data
  filter(gene != "synSNP") %>%
  mutate(position = parse_number(variant)) %>% 
  mutate(across(c(gene, position, variant), as_factor)) %>% 
  mutate(gene = fct_recode(gene, ORF1ab = "orf1ab")) %T>% 
  write_rds(str_c("COG-UK/", params$dataset_date, "/mutations_uk.rds"))

mutations_s_uk <- 
  mutations_uk %>% 
  filter(gene == "S") %>% 
  select(-gene) %>% 
  mutate(across(c(variant, position), fct_drop)) %>% # drop non-spike mutations from factor levels
  write_rds(str_c("COG-UK/", params$dataset_date, "/mutations_s_uk.rds"))

mutations_uk
mutations_s_uk
```


# Deletions
```{r deletions}
deletions <- 
  read_tsv(params$deletions_tsv) %>% 
  separate_rows(samples, sep = '\\|')

deletions %<>% semi_join(consortium_uk, by = c("samples" = "sequence_name")) # remove unfiltered sequence IDs from deletions

message("Writing deletions.rds")
deletions %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/deletions.rds"))
```
```{r deletions_mapping}
deletions_mapping <- 
  read_csv(params$deletions_mapping_csv, 
           col_types = cols(del_start = col_integer(),
                            del_end = col_integer(),
                            gene = readr::col_factor(NULL))) %>% # avoid name clash with scales package
  inner_join(deletions) %>% 
  select(-ref_start, -length)

deletions_mapping <- 
  consortium_uk %>% 
  select(sequence_name, cog_id, sample_date, epi_week, epi_date, lineage, lineage_full, adm1, NUTS1) %>% 
  inner_join(deletions_mapping,  by = c("sequence_name" = "samples")) %>% 
  mutate(del_subst_position = parse_number(del_subst)) 

deletions_mapping %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/deletions_mapping.rds"))
```
## Complete
```{r deletions_complete}
deletions_complete <- 
  deletions_mapping %>% 
  rowwise() %>% 
  mutate(del_start_end = 
           seq(min(c(del_start, del_end, del_subst_position), na.rm = TRUE), 
                             max(c(del_start, del_end, del_subst_position), na.rm = TRUE)) %>% 
           paste(collapse = "|"), .keep = "unused"
         ) %>% 
  separate_rows(del_start_end, sep = '\\|') %>% 
  rename(position = del_start_end, variant = del_id) %>%   
  mutate(across(c(position, variant), as_factor)) %>% 
  select(-del_subst)

deletions_complete
```

## Mutation / REF counts
```{r mutations_refs}
mutations_deletions_uk <- bind_rows(mutations_uk, deletions_complete)

#### UK ### 
genes_positions <- 
  mutations_deletions_uk %>% 
  distinct(gene, position) # gene / position combinations actually found in mutations

sequences_by_week <- 
  consortium_uk %>% 
  dplyr::count(epi_week, epi_date, name = "n_sequences")

positions_by_week <- 
  mutations_deletions_uk %>%
  dplyr::count(epi_week, epi_date, gene, position, .drop = FALSE, name = "n_variant_sequences") # count all possible epi_week/gene/position combinations 

reference_counts <- 
  positions_by_week %>%
  inner_join(genes_positions) %>% # remove gene / position combinations not found in mutations
  inner_join(sequences_by_week) %>% 
  mutate(n = n_sequences - n_variant_sequences, variant = "WT", .keep = "unused") %>% # calculate reference / other
  filter(n > 0) %>%  # remove zero WT entries (where all sequences are variants for an epi_week / position combo)
  mutate(adm1 = "UK")

mutation_counts <- 
  mutations_deletions_uk %>%
  dplyr::count(epi_week, epi_date, gene, position, variant) %>% 
  mutate(adm1 = "UK")

#### Nations ####
sequences_by_week_nations <-
  consortium_uk %>%
  dplyr::count(epi_week, epi_date, adm1, name = "n_sequences")

positions_by_week_nations <-
  mutations_deletions_uk %>%
  dplyr::count(epi_week, epi_date, gene, position, adm1, .drop = FALSE, name = "n_variant_sequences") # count all possible epi_week/gene/position/nation combinations

reference_counts_nations <- 
  positions_by_week_nations %>%
  inner_join(genes_positions) %>% # remove gene / position combinations not found in mutations
  inner_join(sequences_by_week_nations) %>% 
  mutate(n = n_sequences - n_variant_sequences, variant = "WT", .keep = "unused") %>% # calculate reference / other
  filter(n > 0) # remove zero WT entries (where all sequences are variants for an epi_week / position combo)

mutation_counts_nations <- 
  mutations_deletions_uk %>%
  dplyr::count(epi_week, epi_date, gene, position, variant, adm1)

# TODO calculate UK counts by summing the nation counts
mutation_reference_counts <- 
  bind_rows(mutation_counts, reference_counts, mutation_counts_nations, reference_counts_nations) %>% 
  mutate(across(variant, as_factor)) %T>% 
  write_rds(str_c("COG-UK/", params$dataset_date, "/mutation_reference_counts.rds"))

mutation_reference_counts
```


```{r database_deletions}
deletions_uk <-
  deletions_mapping %>% 
  group_by(gene, del_start, del_end, del_id) %>% 
  summarise(UK = n(), earliest = min(sample_date), .groups = "drop")

deletions_nations <- 
  deletions_mapping %>% 
  dplyr::count(gene, del_start, del_end, del_id, adm1) %>% 
  pivot_wider(names_from = adm1, values_from = n)

deletions_uk_28 <- 
  deletions_mapping %>% 
  filter(sample_date >= sample_date_28) %>% 
  dplyr::count(gene, del_start, del_end, del_id, name = "UK_28")

deletions_nations_28 <-
  deletions_mapping %>% 
    filter(sample_date >= sample_date_28) %>% 
    dplyr::count(gene, del_start, del_end, del_id, adm1) %>% 
    pivot_wider(names_from = adm1, values_from = n) %>% 
    rename_with(~paste0(., "_28"), .cols = c(England, Northern_Ireland, Scotland, Wales))

database_deletions <- 
  deletions_uk %>% 
  inner_join(deletions_nations) %>% 
  left_join(deletions_uk_28) %>% 
  left_join(deletions_nations_28) %>% 
  mutate(across(where(is.numeric), ~replace_na(.x, 0L)))

database_deletions %T>% 
  write_rds(str_c("COG-UK/", params$dataset_date, "/database_deletions.rds"))
```

# Insertions
```{r}
insertions <- 
  read_tsv(params$insertions_tsv) %>% 
  separate_rows(samples, sep = '\\|')

insertions %<>% semi_join(consortium_uk, by = c("samples" = "sequence_name")) # remove unfiltered sequence IDs from deletions

message("Writing insertions.rds")
insertions %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/insertions.rds"))

```
### Mapping
```{r insertions_mapping}
insertions_mapping <- 
  read_csv(params$insertions_mapping_csv) %>%
  mutate(across(c(gene), as_factor)) %>% 
  inner_join(insertions)

insertions_mapping <- 
  consortium_uk %>% 
  select(sequence_name, cog_id, sample_date, epi_week, epi_date, lineage, lineage_full, adm1, NUTS1) %>% 
  inner_join(insertions_mapping,  by = c("sequence_name" = "samples")) #%>% 
  # rename(variant = insertion_id) %>% 
  # select(-c(insertion, ref_start))  

insertions_mapping %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/insertions_mapping.rds"))

```
# Mutations + indels
```{r mutations_indels}
# for mutations/indels downloads
mutations_indels_uk_28 <-
  mutations_uk %>% 
  bind_rows(deletions_mapping %>% rename(variant = del_id)) %>% 
  bind_rows(insertions_mapping %>% rename(variant = insertion_id)) %>% 
  filter(sample_date >= sample_date_28) %T>% 
  write_rds(str_c("COG-UK/", params$dataset_date, "/mutations_indels_uk_28.rds"))
```

```{r database_insertions}
insertions_uk <-
  insertions_mapping %>% 
  group_by(gene, ref_start, insertion, insertion_id) %>% 
  summarise(UK = n(), earliest = min(sample_date), .groups = "drop")

insertions_nations <- 
  insertions_mapping %>% 
  dplyr::count(gene, ref_start, insertion, insertion_id, adm1) %>% 
  pivot_wider(names_from = adm1, values_from = n)

insertions_uk_28 <- 
  insertions_mapping %>% 
  filter(sample_date >= sample_date_28) %>% 
  dplyr::count(gene, ref_start, insertion, insertion_id, name = "UK_28")

insertions_nations_28 <-
  insertions_mapping %>% 
    filter(sample_date >= sample_date_28) %>% 
    dplyr::count(gene, ref_start, insertion, insertion_id, adm1) %>% 
    pivot_wider(names_from = adm1, values_from = n) %>% 
    rename_with(~paste0(., "_28"), .cols = c(England, Northern_Ireland, Scotland, Wales))

database_insertions <- 
  insertions_uk %>% 
  inner_join(insertions_nations) %>% 
  left_join(insertions_uk_28) %>% 
  left_join(insertions_nations_28) %>% 
  mutate(across(where(is.numeric), ~replace_na(.x, 0L)))

database_insertions %T>% 
  write_rds(str_c("COG-UK/", params$dataset_date, "/database_insertions.rds"))
```
# Database
```{r database_genome}
lineage_distinct <- 
  mutations_uk %>% 
  group_by(gene, position, variant) %>% 
  summarise(n_lineages = n_distinct(lineage), .groups = "drop") 

lineages <- 
  mutations_uk %>% 
  distinct(gene, position, variant, lineage) %>% 
  group_by(gene, position, variant) %>% 
  arrange(gene, position, variant, lineage, .by_group = TRUE) %>% 
  summarise(lineages = toString(lineage), .groups = "drop")

## UK and nations
# All sample dates
variants_uk <-
  mutations_uk %>% 
  group_by(gene, position, variant) %>% 
  summarise(UK = n(), earliest = min(sample_date), .groups = "drop")

variants_nations <- 
  mutations_uk %>% 
  dplyr::count(gene, position, variant, adm1) %>% 
  pivot_wider(names_from = adm1, values_from = n)

# Sample dates in last 28 days
variants_uk_28 <- 
  mutations_uk %>% 
  filter(sample_date >= sample_date_28) %>% 
  dplyr::count(gene, position, variant, name = "UK_28")

variants_nations_28 <-
  mutations_uk %>% 
    filter(sample_date >= sample_date_28) %>% 
    dplyr::count(gene, position, variant, adm1) %>% 
    pivot_wider(names_from = adm1, values_from = n) %>% 
    rename_with(~paste0(., "_28"), .cols = c(England, Northern_Ireland, Scotland, Wales))

database_genome <- 
  read_csv(params$spike_csv, col_types = cols(.default = col_character())) %>%
  type_convert %>%
  mutate(across(c(mutation, position), as_factor)) %>% 
  mutate(anchor = str_c("<a href='", doi, "'target='_blank'>", citation,"</a>"), .keep = "unused") %>% # hyperlink to citation DOI
  group_by(position, mutation) %>% 
  summarise(escape = escape %>% unique %>% sort %>% toString, 
            anchor = anchor %>% unique %>% str_c(collapse = "<br>"), # line breaks between hyperlinks
            mab = mab %>% any,
            plasma = plasma %>% any,
            vaccine_sera = vaccine_sera %>% any,
            support = support %>% unique %>% toString,
            domain = domain %>% unique %>% toString, 
            .groups = "drop") %>% 
  mutate(gene = factor("S"), .before = position)

join_cols <- c("mutation" = "variant", "position" = "position", "gene" = "gene")

database_genome %<>% 
  full_join(lineage_distinct, by = join_cols) %>% 
  full_join(lineages, by = join_cols) %>% 
  full_join(variants_uk,  by = join_cols) %>% 
  full_join(variants_nations,  by = join_cols) %>% 
  full_join(variants_uk_28,  by = join_cols) %>% 
  full_join(variants_nations_28,  by = join_cols) 

database_genome %<>%
  rename(
    `# Global Lineages associated with` = n_lineages, 
    `Global Lineages` = lineages, 
    
    `numSeqs UK` = UK,
    `numSeqs Eng` = England,
    `numSeqs NI` = Northern_Ireland,
    `numSeqs Scotland` = Scotland,
    `numSeqs Wales` = Wales,

    `numSeqs UK 28 days` = UK_28,
    `numSeqs Eng 28 days` = England_28,
    `numSeqs Scotland 28 days` = Scotland_28,
    `numSeqs Wales 28 days` = Wales_28, 
    `numSeqs NI 28 days` = Northern_Ireland_28) %>% 
  mutate(across(starts_with( c("numSeqs", "#") ), ~replace_na(.x, 0L))) %>% 
  mutate(across(c(gene, position, mutation), as.character)) %>% 
  mutate(across(position, as.integer)) %>% 
  arrange(gene, position, mutation) %>% 
  mutate(across(c(support, domain, gene, mutation), as_factor)) %>% 
  mutate(support = fct_relevel(support, "lower", "medium", "high"))

database_genome %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/database_genome.rds"))
```

# Therapeutics
```{r therapeutics}
# ORF1ab positions https://www.ncbi.nlm.nih.gov/protein/1796318597
# see mat_peptide annotation
# nsp12 4393..5324
# Mpro 3264..3569

therapeutics_data <- function(data_dir, orf1ab_pos){
  fs::dir_ls(data_dir, glob = "*.csv") %>% # get file names
    map_dfr(read_csv, col_types = cols(`quantification (fold)` = col_character())) %>% 
    rename(gene = ORF) %>%
    rename_with(~str_c(.x, "_protein"), c(position, residue, mutation)) %>% 
    mutate(gene = recode(gene, "orf1b" = "orf1ab", "ORF1a" = "orf1ab"),
           position = position_protein + orf1ab_pos - 1, .after = gene) %>% 
    mutate(variant = str_c(str_sub(mutation_protein, 1, 1), 
                           position, 
                           str_sub(mutation_protein, -1, -1) ), 
           .after = position )
}

thera_data <- bind_rows(therapeutics_data(params$remdesivir_dir, 4393), # nsp12 
                        therapeutics_data(params$nirmatrelvir_dir, 3264)) # Mpro
mutations_rem_uk <- 
  mutations_uk %>% 
  filter(gene == "orf1ab") %>% 
  mutate(across(position, as.character)) %>%
  mutate(across(position, as.numeric)) %>%
  mutate(across(c(variant), fct_drop)) %>% 
  semi_join(thera_data)

variants_rem_uk <-
  mutations_rem_uk %>%
  group_by(position, variant) %>%
  summarise(UK = n(), earliest = min(sample_date), .groups = "drop")

# Sample dates in last 28 days
variants_rem_uk_28 <-
  mutations_rem_uk %>%
  filter(sample_date >= sample_date_28) %>%
  dplyr::count(position, variant, name = "UK_28")

thera_data %<>%  
  mutate(anchor = str_c("<a href='https://", doi, "'target='_blank'>", citation,"</a>"), .keep = "unused") %>%   # hyperlink to citation DOI
  left_join(variants_rem_uk) %>% 
  left_join(variants_rem_uk_28) %>% 
  rename(
    `numSeqs UK` = UK,
    `numSeqs UK 28 days` = UK_28) %>% 
  mutate(across(starts_with( c("numSeqs", "#") ), ~replace_na(.x, 0L))) 

thera_data %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/therapeutics.rds"))
```

# T cell
## Epitopes
```{r tcell}
tcell <- read_csv(params$tcell_csv,
                  col_types = cols(
                          `Start position` = col_integer(),
                          `End position` = col_integer(),
                          `Supporting references` = col_integer()
                  ))

predictions <- 
  read_tsv(params$predictions_tsv)

predictions %<>%
  select(
    position,
    mutation,
    Epitope,
    `Start position`,
    `End position`,
    CD4_CD8,
    HLA_prediction,
    `IC50 WT`,
    IC50_mutation,
    Fold
    ) %>%
  mutate(gene = "S", .before = 1)

tcell %<>%
  mutate(HLA_prediction = str_replace(HLA, "\\*", "")) %>%
  mutate(HLA_prediction = str_replace(HLA_prediction, "^DRB1", "DRB1_")) # %>%

nested_html <- function(summary_var){
  summary_var %>%
    unique %>%
    map(function(i) div(i, class = "nested-row")) %>%
    div(class = "nested-container") %>%
    as.character()
}

container_html <- function(summary_var){
  summary_var %>%
    map(function(i) div(HTML(i), class = "cell-row")) %>%
    div(class = "cell-container") %>%
    as.character()
}

database_tcell <-
  database_genome %>%
  filter(gene == "S") %>%
  select(gene,
         position, mutation, `numSeqs UK`, `numSeqs UK 28 days`) %>%
  fuzzy_inner_join(
    tcell,
    by = c(
      "position" = "Start position",
      "position" = "End position"),
    match_fun = list(
      `>=`, `<=`))

database_tcell_predictions <-
  database_tcell %>%
  left_join(predictions) %>%
  select(-HLA_prediction) %>%
  mutate(across(c(gene, mutation, Epitope, CD4_CD8, HLA, assay), as_factor))

database_tcell_predictions

```
## Functional
```{r functional}
functional <- 
  read_csv(params$functional_csv) 

functional %<>% 
  mutate (gene = recode(ORF, 
                        "Spike" = "S", 
                        "Nucleocapsid" = "N",
                        "Membrane" = "M",
                        "Envelope" = "E"), 
          .before = 1,
          .keep = "unused") %>% 
  mutate(HLA_prediction = str_replace(HLA, "\\*", "")) %>%
  mutate(HLA_prediction = str_replace(HLA_prediction, "^DRB1", "DRB1_"))  

database_genome_functional <-
  database_genome %>%
  select(gene, position, mutation, `numSeqs UK`, `numSeqs UK 28 days`) %>% 
  inner_join(functional)

database_functional_predictions <-
  database_genome_functional %>% 
  left_join(predictions) %>% 
  select(-HLA_prediction) %>% 
  mutate(across(c(gene, mutation, Epitope, CD4_CD8, HLA, assay), as_factor))

database_functional_predictions

bind_rows(database_tcell_predictions, database_functional_predictions) %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/database_tcell_predictions.rds"))
```



### Lineages
```{r lineage_counts}
n_uk_lineages <- 
  consortium_uk %>% 
  # filter(sample_date >= sample_date_28) %>% 
  group_by(lineage) %>%
  summarise(sequences = n(), 
            D614G = sum(d614g == "G"), 
            A222V = sum(a222v == "V"), 
            N439K = sum(n439k == "K"), 
            N501Y = sum(n501y == "Y"), 
            Y453F = sum(y453f == "F"),
            DEL_69_70 = sum(del_21765_6 == "del"), 
            N439K_DEL_69_70 = sum(n439k == "K" & del_21765_6 == "del"), 
            N501Y_DEL_69_70 = sum(n501y == "Y" & del_21765_6 == "del"),
            Y453F_DEL_69_70 = sum(y453f == "F" & del_21765_6 == "del")
  )

n_uk_lineages
```


## Antigenic
### Antigenic mutations by lineage
Would you be able to prepare a file with all the antigenic mutations (filtered from Willâ€™s antigenic table) that have accumulated on the top of B.1.1.7 (so non lineage defining mutations) with numbers of sequences per week? We would like to prepare a heat map like the attached picture.

```{r antigenic_mutations, eval=FALSE, include=TRUE}
antigenic <- 
  antigenic_mutations_lineages() %T>% 
  write_rds(str_c("COG-UK/", params$dataset_date, "/antigenic_mutations_lineages.rds"))

antigenic
```
### Antigenic heatmap
```{r antigenic_heatmap, eval=FALSE, include=FALSE}
suppressPackageStartupMessages(library(ComplexHeatmap))
suppressPackageStartupMessages(library(circlize))

# horz_heat_original <- read.table("horz_heat.csv", row.names = 1, header = TRUE, sep = ",", stringsAsFactors = FALSE)

horz_heat <-
  antigenic_mutations_lineages() %>% 
  filter(lineage == "B.1.1.7" & variant != "N501Y") %>% 
  select(-lineage) %>% 
  inner_join(database_genome %>% 
               select(position, mutation, mab, plasma, vaccine_sera, support, domain) %>% 
               add_row(position = 243, mutation = "del243-244", mab = TRUE, plasma = NA, vaccine_sera = NA, support = "lower", domain = "NTD"), 
             by = c("variant" = "mutation")) %>%   
  mutate(across(where(is.logical), ~na_if(.x, FALSE))) %>%
  arrange(position, variant) %>% 
  mutate(across(domain, as_factor)) %>% 
  select(-position) %>% 
  rename(confidence = support) %>% 
  column_to_rownames("variant")

input <- data.matrix(horz_heat)

# define colour heatmap for frequency
col_fun = colorRamp2(c( 0, 0.015, 0.5, 2), c("white", "darkolivegreen1","darkolivegreen3","forestgreen"))

# annotation row
row_ha = rowAnnotation(
  Effect_mab = horz_heat$mab,
  Effect_plasma = horz_heat$plasma,
  Effect_vaccine = horz_heat$vaccine_sera,
  confidence = horz_heat$confidence,
  na_col = 'white',
  col = list(
    confidence = c(
      "lower" = "lightgoldenrod",
      "medium" = "lightgoldenrod3",
      "high" = "lightgoldenrod4"
    ),
    Effect_mab = c("TRUE" = "black"),
    Effect_plasma = c("TRUE" = "black"),
    Effect_vaccine = c("TRUE" = "black")
  ),
  annotation_legend_param = list(confidence = list (at = c(
    "high", "medium", "lower"
  )))
)

# domain
row_ha2 = rowAnnotation(domain = (horz_heat$domain),
                        col = list(
                          domain = c(
                            "FP" = "seashell2",
                            "NTD" = "navajowhite",
                            "RBD" = "pink",
                            "RBM" = "plum1",
                            "SP" = "lightblue1"
                          )
                        ))

# remove x from name of columns (epiweek)
# colnames(horz_heat) <- gsub("X","",colnames(horz_heat))

# pdf("heatmap.pdf", height = 10)
png("heatmap.png", height = 800, type = "cairo-png")
hm <- Heatmap(
  subset(input, select = -c(mab:domain)),
  name = "Percentage %",
  column_title = "Antigenic mutations in lineage B.1.1.7",
  use_raster = TRUE,
  cluster_columns = FALSE,
  cluster_rows = FALSE,
  row_order = order((horz_heat$domain)),
  row_split = (horz_heat$domain),
  column_names_rot = 0,
  row_gap = unit(2, "mm"),
  border = TRUE,
  width = ncol(input) * unit(1.8, "mm"),
  height = nrow(input) * unit(1.8, "mm"),
  col = col_fun,
  na_col = 'white',
  column_names_gp = grid::gpar(fontsize = 4),
  row_names_gp = grid::gpar(fontsize = 4),
  right_annotation = row_ha,
  left_annotation = row_ha2
)
hm
dev.off()
hm

# RBD1_class<-c(403, 405, 406, 408, 409, 414, 415, 416, 417, 420, 421, 449, 453, 455, 456, 457, 458, 459, 460, 473, 474, 475, 476, 477, 484, 486, 487, 489, 490, 492, 493, 494, 495, 496, 498, 500, 501, 502, 503, 504, 505)
# RBD2_class<-c(338, 339, 342, 343, 346, 351, 368, 371, 372, 373, 374, 403, 405, 406, 417, 436, 444, 445, 446, 447, 448, 449, 450, 452, 453, 455, 456, 470, 472, 473, 475, 478, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505)
# RBD3_class<-c(333, 334, 335, 337, 339, 340, 341, 342, 343, 344, 345, 346, 354, 356, 357, 358, 359, 360, 361, 438, 439, 440, 441, 442, 443, 446, 499, 500)
# RBD4_class<-c(369, 370, 371, 372, 374, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 390, 430, 431)
# NTD_class<-c(15, 18, 19, 22, 28, 74, 77, 80, 123, 136, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 157, 158, 164, 244, 246, 247, 248, 249, 250, 251, 252, 253, 255, 257, 258)

# horz_heat$RBD1 <- ifelse(horz_heat$position %in% RBD1_class, TRUE, NA)
# horz_heat$RBD2 <- ifelse(horz_heat$position %in% RBD2_class, TRUE, NA)
# horz_heat$RBD3 <- ifelse(horz_heat$position %in% RBD3_class, TRUE, NA)
# horz_heat$RBD4 <- ifelse(horz_heat$position %in% RBD4_class, TRUE, NA)
# horz_heat$NTD.1 <- ifelse(horz_heat$position %in% NTD_class, TRUE, NA)

# col_fun = colorRamp2(c( 0, 0.015, 0.5, 2), c("white", "darkolivegreen1","darkolivegreen3","forestgreen"))
# 
# row_ha= rowAnnotation(Effect_mab = horz_heat[,20], Effect_plasma = horz_heat [,21], Effect_vaccine= horz_heat [,22], confidence = horz_heat[,23],
#                         na_col = 'white', col= list(
#                         confidence = c("lower" = "lightgoldenrod", "medium" = "lightgoldenrod3", "high" = "lightgoldenrod4"),
#                         Effect_mab = c("TRUE" = "black"),
#                         Effect_plasma = c("TRUE" ="black"),
#                         Effect_vaccine = c("TRUE" = "black")),
#                       annotation_legend_param = list(confidence = list (at = c("high", "medium", "lower")))
#                       )
#                       
# row_ha2=rowAnnotation(domain = (horz_heat[,24]), Ab_class1 = (horz_heat[,30]),Ab_class2 = (horz_heat[,31]),Ab_class3 = (horz_heat[,32]),Ab_class4 = (horz_heat[,33]),Ab_classe5 = (horz_heat[,34]),
#                       na_col = 'white',
#                       width = ncol(horz_heat)*unit(0.8, "mm"),
#                       col=list(
#                       domain = c("FP" ="seashell2", "NTD"= "navajowhite", "RBD" = "pink", "RBM" = "plum1","SP"= "lightblue1"),
#                       Ab_class1 =c ("TRUE" = "lightgreen"),
#                       Ab_class2 =c("TRUE" = "goldenrod1"),
#                       Ab_class3 =c("TRUE" = "cornflowerblue"),
#                       Ab_class4 =c("TRUE" = "tomato"),
#                       Ab_class5 =c("TRUE" = "magenta")),
#                       show_legend = c(domain = FALSE, Ab_class1 = FALSE,Ab_class2 = FALSE,Ab_class3 = FALSE,Ab_class4 = FALSE,Ab_class5 = FALSE)
#                       )
#                       
# colnames(input)<-gsub("X","",colnames(input))
# 
# Heatmap(input[,2:18], name = "Percentage %", column_title = "Antigenic mutations on the top of B.1.1.7", use_raster = TRUE,cluster_columns = FALSE,
#         row_order = order((horz_heat[,24])),
#         row_split = (horz_heat[,24]),
#         column_names_rot=0,
#         row_gap = unit(2, "mm"),  border = TRUE,
#         width = ncol(input)*unit(1.8, "mm"),
#                height = nrow(input)*unit(1.8, "mm"),
#         col=col_fun,
#         na_col = 'white' ,
#               column_names_gp = grid::gpar(fontsize = 4),
#         row_names_gp = grid::gpar(fontsize = 4),
#         right_annotation = row_ha,
#         left_annotation = row_ha2
#         )

```
### ggseqlogo
```{r ggseqlogo}
wt <-
  mutation_reference_counts %>% 
  filter(gene == "S" & variant == "WT" & adm1 == "UK") %>%
  group_by(position) %>% 
  summarise(`numSeqs UK` = sum(n)) %>% 
  mutate(position = fct_drop(position) %>% fct_expand(1:1274 %>% as.character) %>% fct_inseq) %>% 
  complete(position) %>% 
  mutate(across(`numSeqs UK`, ~replace_na(.x, n_distinct(consortium_uk$sequence_name))))

library(seqinr) # NB seqinr also has a count function!
spike_sequence <- 
  read.fasta(params$spike_fasta, seqonly = TRUE) %>% 
  str_extract_all(boundary("character")) %>% 
  flatten_chr() %>% 
  c("*") # append stop codon

wt %<>% 
  add_column(AA = spike_sequence) %>% 
  mutate(across(position, as.character)) %>% 
  mutate(across(position, as.integer)) %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/wt.rds"))

wt %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/wt.rds"))
```


### mydata
```{r eval=FALSE, include=FALSE}
# library(tidyverse)
# library(magrittr)

mydata <- read_csv("mydata.csv") 

names <- 
  c("MA0018.2",
    "MA0031.1",
    "MA0139.1",
    "MA0158.1")

df <- names %>% 
    purrr::set_names() %>%
    map(function(i) 
      gather(mydata, "key", "value", starts_with(i)) %$% as.integer(value) %>% array(dim = c(4, length(.)/4))
    ) %>% as.list 

df
```

## VUI and VOC
### VUI and VOC defining mutations
```{r vui_voc}
vui_voc <-
  read_csv(params$vui_voc_csv) %>% 
  select(-gene, -details_gene, -non_syn) %>% 
  mutate(across(c(lineage, lineage_display), fct_inorder))

vui_voc %T>% write_rds(str_c("COG-UK/", "vui_voc.rds"))
```

### VUI and VOC plot
```{r lineages_plot, eval=FALSE, include=TRUE}
lineages_weeks_nations <-
  consortium_uk %>% dplyr::count(lineage, epi_week, adm1)

lineages_weeks_uk <-
  lineages_weeks_nations %>% 
  group_by(lineage, epi_week) %>% 
  summarise(across(n, sum), .groups = "drop") %>% 
  mutate(adm1 = "UK", .after = epi_week) %>% 
  bind_rows(lineages_weeks_nations) %>% 
  arrange(lineage, adm1, epi_week)
    
lineages_weeks_uk %>%
  filter(adm1 == "UK" & lineage %in% levels(vui_voc$lineage) & lineage != "B.1.1.7") %>%
  ggplot(aes(x=epi_week, y=n, group=lineage, color=lineage)) + 
  geom_line() + 
  geom_point() +
  scale_x_discrete(drop = FALSE) + # include all epi_week factor levels
  theme_classic()
```
### Constellations UpSet plot
```{r upset, eval=FALSE, include=FALSE}
mutations_s_uk_wide <-
  mutations_s_uk %>% 
  filter(lineage %in% levels(vui_voc$lineage)) %>% 
  filter(lineage %in% c("B.1.1.7", "B.1.351", "P.1")) %>% 
  mutate(logical_true = TRUE) %>% 
  pivot_wider(names_from = variant, values_from = logical_true, id_cols = c(sequence_name, variant), values_fill = FALSE)

mutations_s_uk_wide
```
### VUI/VOC/other
```{r vui_voc_other}
# convert Delta and Omicron sublineages to parent for counting
consortium_uk_parent <-
  bind_rows(
    # convert AY.x sublineages to parent B.1.617.2
    # convert BA.1.x sublineages to parent BA.1
    consortium_uk %>%
      mutate(lineage = gsub(sublineage_regex_gsub("AY"), "B.1.617.2", lineage)) %>% # convert AY.x to B.1.617.2
      mutate(lineage = gsub(sublineage_regex_gsub("BA.1"), "BA.1", lineage)), # convert BA.1.x to BA.1
  
    # filter AY.4 and sublineages then convert AY.4.x sublineages to parent AY.4 
    consortium_uk %>% 
      filter(lineage == "AY.4" | str_starts(lineage, fixed("AY.4."))) %>% 
      mutate(lineage = "AY.4"),
  
    # filter AY.4.2 and sublineages then convert any AY.4.2 sublineages to parent AY.4.2
    consortium_uk %>% 
      filter(lineage == "AY.4.2" | str_starts(lineage, fixed("AY.4.2."))) %>% 
      mutate(lineage = "AY.4.2"),
    
    # Delta non-AY.4
    consortium_uk %>% filter(( lineage == "B.1.617.2" | str_starts(lineage_full, fixed("B.1.617.2.")))
                             & lineage != "AY.4" 
                             & !str_starts(lineage, fixed("AY.4."))) %>% 
      mutate(lineage = "Delta_minus_AY.4"),
    
    # Delta non-AY.4.2
    consortium_uk %>% filter(( lineage == "B.1.617.2" | str_starts(lineage_full, fixed("B.1.617.2.")))
                             & lineage != "AY.4.2" 
                             & !str_starts(lineage, fixed("AY.4.2."))) %>% 
      mutate(lineage = "Delta_minus_AY.4.2")
  ) 

# count sequences by day
lineages_days_uk_all <- 
  bind_rows(
    consortium_uk_parent %>% 
      dplyr::count(lineage, sample_date, adm1, name = "n_day"),
    
    consortium_uk_parent %>% 
      dplyr::count(lineage, sample_date, name = "n_day") %>% 
      mutate(adm1 = "UK") %>% 
      mutate(across(adm1, as_factor))
  )

# by week
lineages_weeks_uk_all <- bind_rows(
 consortium_uk_parent %>% 
   dplyr::count(lineage, epi_date, adm1, name = "n_week"),
 
 consortium_uk_parent %>% dplyr::count(lineage, epi_date, name = "n_week") %>% 
   mutate(adm1 = "UK") %>% 
   mutate(across(adm1, as_factor))
)
 
lineages_days_uk_all %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/lineages_days_uk_all.rds"))
lineages_weeks_uk_all %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/lineages_weeks_uk_all.rds"))
```
## GISAID
```{r gisaid, eval=FALSE, include=TRUE}
# GISAID Delta sequences
gisaid <- 
  read_csv("6_seqmuts_ale.txt", 
           col_names = 
              c("sequence_name",
              "gisaid_id",
              "lineage", 
              "sample_date",
              "epi_week",
              "country",
              "region",
              "mutations")
  ) %>% 
  drop_na(sample_date) %>% # exclude sequences with missing sample date
  distinct

epi_levels_gisaid <- 
  min(gisaid$epi_week):max(gisaid$epi_week) %>% as.character

gisaid %<>% 
  mutate(across(c(epi_week), as_factor)) %>%
  mutate(epi_week = fct_expand(epi_week, epi_levels_gisaid) %>% fct_inseq) # expand factor levels to include any missing weeks


# All genes mutations and deletions
mutations_gisaid <-
  gisaid %>% 
  separate_rows(mutations, sep = '\\|') %>% 
  filter(mutations != "") %>% # trailing '|' generates empty string
  separate(mutations, into = c("gene", "variant"), sep = ':') %>% 
  distinct 

# S gene mutations and deletions
mutations_s_all_gisaid <- 
  mutations_gisaid %>% 
  filter(gene == "S") %>% 
  mutate(position = parse_number(variant))

# S gene del243-244
dels_s_gisaid <- 
  mutations_s_all_gisaid %>% 
  filter(str_detect(variant, "del") & (position == 243)) %>% 
  semi_join(mutations_s_all_gisaid %>% # sequences with both del243 and del244
              filter(str_detect(variant, "del") & (position == 244)),
            by = c("sequence_name", "gisaid_id", "lineage", 
                   "sample_date", "epi_week", "country", "region", "gene")) %>% 
  mutate(variant = "del243-244")
  
# defining mutations of delta variant
defining_delta <- 
        vui_voc %>% 
        filter(lineage == "B.1.617.2") %$% 
        mutation

# S gene mutations minus defining plus del243-244
mutations_s_gisaid <- 
  mutations_s_all_gisaid %>% 
  filter(!str_detect(variant, "del")) %>%  # remove deletions
  filter(!(variant %in% defining_delta)) %>% # remove Delta defining mutations
  bind_rows(dels_s_gisaid)  # bind del243-244

mutations_s_gisaid
#   mutate(across(c(gene, position, variant), as_factor)) %T>% 

```
### GISAID antigenic
```{r eval=FALSE, include=TRUE}

sequences_by_week_gisaid <- 
    gisaid %>% 
    dplyr::count(epi_week, name = "n_sequences_lineage")

# S gene escape mutations
escape_mutations <-
  database_genome %>%
  filter(!is.na(escape)) %$% 
  mutation 
  
antigenic_mutations_gisaid <- 
    mutations_s_gisaid %>% 
    filter(variant %in% escape_mutations | variant == "del243-244") %>% 
    dplyr::count(variant, epi_week, sort = TRUE) 

antigenic_mutations_gisaid_all <- 
  inner_join(antigenic_mutations_gisaid, sequences_by_week_gisaid) %>% 
  mutate(percentage = n / n_sequences_lineage * 100 ) %>% 
   complete(epi_week, nesting(variant), fill = list(n = 0, n_sequences_lineage = 0, percentage = 0)) %>%
    mutate(epi_week = epi_week %>% as.character %>% as.integer)

first_occurrence_gisaid <- 
    antigenic_mutations_gisaid_all %>% 
    filter(n > 0) %$% 
    min(epi_week)

antigenic_mutations_gisaid_all %<>%
  filter(epi_week >= first_occurrence_gisaid) %>%
  inner_join(epi_lookup) %>% 
  pivot_wider(names_from = epi_date, values_from = percentage, names_sort = TRUE, values_fill = 0, id_cols = variant) 

png("gisaid_delta.png",width=750, height=1300, units="px", type = "cairo-png")
antibody_complex_heatmap(antigenic_mutations_gisaid_all)
dev.off()

antigenic_mutations_gisaid_all
```
## Geo
```{r geo}
# TOPOJSON objectid
# 1 North East (England)
# 2 "North West (England)"
# 3 Yorkshire and The Humber
# 
# 4 East Midlands (England)
# 5 West Midlands (England)
# 6 East of England
# 
# 7 London
# 8 South East (England)
# 9 South West (England)
# 
# 10 Wales
# 11 Scotland
# 12 Northern Ireland
# 

# NUTS1 categories from consortium_uk in same order 
NUTS1 <- c( 
"North_East",               
"North_West",     
"Yorkshire_And_The_Humber",

"East_Midlands"            ,
"West_Midlands"            ,
"East_Of_England"          ,

"Greater_London"           ,
"South_East"               ,
"South_West"               ,

"Wales"        ,
"Scotland"      ,           
"Northern_Ireland"         
) 

NUTS1_objectid <- tibble(NUTS1, objectid = 1:length(NUTS1))

# count regional total sequences by week for calculation of percentage
geo <- 
  consortium_uk %>% 
  filter(!is.na(NUTS1)) %>% 
  dplyr::count(epi_week, NUTS1, .drop = FALSE) 

# regional counts for all variants with NUTS1 data
geo_variants <- bind_rows(
  # Delta and Omicron
  consortium_uk %>%
  filter(!is.na(NUTS1)) %>% 
  mutate(lineage = gsub(sublineage_regex_gsub("AY"), "B.1.617.2", lineage)) %>%  # convert AY.x lineages to B.617.2
  mutate(lineage = gsub(sublineage_regex_gsub("BA.1"), "BA.1", lineage)) %>%  # convert BA.1.x lineages to BA.1  
  mutate(across(lineage, as_factor)) %>%
  mutate(lineage = fct_other(lineage, 
                             keep = 
                               vui_voc %$% 
                               levels(lineage) %>% 
                               str_subset("^AY\\.", negate = TRUE))) %>% # convert non-VUI/VOC lineages to "Other"
  dplyr::count(epi_week, NUTS1, lineage, name = "n_week", .drop = FALSE), # TODO count AY lineages / Other Delta

  # AY.4
  consortium_uk %>%
    filter(!is.na(NUTS1)) %>%
    filter(lineage_full == "B.1.617.2" | str_starts(lineage_full, fixed("B.1.617.2."))) %>% # filter Delta only
    mutate(lineage = gsub(sublineage_regex_gsub("AY.4"), "AY.4", lineage)) %>%  # recode AY.4.x to AY.4
    mutate(lineage = fct_other(lineage, keep = "AY.4", other_level = "Delta_minus_AY.4")) %>%  # convert Delta non-AY.4/AY.4.x lineages to other Delta
    dplyr::count(epi_week, NUTS1, lineage, name = "n_week", .drop = FALSE),
  
  # AY.4.2
  consortium_uk %>%
    filter(!is.na(NUTS1)) %>%
    filter(lineage_full == "B.1.617.2" | str_starts(lineage_full, fixed("B.1.617.2."))) %>% # filter Delta only
    mutate(lineage = gsub(sublineage_regex_gsub("AY.4.2"), "AY.4.2", lineage)) %>%  # recode AY.4.2.x to AY.4.2
    mutate(lineage = fct_other(lineage, keep = "AY.4.2", other_level = "Delta_minus_AY.4.2")) %>%  # convert Delta non-AY.4.2/AY.4.x lineages to other Delta
    dplyr::count(epi_week, NUTS1, lineage, name = "n_week", .drop = FALSE)
)
    
geo_all <- 
  dplyr::inner_join(geo, geo_variants) %>%
  dplyr::mutate(across(epi_week, as.character)) %>%
  dplyr::mutate(across(epi_week, as.integer))

# calculate first week
earliest_voc_vui <- 
  geo_all %>% 
  filter(lineage != "Other" & n_week > 0) %$%
  min(epi_week)

geo_all %<>% 
  filter(epi_week >= earliest_voc_vui) %>% 
  dplyr::inner_join(epi_lookup) %>% 
  dplyr::mutate(Proportion = ifelse(n==0, 0, n_week / n * 100)) %>%  # keep zero counts for rendering 
  dplyr::select(-n) %>%
  dplyr::inner_join(NUTS1_objectid) %>% 
  dplyr::rename(Count = n_week) %T>%
  write_rds(str_c("COG-UK/", params$dataset_date, "/geo_all.rds"))

geo
geo_variants
geo_all
```
## MAP
### Geo distribution - run once
```{r geo_map_variant_alias, eval=FALSE, include=TRUE}
# Shapefile: NUTS Level 1 (January 2018) Ultra Generalised Clipped Boundaries in the United Kingdom
# https://data.gov.uk/dataset/37edc0ad-ffff-47c9-a01c-cb8d6123ec79/nuts-level-1-january-2018-ultra-generalised-clipped-boundaries-in-the-united-kingdom

# Convert shapefile to dataframe for ggplot2
# Run once locally and transfer mapdata RDS file to web server
# Uses packages rgdal and broom - not required on CLIMB
# Requires packages rgeos, maptools, rgdal, broom
# On Linux, install rgeos before rgdal

# Reshape for ggplot2 using the Broom package
mapdata <- 
  rgdal::readOGR(dsn = "COG-UK/Maps/", layer = "NUTS_Level_1_(January_2018)_Boundaries") %>%  # Load shapefile
  broom::tidy(region="nuts118nm") %>% # Convert shapefile to dataframe
  mutate(id = recode(id, # recode from NUTS1 categories in consortium_uk to NUTS1 names in map
                                            "East Midlands (England)" = "East_Midlands",
                                            "East of England"= "East_Of_England" ,     
                                            "London" = "Greater_London",               
                                            "North East (England)"= "North_East",     
                                            "North West (England)"= "North_West",     
                                            "Northern Ireland" = "Northern_Ireland",        
                                            "South East (England)" = "South_East",    
                                            "South West (England)" = "South_West",  
                                            "West Midlands (England)" = "West_Midlands",
                                            "Yorkshire and The Humber" = "Yorkshire_And_The_Humber")) %>% 
  dplyr::rename("NUTS1" = "id") %>% 
  write_rds(str_c("COG-UK/mapdata.rds"))

mapdata
```
### Antigenic and map
```{r geo_map_antigenic_alias, eval=FALSE, include=FALSE}
# del243-244 sample IDs
del_22289_6_samples <- 
  deletions %>% 
  filter(
    (ref_start == 22289 & length == 6) 
  ) %$% samples 

# Antigenic deletion del243-244 22289-22294 (6nt) by region 
del_22289_6_regions <- 
  consortium_uk %>% 
  filter(!is.na(NUTS1)) %>%
  filter(sequence_name %in% del_22289_6_samples) %>% 
  dplyr::count(epi_week, lineage, NUTS1, name = "n_sequences_lineage", .drop = FALSE) %>% 
  mutate(variant = "del243-244", .before = 1)

sequences_by_week_regions <- 
  consortium_uk %>% 
  filter(!is.na(NUTS1)) %>%
  dplyr::count(epi_week, lineage, NUTS1, name = "n", .drop = FALSE) # count total sequences per epiweek/lineage/NUTS1

escape_mutations <- 
  database_genome %>%
  filter(gene == "S" & !is.na(escape)) %$% 
  mutation # filter escape mutations from database

antigenic_mutations <- 
  mutations_uk %>% 
  filter(!is.na(NUTS1)) %>% 
  filter(variant %in% escape_mutations) %>% 
  filter(sequence_name != "England/NEWC-2729532/2021") %>% # remove Delta outlier from January 2021
  dplyr::count(variant, epi_week, lineage, NUTS1, name = "n_sequences_lineage", .drop = FALSE) # count specific variant carry a specific mutation per epiweek and NUTS1

antigenic_mutations <- bind_rows(antigenic_mutations,del_22289_6) # bind with deletion data

antigenic_mutations_lineages_all <- 
  inner_join(antigenic_mutations, sequences_by_week_lineages) %>% 
  mutate(percentage = ifelse(n==0, 0, n_sequences_lineage  / n * 100)) # calculate proportion

antigenic_mutations_lineages_all$variant <- as.factor(antigenic_mutations_lineages_all$variant)

# antigenic_mutations_lineages_all %>% mutate(variant, fct_expand(variant, "All"))
antigenic_mutations_lineages_all$epi_week <- as.character(antigenic_mutations_lineages_all$epi_week)
antigenic_mutations_lineages_all$epi_week <- as.numeric(antigenic_mutations_lineages_all$epi_week)
antigenic_mutations_lineages_all <- dplyr::inner_join(antigenic_mutations_lineages_all, epi_lookup)
antigenic_mutations_lineages_all <- dplyr::rename(antigenic_mutations_lineages_all, "Count" = "n_sequences_lineage")
antigenic_mutations_lineages_all <- dplyr::rename(antigenic_mutations_lineages_all, "Proportion" = "percentage")
antigenic_mutations_lineages_all <- antigenic_mutations_lineages_all %>% 
  mutate(lineage = fct_other(lineage, keep = vui_voc %$% levels(lineage))) %>%
  filter(!is.na(NUTS1) & !is.na(lineage)) 

antigenic_mutations_lineages_all %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/antigenic_mutations_lineages_all.rds"))

```

## ISARIC
### Alias
```{r isaric_alias, eval=FALSE, include=FALSE}
library(jsonlite)
alias_key <- fromJSON("https://raw.githubusercontent.com/cov-lineages/pango-designation/master/pango_designation/alias_key.json")

alias_key %<>% 
  keep(~ length(.x) == 1) %>% # drop recombinants
  purrr::discard(~ .x == "") # drop top level lineages

# TODO mutate full lineage in initial consortium read instead
consortium_full <- 
  consortium_uk %>% 
  mutate(lineage_full = lineage, .after = lineage)

mutations_full <- 
  mutations_uk %>% 
  mutate(lineage_full = lineage, .after = lineage)

for (i in 1:length(alias_key)) {
  consortium_full <<- 
    consortium_full %>% 
    mutate(lineage_full = str_replace(lineage_full, str_c("^", names(alias_key)[i], "(?=\\.)"), str_c(alias_key[[i]])))
  
  mutations_full <<- 
    mutations_full %>% 
    mutate(lineage_full = str_replace(lineage_full, str_c("^", names(alias_key)[i], "(?=\\.)"), str_c(alias_key[[i]])))
}
```
### Filter
```{r isaric}
# source("COG-UK/out_frame_del.R")
# source("COG-UK/wuhan_ref_aa.R")

message("Reading ISARIC list file ", params$isaric_csv)
isaric_list <- read_csv(params$isaric_csv)

# iterate through isaric_list row by row
isaric_dfr <-
  isaric_list %>%
  pmap_dfr(function(...) {
    current <- tibble(...) # current row of isaric_list
    
    output <- tibble()
    
    if (is.na(current$Mutation)) { # if no mutations then search consortium 
      if (!is.na(current$Lineage)) {
        
        # filter by lineage and wildcard
        if (str_ends(current$Lineage, fixed("*"))) { # filter sublineages if wildcard
          lineage_prefix <- str_sub(current$Lineage, 1, nchar(current$Lineage) - 1)
          
          output <-
            consortium_uk %>%
            filter(if_any(c(lineage, lineage_full), ~ str_starts(.x, fixed(lineage_prefix)))) %>%   # use fixed because dot is regex special character
            select(sequence_name, cog_id, sample_date, lineage, lineage_full)
          
        } else { # no wildcard - filter exact lineage
          output <-
            consortium_uk %>%
            filter(lineage_full == current$Lineage |
                     lineage == current$Lineage) %>% 
            select(sequence_name, cog_id, sample_date, lineage, lineage_full)
        }
        
        if(!is.na(current$Lineage_filter_out)){
          filters <- str_split(current$Lineage_filter_out, fixed("|"))
          # TODO (no examples at present)
        }
      } 
    } else { # filter deletion/insertion/mutation
     gene_mutation <- 
       str_split(current$Mutation, ":") %>% 
       unlist # split gene:mutation

      if(str_starts(gene_mutation[2], "del|ins")){ # deletion or insertion - look up consortium
        output <- consortium_uk
      } else{ # mutation
        output <- mutations_uk
      }

      # filter by lineage
      if(!is.na(current$Lineage)){
        if (str_ends(current$Lineage, fixed("*"))) { # filter sublineages if wildcard
          lineage_prefix <- str_sub(current$Lineage, 1, nchar(current$Lineage) - 1)

          output %<>%
            filter(if_any(c(lineage, lineage_full), ~ str_starts(.x, fixed(lineage_prefix))))
        } else { # no wildcard - filter exact lineage
          output %<>%
            filter(lineage == current$Lineage)
        }
      }

      # filter out lineage
      if(!is.na(current$Lineage_filter_out)){
        excludes <- 
          current$Lineage_filter_out %>% 
          str_split(fixed("|")) %>% 
          unlist
        
        walk(excludes, function(x){
          if(str_ends(x, fixed("*"))){ # if wildcard
            lineage_prefix <- str_sub(x, 1, nchar(x) - 1)

            output <<-
              output %>%
              filter(if_all(c(lineage, lineage_full), ~ !str_starts(.x, fixed(lineage_prefix))))

          } else { # else exact lineage
            output <<-
              output %>%
              filter(if_all(c(lineage, lineage_full), ~ .x != x))
          }
        })
        
      }

      if(str_starts(gene_mutation[2], "del")){ # deletion - look up consortium 
        #TODO calculate genome coordinates from aa positions
        #TODO in frame only?
        #TODO gene name
        
        dels <-
          deletions %>% 
          filter(between(ref_start, 22283, 22294)) %>% 
          mutate(gene = "S", variant = str_c("del_", ref_start, "_", length)) %>% 
          select(-ref_start, -length)

        # del_22289_6 is del243-244
        # S:del241-243 is del_22283_9
        # S:del242-244 is del_22286_9
        # 22283, 22286, 22289 and 22292 ( to 22294 ?)
        
        output %<>% 
          select(sequence_name, cog_id, sample_date, lineage, lineage_full) %>% 
          inner_join(dels, by = c("sequence_name" = "samples"))
      } else if(gene_mutation[1] == "S" & str_starts(gene_mutation[2], "ins")){ # insertion - look up consortium
        # Spike genomic coordinates 21563..25384 
        # TODO in frame only
        
        ins_samples <- 
          insertions %>% 
          # filter(str_length(insertion) %% 3 == 0) %>% 
          filter(ref_start >= 21563 & ref_start < 25384) %>%  # Spike coordinates 21563 to 25384 
          filter(!str_detect(insertion, "N")) %>% # exclude any insertions with uncalled nucleotides
          mutate(gene = "S", variant = str_c("ins_", ref_start, "_", insertion), .keep = "unused") 

        output %<>% 
          select(sequence_name, cog_id, sample_date, lineage, lineage_full) %>% 
          inner_join(ins_samples, by = c("sequence_name" = "samples"))
      } else { # mutation - look up mutations
          
          if(str_ends(gene_mutation[2], "X")){ # mutation wildcard
            output %<>% filter(gene == gene_mutation[1] & position == parse_number(gene_mutation[2]))
          } else { # exact match of mutation
            output %<>% filter(gene == gene_mutation[1] & variant == gene_mutation[2])
          }

        output %<>% select(sequence_name, cog_id, sample_date, lineage, lineage_full, gene, variant)
     }

    }
    
    output %>% mutate(query_id = current$ID)
  })# %>% distinct

isaric_dfr
```
### Compare
```{r isaric_compare}
# list isaric TSV files
isaric_files <- list.files(pattern = "isaric_.*_cumulative\\.tsv") 
  
# extract dates from filenames  
isaric_dates <-
  isaric_files %>% 
  str_extract("\\d{4}-\\d{2}-\\d{2}") %>% 
  parse_date

# get most recent date
isaric_previous <- isaric_dates[isaric_dates < params$dataset_date]
isaric_latest <- NULL
if(length(isaric_previous > 0)){ # previous datasets exist
  message("Reading most recent ISARIC cumulative file")
  isaric_recent <- 
    isaric_previous %>% 
    max %>% 
    grep(isaric_files) %>% 
    isaric_files[.] %>% 
    print %>%
    read_tsv() %>% 
    separate_rows(query_id, sep = ",") %>% 
    mutate(query_id = as.numeric(query_id)) 
  
  isaric_latest <- 
    anti_join(isaric_dfr, isaric_recent, by = c("cog_id", "query_id"))
}

isaric_latest
```

### Collapse
```{r isaric_collapse}
collapse_isaric <- function(isaric_hits){
  isaric_hits %>% 
  mutate(gene_variant = str_c(gene, ":", variant), .keep = "unused") %>% 
  group_by(cog_id, sample_date, lineage) %>% 
  summarise(mutations = toString(str_c(gene_variant)), query_id = toString(query_id), .groups = "drop") %>% 
  arrange(desc(sample_date), lineage, cog_id)
}

if(!is.null(isaric_latest)){
  isaric_latest_collapse <- 
    isaric_latest %>% 
    collapse_isaric %T>% 
    write_tsv(str_c("isaric_", params$dataset_date, "_latest.tsv") %T>% message("Writing ", .))
  
  isaric_latest_collapse
}

isaric_dfr_collapse <- 
  isaric_dfr %>% 
  collapse_isaric %T>% 
  write_tsv(str_c("isaric_", params$dataset_date, "_cumulative.tsv") %T>% message("Writing ", .))

isaric_dfr_collapse
```
## Ronapreve plot
```{r ronopreve_plot}
source("mab_upset_regeneron.R")
ronapreve_upset <- generate_upset()
ronapreve_upset_28 <- generate_upset(filter_date = sample_date_28)

png(filename=str_c("COG-UK/", params$dataset_date, "/Ronapreve.png"), width=1800, height=975, type = "cairo-png")
ronapreve_upset
dev.off()

png(filename = str_c("COG-UK/", params$dataset_date, "/Ronapreve_28.png"), width=1800, height=975, type = "cairo-png")
ronapreve_upset_28
dev.off()

# ronapreve_upset
# ronapreve_upset_28

```

## Spike profiles for table/plots
```{r spike_profiles}
source("spike_profiles.R")
viruses <- virus_profiles(mutation_df = mutations_uk)
spike_tab <- spike_profiles_nations(viruses)
write_rds(viruses, str_c("COG-UK/", params$dataset_date, "/spike_viruses.rds"))
write_rds(spike_tab, str_c("COG-UK/", params$dataset_date, "/spike_table.rds"))
```
# RDS check
```{r rds_check}
# TODO Check that RDS files can be read
# filedata <- map(filenames, function(x){print(x); read_rds(x)} )
```

## Done
```{r success}
message("PIPELINE COMPLETED")
```