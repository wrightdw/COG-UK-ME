---
title:  "COG-UK Mutations"
output: html_notebook
params: 
  latest:           TRUE # TRUE to copy latest files on CLIMB to working directory, overrides dataset_date with today()
  dataset_date:     "" # Used if latest == FALSE. if empty, defaults to today's date, otherwise enter date string
  spike_csv:        "spike_escape_info.csv"
  spike_extra_csv:  "spike_escape_extra.csv"
  tcell_csv:        "tcell_long.csv"
  deletions_tsv:    "cog.deletions.tsv"
  predictions_tsv:  "Prediction_from_Morten.txt"
  spike_fasta:      "sequence.fasta"
  vui_voc_csv:      "VUI and VOC.csv"
  remdesivir_dir:   "Remdesivir Mutants" 
  nirmatrelvir_dir: "Nirmatrelvir Mutants" 
  isaric_csv:       "Isaric_list.csv"
  insertions_tsv:   "cog.insertions.tsv"
  functional_csv:   "tcell_functional_mutations.csv"
  deletions_mapping_csv: "deletion_mapping.csv"
  insertions_mapping_csv: "insertion_mapping.csv"
---
# Setup
```{r setup}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(magrittr))
library(wesanderson)
library(RColorBrewer)
suppressPackageStartupMessages(library(lubridate))
library(fuzzyjoin)
library(htmltools)
suppressPackageStartupMessages(library(jsonlite))
# also require seqinr - loaded later on to avoid name clash of dplyr count function
library(UpSetR)

# Helper function
# Construct a regular expression for replacement of the sublineages of a lineage using gsub
sublineage_regex_gsub <- function(lineage){
  str_replace_all(lineage, "\\.", "\\\\\\.") %>% 
    paste0("^", ., "\\..*")
}
```
```{r climb}
Sys.setenv(TZ="Europe/London")

if(params$latest){ # copy today's files to working directory on CLIMB, stop if process run previously or today's files not available yet
  
  # check files exist
  params$dataset_date <- today()
  latest_dir <- "/cephfs/covid/bham/results/msa/latest"
  consortium_csv <- str_c("cog_global_", params$dataset_date, "_consortium.csv")
  consortium_today_msa <- file.path(latest_dir, "metadata", consortium_csv)
  
  if(!file.exists(consortium_csv) && # file not already copied
     file.exists(consortium_today_msa)){ # MSA file exists
    
    # copy consortium and deletions to working directory
    message("Copying latest consortium and deletions files")
    file.copy(consortium_today_msa, getwd())
    
    # deletions and insertions files not named by date so overwrite previous
    file.copy(file.path(latest_dir, "cog", params$deletions_tsv), getwd(), overwrite = TRUE) 
    file.copy(file.path(latest_dir, "cog", params$insertions_tsv), getwd(), overwrite = TRUE) 
  } else {
    stop(str_c(consortium_today_msa, " does not exist or already copied")) # terminate script
  }  
  
} else {
  if(params$dataset_date == ""){
    params$dataset_date <- today()
  } else {
    params$dataset_date %<>% as.Date
  }
  
  consortium_csv <- str_c("cog_global_", params$dataset_date, "_consortium.csv")
}

dir.create(str_c("COG-UK/", params$dataset_date))
```

# Consortium
## Read
```{r consortium_read, include=FALSE}
message("Reading ", consortium_csv)
consortium_uk <- 
  read_csv((consortium_csv), col_types = cols(.default = col_character())) %>% 
  filter(country == "UK" & !is.na(adm1) & adm1 %in% (c("England", "Scotland", "Wales", "Northern_Ireland"))) %>% # exclude Crown dependencies and British Overseas Territories
  select(-gisaid_id, -submission_org_code, -root_sample_id, -(adm2:travel_history), NUTS1,
         -lineages_version, -country,
         -received_date, -collection_date, -published_date, -starts_with("scorpio"),
         -lineage_conflict, -lineage_ambiguity_score, -sequencing_org_code, -submission_user
         ) %>% # remove unused columns
  relocate(NUTS1,.after = adm1) %>% 
  type_convert 

consortium_uk
```
```{r consortium_clean, include=FALSE}
# Data cleaning:
# Exclude duplicate Delta sequences with incorrect dates in April 2020
# NUTS1 cleanup - correct NUTS1 missing or incorrect values
# Correct to 2nd December
  # England/PHEP-YYNQW43/2021	2021-11-02	97	2021-10-31	B.1.1.529
  # to sample_date 2021-12-02 epi_week 101
dodgy_delta <- 
  consortium_uk %>% 
  filter(lineage == "B.1.617.2" & epi_week %in% c(16, 17))

# Exclude Omicron sequences with erroneous dates before November 2021
dodgy_omicron <- 
  consortium_uk %>% 
  filter( (lineage == "BA.1" | str_starts(lineage, fixed("BA.1."))) & sample_date < "2021-11-20")

consortium_uk %<>% 
  anti_join(dodgy_delta) %>% 
  anti_join(dodgy_omicron) %>% 
  mutate( 
    NUTS1 = case_when(
      adm1 == "Scotland" ~ "Scotland",
      adm1 == "Wales" ~ "Wales",
      adm1 == "Northern_Ireland" ~ "Northern_Ireland",
      TRUE ~ NUTS1
    )
  ) %>%
  rows_update(tibble(sequence_name = "England/PHEP-YYNQW43/2021", sample_date = as.Date("2021-12-02"), epi_week = 101))
  
# Epidemic week / Sunday date conversion
epi_lookup <-
  tibble(
    epi_date = seq(from = ymd("2020-01-26"), to = consortium_uk %$% max(sample_date), by = "week"),
    epi_week = seq(consortium_uk %$% min(epi_week), consortium_uk %$% max(epi_week))
  ) 

epi_levels <- min(consortium_uk$epi_week):max(consortium_uk$epi_week) %>% as.character

consortium_uk %<>% 
  inner_join(epi_lookup) %>% 
  relocate(epi_date, .after = epi_week) %>% 
  mutate(across(c(epi_week, adm1, NUTS1), as_factor)) %>%
  mutate(epi_week = fct_expand(epi_week, epi_levels) %>% fct_inseq) # expand factor levels to include any missing weeks

consortium_uk
```
## 28 days
```{r consortium_constants, include=FALSE}
sample_date_28 <- max(consortium_uk$sample_date) - days(27) # calculate 28 day period up to and including latest sample date
message("28 days date: ", sample_date_28)
```
## Alias
```{r consortium_alias, include=FALSE}
message("Looking up PANGO designation lineage alias key on GitHub")
# reconstruct lineage full names from alias JSON
alias_key <- fromJSON("https://raw.githubusercontent.com/cov-lineages/pango-designation/master/pango_designation/alias_key.json")

alias_key %<>% 
  keep(~ length(.x) == 1) %>% # drop recombinants
  purrr::discard(~ .x == "") # drop top level lineages

# copy lineage column
consortium_uk %<>% 
  mutate(lineage_full = lineage, .after = lineage)

# overwrite aliases with full lineage names
for (i in 1:length(alias_key)) {
  consortium_uk <<- 
    consortium_uk %>% 
    mutate(lineage_full = str_replace(lineage_full, str_c("^", names(alias_key)[i], "(?=\\.)"), str_c(alias_key[[i]])))
}

consortium_uk
```
## Sample
```{r consortium_sample, eval=FALSE, include=TRUE}
# Sample of full dataset for development purposes
consortium_uk %<>% slice_sample(n = 100000)
consortium_uk
```

## Write
```{r consortium_write}
mutations_uk <- 
  consortium_uk %>% 
  select(sequence_name, cog_id, sample_date, epi_week, epi_date, lineage, lineage_full, adm1, NUTS1, mutations) %>% 
  distinct # get rid of identical variant calls

message("Writing consortium_uk.rds")
consortium_uk %<>% 
  select(-mutations) %>% 
  distinct %T>% # remove duplicates
  write_rds(str_c("COG-UK/", params$dataset_date, "/consortium_uk.rds"))

consortium_uk
```
# Mutations
```{r mutations_consortium}
mutations_uk %<>%    
  separate_rows(mutations, sep = '\\|') %>% 
  separate(mutations, into = c("gene", "variant"), sep = ':') %>% 
  drop_na(-NUTS1) %>% # don't drop missing geographical data
  filter(gene != "synSNP") %>%
  mutate(position = parse_number(variant)) %>% 
  mutate(across(c(gene, position, variant), as_factor)) %>% 
  mutate(gene = fct_recode(gene, ORF1ab = "orf1ab")) %T>% 
  write_rds(str_c("COG-UK/", params$dataset_date, "/mutations_uk.rds"))

mutations_s_uk <- 
  mutations_uk %>% 
  filter(gene == "S") %>% 
  select(-gene) %>% 
  mutate(across(c(variant, position), fct_drop)) %>% # drop non-spike mutations from factor levels
  write_rds(str_c("COG-UK/", params$dataset_date, "/mutations_s_uk.rds"))

mutations_uk
mutations_s_uk
```


# Deletions
```{r deletions}
deletions <- 
  read_tsv(params$deletions_tsv) %>% 
  separate_rows(samples, sep = '\\|')

deletions %<>% semi_join(consortium_uk, by = c("samples" = "sequence_name")) # remove unfiltered sequence IDs from deletions

message("Writing deletions.rds")
deletions %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/deletions.rds"))
```
```{r deletions_mapping}
deletions_mapping <- 
  read_csv(params$deletions_mapping_csv, 
           col_types = cols(del_start = col_integer(),
                            del_end = col_integer(),
                            gene = readr::col_factor(NULL))) %>% # avoid name clash with scales package
  inner_join(deletions) %>% 
  select(-ref_start, -length)

deletions_mapping <- 
  consortium_uk %>% 
  select(sequence_name, cog_id, sample_date, epi_week, epi_date, lineage, lineage_full, adm1, NUTS1) %>% 
  inner_join(deletions_mapping,  by = c("sequence_name" = "samples")) %>% 
  mutate(del_subst_position = parse_number(del_subst)) 

deletions_mapping %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/deletions_mapping.rds"))
```
## Complete
```{r deletions_complete}
deletions_complete <- 
  deletions_mapping %>% 
  rowwise() %>% 
  mutate(del_start_end = 
           seq(min(c(del_start, del_end, del_subst_position), na.rm = TRUE), 
                             max(c(del_start, del_end, del_subst_position), na.rm = TRUE)) %>% 
           paste(collapse = "|"), .keep = "unused"
         ) %>% 
  separate_rows(del_start_end, sep = '\\|') %>% 
  rename(position = del_start_end, variant = del_id) %>%   
  mutate(across(c(position, variant), as_factor)) %>% 
  select(-del_subst)

deletions_complete
```

## Mutation / REF counts
```{r mutations_refs}
mutations_deletions_uk <- bind_rows(mutations_uk, deletions_complete)

#### UK ### 
genes_positions <- 
  mutations_deletions_uk %>% 
  distinct(gene, position) # gene / position combinations actually found in mutations

sequences_by_week <- 
  consortium_uk %>% 
  dplyr::count(epi_week, epi_date, name = "n_sequences")

positions_by_week <- 
  mutations_deletions_uk %>%
  dplyr::count(epi_week, epi_date, gene, position, .drop = FALSE, name = "n_variant_sequences") # count all possible epi_week/gene/position combinations 

reference_counts <- 
  positions_by_week %>%
  inner_join(genes_positions) %>% # remove gene / position combinations not found in mutations
  inner_join(sequences_by_week) %>% 
  mutate(n = n_sequences - n_variant_sequences, variant = "WT", .keep = "unused") %>% # calculate reference / other
  filter(n > 0) %>%  # remove zero WT entries (where all sequences are variants for an epi_week / position combo)
  mutate(adm1 = "UK")

mutation_counts <- 
  mutations_deletions_uk %>%
  dplyr::count(epi_week, epi_date, gene, position, variant) %>% 
  mutate(adm1 = "UK")

#### Nations ####
sequences_by_week_nations <-
  consortium_uk %>%
  dplyr::count(epi_week, epi_date, adm1, name = "n_sequences")

positions_by_week_nations <-
  mutations_deletions_uk %>%
  dplyr::count(epi_week, epi_date, gene, position, adm1, .drop = FALSE, name = "n_variant_sequences") # count all possible epi_week/gene/position/nation combinations

reference_counts_nations <- 
  positions_by_week_nations %>%
  inner_join(genes_positions) %>% # remove gene / position combinations not found in mutations
  inner_join(sequences_by_week_nations) %>% 
  mutate(n = n_sequences - n_variant_sequences, variant = "WT", .keep = "unused") %>% # calculate reference / other
  filter(n > 0) # remove zero WT entries (where all sequences are variants for an epi_week / position combo)

mutation_counts_nations <- 
  mutations_deletions_uk %>%
  dplyr::count(epi_week, epi_date, gene, position, variant, adm1)

# TODO calculate UK counts by summing the nation counts
mutation_reference_counts <- 
  bind_rows(mutation_counts, reference_counts, mutation_counts_nations, reference_counts_nations) %>% 
  mutate(across(variant, as_factor)) %T>% 
  write_rds(str_c("COG-UK/", params$dataset_date, "/mutation_reference_counts.rds"))

mutation_reference_counts
```


```{r database_deletions}
deletions_uk <-
  deletions_mapping %>% 
  group_by(gene, del_start, del_end, del_id) %>% 
  summarise(UK = n(), earliest = min(sample_date), .groups = "drop")

deletions_nations <- 
  deletions_mapping %>% 
  dplyr::count(gene, del_start, del_end, del_id, adm1) %>% 
  pivot_wider(names_from = adm1, values_from = n)

deletions_uk_28 <- 
  deletions_mapping %>% 
  filter(sample_date >= sample_date_28) %>% 
  dplyr::count(gene, del_start, del_end, del_id, name = "UK_28")

deletions_nations_28 <-
  deletions_mapping %>% 
    filter(sample_date >= sample_date_28) %>% 
    dplyr::count(gene, del_start, del_end, del_id, adm1) %>% 
    pivot_wider(names_from = adm1, values_from = n) %>% 
    rename_with(~paste0(., "_28"), .cols = c(England, Northern_Ireland, Scotland, Wales))

database_deletions <- 
  deletions_uk %>% 
  inner_join(deletions_nations) %>% 
  left_join(deletions_uk_28) %>% 
  left_join(deletions_nations_28) %>% 
  mutate(across(where(is.numeric), ~replace_na(.x, 0L)))

database_deletions %T>% 
  write_rds(str_c("COG-UK/", params$dataset_date, "/database_deletions.rds"))
```

# Insertions
```{r}
insertions <- 
  read_tsv(params$insertions_tsv) %>% 
  separate_rows(samples, sep = '\\|')

insertions %<>% semi_join(consortium_uk, by = c("samples" = "sequence_name")) # remove unfiltered sequence IDs from deletions

message("Writing insertions.rds")
insertions %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/insertions.rds"))

```
### Mapping
```{r insertions_mapping}
insertions_mapping <- 
  read_csv(params$insertions_mapping_csv) %>%
  mutate(across(c(gene), as_factor)) %>% 
  inner_join(insertions)

insertions_mapping <- 
  consortium_uk %>% 
  select(sequence_name, cog_id, sample_date, epi_week, epi_date, lineage, lineage_full, adm1, NUTS1) %>% 
  inner_join(insertions_mapping,  by = c("sequence_name" = "samples")) #%>% 
  # rename(variant = insertion_id) %>% 
  # select(-c(insertion, ref_start))  

insertions_mapping %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/insertions_mapping.rds"))

```
# Mutations + indels
```{r mutations_indels}
# for mutations/indels downloads
mutations_indels_uk_28 <-
  mutations_uk %>% 
  bind_rows(deletions_mapping %>% rename(variant = del_id)) %>% 
  bind_rows(insertions_mapping %>% rename(variant = insertion_id)) %>% 
  filter(sample_date >= sample_date_28) %T>% 
  write_rds(str_c("COG-UK/", params$dataset_date, "/mutations_indels_uk_28.rds"))
```

```{r database_insertions}
insertions_uk <-
  insertions_mapping %>% 
  group_by(gene, ref_start, insertion, insertion_id) %>% 
  summarise(UK = n(), earliest = min(sample_date), .groups = "drop")

insertions_nations <- 
  insertions_mapping %>% 
  dplyr::count(gene, ref_start, insertion, insertion_id, adm1) %>% 
  pivot_wider(names_from = adm1, values_from = n)

insertions_uk_28 <- 
  insertions_mapping %>% 
  filter(sample_date >= sample_date_28) %>% 
  dplyr::count(gene, ref_start, insertion, insertion_id, name = "UK_28")

insertions_nations_28 <-
  insertions_mapping %>% 
    filter(sample_date >= sample_date_28) %>% 
    dplyr::count(gene, ref_start, insertion, insertion_id, adm1) %>% 
    pivot_wider(names_from = adm1, values_from = n) %>% 
    rename_with(~paste0(., "_28"), .cols = c(England, Northern_Ireland, Scotland, Wales))

database_insertions <- 
  insertions_uk %>% 
  inner_join(insertions_nations) %>% 
  left_join(insertions_uk_28) %>% 
  left_join(insertions_nations_28) %>% 
  mutate(across(where(is.numeric), ~replace_na(.x, 0L)))

database_insertions %T>% 
  write_rds(str_c("COG-UK/", params$dataset_date, "/database_insertions.rds"))
```
# Database
```{r database_genome}
lineage_distinct <- 
  mutations_uk %>% 
  group_by(gene, position, variant) %>% 
  summarise(n_lineages = n_distinct(lineage), .groups = "drop") 

lineages <- 
  mutations_uk %>% 
  distinct(gene, position, variant, lineage) %>% 
  group_by(gene, position, variant) %>% 
  arrange(gene, position, variant, lineage, .by_group = TRUE) %>% 
  summarise(lineages = toString(lineage), .groups = "drop")

## UK and nations
# All sample dates
variants_uk <-
  mutations_uk %>% 
  group_by(gene, position, variant) %>% 
  summarise(UK = n(), earliest = min(sample_date), .groups = "drop")

variants_nations <- 
  mutations_uk %>% 
  dplyr::count(gene, position, variant, adm1) %>% 
  pivot_wider(names_from = adm1, values_from = n)

# Sample dates in last 28 days
variants_uk_28 <- 
  mutations_uk %>% 
  filter(sample_date >= sample_date_28) %>% 
  dplyr::count(gene, position, variant, name = "UK_28")

variants_nations_28 <-
  mutations_uk %>% 
    filter(sample_date >= sample_date_28) %>% 
    dplyr::count(gene, position, variant, adm1) %>% 
    pivot_wider(names_from = adm1, values_from = n) %>% 
    rename_with(~paste0(., "_28"), .cols = c(England, Northern_Ireland, Scotland, Wales))

database_genome <- 
  read_csv(params$spike_csv, col_types = cols(.default = col_character())) %>%
  type_convert %>%
  mutate(across(c(mutation, position), as_factor)) %>% 
  mutate(anchor = str_c("<a href='", doi, "'target='_blank'>", citation,"</a>"), .keep = "unused") %>% # hyperlink to citation DOI
  group_by(position, mutation) %>% 
  summarise(escape = escape %>% unique %>% sort %>% toString, 
            anchor = anchor %>% unique %>% str_c(collapse = "<br>"), # line breaks between hyperlinks
            mab = mab %>% any,
            plasma = plasma %>% any,
            vaccine_sera = vaccine_sera %>% any,
            support = support %>% unique %>% toString,
            domain = domain %>% unique %>% toString, 
            .groups = "drop") %>% 
  mutate(gene = factor("S"), .before = position)

join_cols <- c("mutation" = "variant", "position" = "position", "gene" = "gene")

database_genome %<>% 
  full_join(lineage_distinct, by = join_cols) %>% 
  full_join(lineages, by = join_cols) %>% 
  full_join(variants_uk,  by = join_cols) %>% 
  full_join(variants_nations,  by = join_cols) %>% 
  full_join(variants_uk_28,  by = join_cols) %>% 
  full_join(variants_nations_28,  by = join_cols) 

database_genome %<>%
  rename(
    `# Global Lineages associated with` = n_lineages, 
    `Global Lineages` = lineages, 
    
    `numSeqs UK` = UK,
    `numSeqs Eng` = England,
    `numSeqs NI` = Northern_Ireland,
    `numSeqs Scotland` = Scotland,
    `numSeqs Wales` = Wales,

    `numSeqs UK 28 days` = UK_28,
    `numSeqs Eng 28 days` = England_28,
    `numSeqs Scotland 28 days` = Scotland_28,
    `numSeqs Wales 28 days` = Wales_28, 
    `numSeqs NI 28 days` = Northern_Ireland_28) %>% 
  mutate(across(starts_with( c("numSeqs", "#") ), ~replace_na(.x, 0L))) %>% 
  mutate(across(c(gene, position, mutation), as.character)) %>% 
  mutate(across(position, as.integer)) %>% 
  arrange(gene, position, mutation) %>% 
  mutate(across(c(support, domain, gene, mutation), as_factor)) %>% 
  mutate(support = fct_relevel(support, "lower", "medium", "high"))

database_genome %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/database_genome.rds"))
```

# Therapeutics
```{r therapeutics}
# ORF1ab positions https://www.ncbi.nlm.nih.gov/protein/1796318597
# see mat_peptide annotation
# nsp12 4393..5324
# Mpro 3264..3569

therapeutics_data <- function(data_dir, orf1ab_pos){
  fs::dir_ls(data_dir, glob = "*.csv") %>% # get file names
    map_dfr(read_csv, col_types = cols(`quantification (fold)` = col_character())) %>% 
    rename(gene = ORF) %>%
    rename_with(~str_c(.x, "_protein"), c(position, residue, mutation)) %>% 
    mutate(gene = recode(gene, "orf1b" = "orf1ab", "ORF1a" = "orf1ab"),
           position = position_protein + orf1ab_pos - 1, .after = gene) %>% 
    mutate(variant = str_c(str_sub(mutation_protein, 1, 1), 
                           position, 
                           str_sub(mutation_protein, -1, -1) ), 
           .after = position )
}

thera_data <- bind_rows(therapeutics_data(params$remdesivir_dir, 4393), # nsp12 
                        therapeutics_data(params$nirmatrelvir_dir, 3264)) # Mpro
mutations_rem_uk <- 
  mutations_uk %>% 
  filter(gene == "orf1ab") %>% 
  mutate(across(position, as.character)) %>%
  mutate(across(position, as.numeric)) %>%
  mutate(across(c(variant), fct_drop)) %>% 
  semi_join(thera_data)

variants_rem_uk <-
  mutations_rem_uk %>%
  group_by(position, variant) %>%
  summarise(UK = n(), earliest = min(sample_date), .groups = "drop")

# Sample dates in last 28 days
variants_rem_uk_28 <-
  mutations_rem_uk %>%
  filter(sample_date >= sample_date_28) %>%
  dplyr::count(position, variant, name = "UK_28")

thera_data %<>%  
  mutate(anchor = str_c("<a href='https://", doi, "'target='_blank'>", citation,"</a>"), .keep = "unused") %>%   # hyperlink to citation DOI
  left_join(variants_rem_uk) %>% 
  left_join(variants_rem_uk_28) %>% 
  rename(
    `numSeqs UK` = UK,
    `numSeqs UK 28 days` = UK_28) %>% 
  mutate(across(starts_with( c("numSeqs", "#") ), ~replace_na(.x, 0L))) 

thera_data %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/therapeutics.rds"))
```

# T cell
## Epitopes
```{r tcell}
tcell <- read_csv(params$tcell_csv,
                  col_types = cols(
                          `Start position` = col_integer(),
                          `End position` = col_integer(),
                          `Supporting references` = col_integer()
                  ))

predictions <- 
  read_tsv(params$predictions_tsv)

predictions %<>%
  select(
    position,
    mutation,
    Epitope,
    `Start position`,
    `End position`,
    CD4_CD8,
    HLA_prediction,
    `IC50 WT`,
    IC50_mutation,
    Fold
    ) %>%
  mutate(gene = "S", .before = 1)

tcell %<>%
  mutate(HLA_prediction = str_replace(HLA, "\\*", "")) %>%
  mutate(HLA_prediction = str_replace(HLA_prediction, "^DRB1", "DRB1_")) # %>%

nested_html <- function(summary_var){
  summary_var %>%
    unique %>%
    map(function(i) div(i, class = "nested-row")) %>%
    div(class = "nested-container") %>%
    as.character()
}

container_html <- function(summary_var){
  summary_var %>%
    map(function(i) div(HTML(i), class = "cell-row")) %>%
    div(class = "cell-container") %>%
    as.character()
}

database_tcell <-
  database_genome %>%
  filter(gene == "S") %>%
  select(gene,
         position, mutation, `numSeqs UK`, `numSeqs UK 28 days`) %>%
  fuzzy_inner_join(
    tcell,
    by = c(
      "position" = "Start position",
      "position" = "End position"),
    match_fun = list(
      `>=`, `<=`))

database_tcell_predictions <-
  database_tcell %>%
  left_join(predictions) %>%
  select(-HLA_prediction) %>%
  mutate(across(c(gene, mutation, Epitope, CD4_CD8, HLA, assay), as_factor))

database_tcell_predictions

```
## Functional
```{r functional}
functional <- 
  read_csv(params$functional_csv) 

functional %<>% 
  mutate (gene = recode(ORF, 
                        "Spike" = "S", 
                        "Nucleocapsid" = "N",
                        "Membrane" = "M",
                        "Envelope" = "E"), 
          .before = 1,
          .keep = "unused") %>% 
  mutate(HLA_prediction = str_replace(HLA, "\\*", "")) %>%
  mutate(HLA_prediction = str_replace(HLA_prediction, "^DRB1", "DRB1_"))  

database_genome_functional <-
  database_genome %>%
  select(gene, position, mutation, `numSeqs UK`, `numSeqs UK 28 days`) %>% 
  inner_join(functional)

database_functional_predictions <-
  database_genome_functional %>% 
  left_join(predictions) %>% 
  select(-HLA_prediction) %>% 
  mutate(across(c(gene, mutation, Epitope, CD4_CD8, HLA, assay), as_factor))

database_functional_predictions

bind_rows(database_tcell_predictions, database_functional_predictions) %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/database_tcell_predictions.rds"))
```



### Lineages
```{r lineage_counts}
n_uk_lineages <- 
  consortium_uk %>% 
  # filter(sample_date >= sample_date_28) %>% 
  group_by(lineage) %>%
  summarise(sequences = n(), 
            D614G = sum(d614g == "G"), 
            A222V = sum(a222v == "V"), 
            N439K = sum(n439k == "K"), 
            N501Y = sum(n501y == "Y"), 
            Y453F = sum(y453f == "F"),
            DEL_69_70 = sum(del_21765_6 == "del"), 
            N439K_DEL_69_70 = sum(n439k == "K" & del_21765_6 == "del"), 
            N501Y_DEL_69_70 = sum(n501y == "Y" & del_21765_6 == "del"),
            Y453F_DEL_69_70 = sum(y453f == "F" & del_21765_6 == "del")
  )

n_uk_lineages
```


## Antigenic
### Antigenic mutations by lineage
Would you be able to prepare a file with all the antigenic mutations (filtered from Will’s antigenic table) that have accumulated on the top of B.1.1.7 (so non lineage defining mutations) with numbers of sequences per week? We would like to prepare a heat map like the attached picture.

```{r antigenic_mutations, eval=FALSE, include=TRUE}
antigenic <- 
  antigenic_mutations_lineages() %T>% 
  write_rds(str_c("COG-UK/", params$dataset_date, "/antigenic_mutations_lineages.rds"))

antigenic
```
### Antigenic heatmap
```{r antigenic_heatmap, eval=FALSE, include=FALSE}
suppressPackageStartupMessages(library(ComplexHeatmap))
suppressPackageStartupMessages(library(circlize))

# horz_heat_original <- read.table("horz_heat.csv", row.names = 1, header = TRUE, sep = ",", stringsAsFactors = FALSE)

horz_heat <-
  antigenic_mutations_lineages() %>% 
  filter(lineage == "B.1.1.7" & variant != "N501Y") %>% 
  select(-lineage) %>% 
  inner_join(database_genome %>% 
               select(position, mutation, mab, plasma, vaccine_sera, support, domain) %>% 
               add_row(position = 243, mutation = "del243-244", mab = TRUE, plasma = NA, vaccine_sera = NA, support = "lower", domain = "NTD"), 
             by = c("variant" = "mutation")) %>%   
  mutate(across(where(is.logical), ~na_if(.x, FALSE))) %>%
  arrange(position, variant) %>% 
  mutate(across(domain, as_factor)) %>% 
  select(-position) %>% 
  rename(confidence = support) %>% 
  column_to_rownames("variant")

input <- data.matrix(horz_heat)

# define colour heatmap for frequency
col_fun = colorRamp2(c( 0, 0.015, 0.5, 2), c("white", "darkolivegreen1","darkolivegreen3","forestgreen"))

# annotation row
row_ha = rowAnnotation(
  Effect_mab = horz_heat$mab,
  Effect_plasma = horz_heat$plasma,
  Effect_vaccine = horz_heat$vaccine_sera,
  confidence = horz_heat$confidence,
  na_col = 'white',
  col = list(
    confidence = c(
      "lower" = "lightgoldenrod",
      "medium" = "lightgoldenrod3",
      "high" = "lightgoldenrod4"
    ),
    Effect_mab = c("TRUE" = "black"),
    Effect_plasma = c("TRUE" = "black"),
    Effect_vaccine = c("TRUE" = "black")
  ),
  annotation_legend_param = list(confidence = list (at = c(
    "high", "medium", "lower"
  )))
)

# domain
row_ha2 = rowAnnotation(domain = (horz_heat$domain),
                        col = list(
                          domain = c(
                            "FP" = "seashell2",
                            "NTD" = "navajowhite",
                            "RBD" = "pink",
                            "RBM" = "plum1",
                            "SP" = "lightblue1"
                          )
                        ))

# remove x from name of columns (epiweek)
# colnames(horz_heat) <- gsub("X","",colnames(horz_heat))

# pdf("heatmap.pdf", height = 10)
png("heatmap.png", height = 800, type = "cairo-png")
hm <- Heatmap(
  subset(input, select = -c(mab:domain)),
  name = "Percentage %",
  column_title = "Antigenic mutations in lineage B.1.1.7",
  use_raster = TRUE,
  cluster_columns = FALSE,
  cluster_rows = FALSE,
  row_order = order((horz_heat$domain)),
  row_split = (horz_heat$domain),
  column_names_rot = 0,
  row_gap = unit(2, "mm"),
  border = TRUE,
  width = ncol(input) * unit(1.8, "mm"),
  height = nrow(input) * unit(1.8, "mm"),
  col = col_fun,
  na_col = 'white',
  column_names_gp = grid::gpar(fontsize = 4),
  row_names_gp = grid::gpar(fontsize = 4),
  right_annotation = row_ha,
  left_annotation = row_ha2
)
hm
dev.off()
hm

# RBD1_class<-c(403, 405, 406, 408, 409, 414, 415, 416, 417, 420, 421, 449, 453, 455, 456, 457, 458, 459, 460, 473, 474, 475, 476, 477, 484, 486, 487, 489, 490, 492, 493, 494, 495, 496, 498, 500, 501, 502, 503, 504, 505)
# RBD2_class<-c(338, 339, 342, 343, 346, 351, 368, 371, 372, 373, 374, 403, 405, 406, 417, 436, 444, 445, 446, 447, 448, 449, 450, 452, 453, 455, 456, 470, 472, 473, 475, 478, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505)
# RBD3_class<-c(333, 334, 335, 337, 339, 340, 341, 342, 343, 344, 345, 346, 354, 356, 357, 358, 359, 360, 361, 438, 439, 440, 441, 442, 443, 446, 499, 500)
# RBD4_class<-c(369, 370, 371, 372, 374, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 390, 430, 431)
# NTD_class<-c(15, 18, 19, 22, 28, 74, 77, 80, 123, 136, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 157, 158, 164, 244, 246, 247, 248, 249, 250, 251, 252, 253, 255, 257, 258)

# horz_heat$RBD1 <- ifelse(horz_heat$position %in% RBD1_class, TRUE, NA)
# horz_heat$RBD2 <- ifelse(horz_heat$position %in% RBD2_class, TRUE, NA)
# horz_heat$RBD3 <- ifelse(horz_heat$position %in% RBD3_class, TRUE, NA)
# horz_heat$RBD4 <- ifelse(horz_heat$position %in% RBD4_class, TRUE, NA)
# horz_heat$NTD.1 <- ifelse(horz_heat$position %in% NTD_class, TRUE, NA)

# col_fun = colorRamp2(c( 0, 0.015, 0.5, 2), c("white", "darkolivegreen1","darkolivegreen3","forestgreen"))
# 
# row_ha= rowAnnotation(Effect_mab = horz_heat[,20], Effect_plasma = horz_heat [,21], Effect_vaccine= horz_heat [,22], confidence = horz_heat[,23],
#                         na_col = 'white', col= list(
#                         confidence = c("lower" = "lightgoldenrod", "medium" = "lightgoldenrod3", "high" = "lightgoldenrod4"),
#                         Effect_mab = c("TRUE" = "black"),
#                         Effect_plasma = c("TRUE" ="black"),
#                         Effect_vaccine = c("TRUE" = "black")),
#                       annotation_legend_param = list(confidence = list (at = c("high", "medium", "lower")))
#                       )
#                       
# row_ha2=rowAnnotation(domain = (horz_heat[,24]), Ab_class1 = (horz_heat[,30]),Ab_class2 = (horz_heat[,31]),Ab_class3 = (horz_heat[,32]),Ab_class4 = (horz_heat[,33]),Ab_classe5 = (horz_heat[,34]),
#                       na_col = 'white',
#                       width = ncol(horz_heat)*unit(0.8, "mm"),
#                       col=list(
#                       domain = c("FP" ="seashell2", "NTD"= "navajowhite", "RBD" = "pink", "RBM" = "plum1","SP"= "lightblue1"),
#                       Ab_class1 =c ("TRUE" = "lightgreen"),
#                       Ab_class2 =c("TRUE" = "goldenrod1"),
#                       Ab_class3 =c("TRUE" = "cornflowerblue"),
#                       Ab_class4 =c("TRUE" = "tomato"),
#                       Ab_class5 =c("TRUE" = "magenta")),
#                       show_legend = c(domain = FALSE, Ab_class1 = FALSE,Ab_class2 = FALSE,Ab_class3 = FALSE,Ab_class4 = FALSE,Ab_class5 = FALSE)
#                       )
#                       
# colnames(input)<-gsub("X","",colnames(input))
# 
# Heatmap(input[,2:18], name = "Percentage %", column_title = "Antigenic mutations on the top of B.1.1.7", use_raster = TRUE,cluster_columns = FALSE,
#         row_order = order((horz_heat[,24])),
#         row_split = (horz_heat[,24]),
#         column_names_rot=0,
#         row_gap = unit(2, "mm"),  border = TRUE,
#         width = ncol(input)*unit(1.8, "mm"),
#                height = nrow(input)*unit(1.8, "mm"),
#         col=col_fun,
#         na_col = 'white' ,
#               column_names_gp = grid::gpar(fontsize = 4),
#         row_names_gp = grid::gpar(fontsize = 4),
#         right_annotation = row_ha,
#         left_annotation = row_ha2
#         )

```
### ggseqlogo
```{r ggseqlogo}
wt <-
  mutation_reference_counts %>% 
  filter(gene == "S" & variant == "WT" & adm1 == "UK") %>%
  group_by(position) %>% 
  summarise(`numSeqs UK` = sum(n)) %>% 
  mutate(position = fct_drop(position) %>% fct_expand(1:1274 %>% as.character) %>% fct_inseq) %>% 
  complete(position) %>% 
  mutate(across(`numSeqs UK`, ~replace_na(.x, n_distinct(consortium_uk$sequence_name))))

library(seqinr) # NB seqinr also has a count function!
spike_sequence <- 
  read.fasta(params$spike_fasta, seqonly = TRUE) %>% 
  str_extract_all(boundary("character")) %>% 
  flatten_chr() %>% 
  c("*") # append stop codon

wt %<>% 
  add_column(AA = spike_sequence) %>% 
  mutate(across(position, as.character)) %>% 
  mutate(across(position, as.integer)) %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/wt.rds"))

wt %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/wt.rds"))
```


### mydata
```{r eval=FALSE, include=FALSE}
# library(tidyverse)
# library(magrittr)

mydata <- read_csv("mydata.csv") 

names <- 
  c("MA0018.2",
    "MA0031.1",
    "MA0139.1",
    "MA0158.1")

df <- names %>% 
    purrr::set_names() %>%
    map(function(i) 
      gather(mydata, "key", "value", starts_with(i)) %$% as.integer(value) %>% array(dim = c(4, length(.)/4))
    ) %>% as.list 

df
```

## VUI and VOC
### VUI and VOC defining mutations
```{r vui_voc}
vui_voc <-
  read_csv(params$vui_voc_csv) %>% 
  select(-gene, -details_gene, -non_syn) %>% 
  mutate(across(c(lineage, lineage_display), fct_inorder))

vui_voc %T>% write_rds(str_c("COG-UK/", "vui_voc.rds"))
```

### VUI and VOC plot
```{r lineages_plot, eval=FALSE, include=TRUE}
lineages_weeks_nations <-
  consortium_uk %>% dplyr::count(lineage, epi_week, adm1)

lineages_weeks_uk <-
  lineages_weeks_nations %>% 
  group_by(lineage, epi_week) %>% 
  summarise(across(n, sum), .groups = "drop") %>% 
  mutate(adm1 = "UK", .after = epi_week) %>% 
  bind_rows(lineages_weeks_nations) %>% 
  arrange(lineage, adm1, epi_week)
    
lineages_weeks_uk %>%
  filter(adm1 == "UK" & lineage %in% levels(vui_voc$lineage) & lineage != "B.1.1.7") %>%
  ggplot(aes(x=epi_week, y=n, group=lineage, color=lineage)) + 
  geom_line() + 
  geom_point() +
  scale_x_discrete(drop = FALSE) + # include all epi_week factor levels
  theme_classic()
```
### Constellations UpSet plot
```{r upset, eval=FALSE, include=FALSE}
mutations_s_uk_wide <-
  mutations_s_uk %>% 
  filter(lineage %in% levels(vui_voc$lineage)) %>% 
  filter(lineage %in% c("B.1.1.7", "B.1.351", "P.1")) %>% 
  mutate(logical_true = TRUE) %>% 
  pivot_wider(names_from = variant, values_from = logical_true, id_cols = c(sequence_name, variant), values_fill = FALSE)

mutations_s_uk_wide
```
### VUI/VOC/other
```{r vui_voc_other}
# convert Delta and Omicron sublineages to parent for counting
consortium_uk_parent <-
  bind_rows(
    # convert AY.x sublineages to parent B.1.617.2
    # convert BA.1.x sublineages to parent BA.1
    consortium_uk %>%
      mutate(lineage = gsub(sublineage_regex_gsub("AY"), "B.1.617.2", lineage)) %>% # convert AY.x to B.1.617.2
      mutate(lineage = gsub(sublineage_regex_gsub("BA.1"), "BA.1", lineage)), # convert BA.1.x to BA.1
  
    # filter AY.4 and sublineages then convert AY.4.x sublineages to parent AY.4 
    consortium_uk %>% 
      filter(lineage == "AY.4" | str_starts(lineage, fixed("AY.4."))) %>% 
      mutate(lineage = "AY.4"),
  
    # filter AY.4.2 and sublineages then convert any AY.4.2 sublineages to parent AY.4.2
    consortium_uk %>% 
      filter(lineage == "AY.4.2" | str_starts(lineage, fixed("AY.4.2."))) %>% 
      mutate(lineage = "AY.4.2"),
    
    # Delta non-AY.4
    consortium_uk %>% filter(( lineage == "B.1.617.2" | str_starts(lineage_full, fixed("B.1.617.2.")))
                             & lineage != "AY.4" 
                             & !str_starts(lineage, fixed("AY.4."))) %>% 
      mutate(lineage = "Delta_minus_AY.4"),
    
    # Delta non-AY.4.2
    consortium_uk %>% filter(( lineage == "B.1.617.2" | str_starts(lineage_full, fixed("B.1.617.2.")))
                             & lineage != "AY.4.2" 
                             & !str_starts(lineage, fixed("AY.4.2."))) %>% 
      mutate(lineage = "Delta_minus_AY.4.2")
  ) 

# count sequences by day
lineages_days_uk_all <- 
  bind_rows(
    consortium_uk_parent %>% 
      dplyr::count(lineage, sample_date, adm1, name = "n_day"),
    
    consortium_uk_parent %>% 
      dplyr::count(lineage, sample_date, name = "n_day") %>% 
      mutate(adm1 = "UK") %>% 
      mutate(across(adm1, as_factor))
  )

# by week
lineages_weeks_uk_all <- bind_rows(
 consortium_uk_parent %>% 
   dplyr::count(lineage, epi_date, adm1, name = "n_week"),
 
 consortium_uk_parent %>% dplyr::count(lineage, epi_date, name = "n_week") %>% 
   mutate(adm1 = "UK") %>% 
   mutate(across(adm1, as_factor))
)
 
lineages_days_uk_all %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/lineages_days_uk_all.rds"))
lineages_weeks_uk_all %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/lineages_weeks_uk_all.rds"))
```
## GISAID
```{r gisaid, eval=FALSE, include=TRUE}
# GISAID Delta sequences
gisaid <- 
  read_csv("6_seqmuts_ale.txt", 
           col_names = 
              c("sequence_name",
              "gisaid_id",
              "lineage", 
              "sample_date",
              "epi_week",
              "country",
              "region",
              "mutations")
  ) %>% 
  drop_na(sample_date) %>% # exclude sequences with missing sample date
  distinct

epi_levels_gisaid <- 
  min(gisaid$epi_week):max(gisaid$epi_week) %>% as.character

gisaid %<>% 
  mutate(across(c(epi_week), as_factor)) %>%
  mutate(epi_week = fct_expand(epi_week, epi_levels_gisaid) %>% fct_inseq) # expand factor levels to include any missing weeks


# All genes mutations and deletions
mutations_gisaid <-
  gisaid %>% 
  separate_rows(mutations, sep = '\\|') %>% 
  filter(mutations != "") %>% # trailing '|' generates empty string
  separate(mutations, into = c("gene", "variant"), sep = ':') %>% 
  distinct 

# S gene mutations and deletions
mutations_s_all_gisaid <- 
  mutations_gisaid %>% 
  filter(gene == "S") %>% 
  mutate(position = parse_number(variant))

# S gene del243-244
dels_s_gisaid <- 
  mutations_s_all_gisaid %>% 
  filter(str_detect(variant, "del") & (position == 243)) %>% 
  semi_join(mutations_s_all_gisaid %>% # sequences with both del243 and del244
              filter(str_detect(variant, "del") & (position == 244)),
            by = c("sequence_name", "gisaid_id", "lineage", 
                   "sample_date", "epi_week", "country", "region", "gene")) %>% 
  mutate(variant = "del243-244")
  
# defining mutations of delta variant
defining_delta <- 
        vui_voc %>% 
        filter(lineage == "B.1.617.2") %$% 
        mutation

# S gene mutations minus defining plus del243-244
mutations_s_gisaid <- 
  mutations_s_all_gisaid %>% 
  filter(!str_detect(variant, "del")) %>%  # remove deletions
  filter(!(variant %in% defining_delta)) %>% # remove Delta defining mutations
  bind_rows(dels_s_gisaid)  # bind del243-244

mutations_s_gisaid
#   mutate(across(c(gene, position, variant), as_factor)) %T>% 

```
### GISAID antigenic
```{r eval=FALSE, include=TRUE}

sequences_by_week_gisaid <- 
    gisaid %>% 
    dplyr::count(epi_week, name = "n_sequences_lineage")

# S gene escape mutations
escape_mutations <-
  database_genome %>%
  filter(!is.na(escape)) %$% 
  mutation 
  
antigenic_mutations_gisaid <- 
    mutations_s_gisaid %>% 
    filter(variant %in% escape_mutations | variant == "del243-244") %>% 
    dplyr::count(variant, epi_week, sort = TRUE) 

antigenic_mutations_gisaid_all <- 
  inner_join(antigenic_mutations_gisaid, sequences_by_week_gisaid) %>% 
  mutate(percentage = n / n_sequences_lineage * 100 ) %>% 
   complete(epi_week, nesting(variant), fill = list(n = 0, n_sequences_lineage = 0, percentage = 0)) %>%
    mutate(epi_week = epi_week %>% as.character %>% as.integer)

first_occurrence_gisaid <- 
    antigenic_mutations_gisaid_all %>% 
    filter(n > 0) %$% 
    min(epi_week)

antigenic_mutations_gisaid_all %<>%
  filter(epi_week >= first_occurrence_gisaid) %>%
  inner_join(epi_lookup) %>% 
  pivot_wider(names_from = epi_date, values_from = percentage, names_sort = TRUE, values_fill = 0, id_cols = variant) 

png("gisaid_delta.png",width=750, height=1300, units="px", type = "cairo-png")
antibody_complex_heatmap(antigenic_mutations_gisaid_all)
dev.off()

antigenic_mutations_gisaid_all
```
## Geo
```{r geo}
# TOPOJSON objectid
# 1 North East (England)
# 2 "North West (England)"
# 3 Yorkshire and The Humber
# 
# 4 East Midlands (England)
# 5 West Midlands (England)
# 6 East of England
# 
# 7 London
# 8 South East (England)
# 9 South West (England)
# 
# 10 Wales
# 11 Scotland
# 12 Northern Ireland
# 

# NUTS1 categories from consortium_uk in same order 
NUTS1 <- c( 
"North_East",               
"North_West",     
"Yorkshire_And_The_Humber",

"East_Midlands"            ,
"West_Midlands"            ,
"East_Of_England"          ,

"Greater_London"           ,
"South_East"               ,
"South_West"               ,

"Wales"        ,
"Scotland"      ,           
"Northern_Ireland"         
) 

NUTS1_objectid <- tibble(NUTS1, objectid = 1:length(NUTS1))

# count regional total sequences by week for calculation of percentage
geo <- 
  consortium_uk %>% 
  filter(!is.na(NUTS1)) %>% 
  dplyr::count(epi_week, NUTS1, .drop = FALSE) 

# regional counts for all variants with NUTS1 data
geo_variants <- bind_rows(
  # Delta and Omicron
  consortium_uk %>%
  filter(!is.na(NUTS1)) %>% 
  mutate(lineage = gsub(sublineage_regex_gsub("AY"), "B.1.617.2", lineage)) %>%  # convert AY.x lineages to B.617.2
  mutate(lineage = gsub(sublineage_regex_gsub("BA.1"), "BA.1", lineage)) %>%  # convert BA.1.x lineages to BA.1  
  mutate(across(lineage, as_factor)) %>%
  mutate(lineage = fct_other(lineage, 
                             keep = 
                               vui_voc %$% 
                               levels(lineage) %>% 
                               str_subset("^AY\\.", negate = TRUE))) %>% # convert non-VUI/VOC lineages to "Other"
  dplyr::count(epi_week, NUTS1, lineage, name = "n_week", .drop = FALSE), # TODO count AY lineages / Other Delta

  # AY.4
  consortium_uk %>%
    filter(!is.na(NUTS1)) %>%
    filter(lineage_full == "B.1.617.2" | str_starts(lineage_full, fixed("B.1.617.2."))) %>% # filter Delta only
    mutate(lineage = gsub(sublineage_regex_gsub("AY.4"), "AY.4", lineage)) %>%  # recode AY.4.x to AY.4
    mutate(lineage = fct_other(lineage, keep = "AY.4", other_level = "Delta_minus_AY.4")) %>%  # convert Delta non-AY.4/AY.4.x lineages to other Delta
    dplyr::count(epi_week, NUTS1, lineage, name = "n_week", .drop = FALSE),
  
  # AY.4.2
  consortium_uk %>%
    filter(!is.na(NUTS1)) %>%
    filter(lineage_full == "B.1.617.2" | str_starts(lineage_full, fixed("B.1.617.2."))) %>% # filter Delta only
    mutate(lineage = gsub(sublineage_regex_gsub("AY.4.2"), "AY.4.2", lineage)) %>%  # recode AY.4.2.x to AY.4.2
    mutate(lineage = fct_other(lineage, keep = "AY.4.2", other_level = "Delta_minus_AY.4.2")) %>%  # convert Delta non-AY.4.2/AY.4.x lineages to other Delta
    dplyr::count(epi_week, NUTS1, lineage, name = "n_week", .drop = FALSE)
)
    
geo_all <- 
  dplyr::inner_join(geo, geo_variants) %>%
  dplyr::mutate(across(epi_week, as.character)) %>%
  dplyr::mutate(across(epi_week, as.integer))

# calculate first week
earliest_voc_vui <- 
  geo_all %>% 
  filter(lineage != "Other" & n_week > 0) %$%
  min(epi_week)

geo_all %<>% 
  filter(epi_week >= earliest_voc_vui) %>% 
  dplyr::inner_join(epi_lookup) %>% 
  dplyr::mutate(Proportion = ifelse(n==0, 0, n_week / n * 100)) %>%  # keep zero counts for rendering 
  dplyr::select(-n) %>%
  dplyr::inner_join(NUTS1_objectid) %>% 
  dplyr::rename(Count = n_week) %T>%
  write_rds(str_c("COG-UK/", params$dataset_date, "/geo_all.rds"))

geo
geo_variants
geo_all
```
## MAP
### Geo distribution - run once
```{r geo_map_variant_alias, eval=FALSE, include=TRUE}
# Shapefile: NUTS Level 1 (January 2018) Ultra Generalised Clipped Boundaries in the United Kingdom
# https://data.gov.uk/dataset/37edc0ad-ffff-47c9-a01c-cb8d6123ec79/nuts-level-1-january-2018-ultra-generalised-clipped-boundaries-in-the-united-kingdom

# Convert shapefile to dataframe for ggplot2
# Run once locally and transfer mapdata RDS file to web server
# Uses packages rgdal and broom - not required on CLIMB
# Requires packages rgeos, maptools, rgdal, broom
# On Linux, install rgeos before rgdal

# Reshape for ggplot2 using the Broom package
mapdata <- 
  rgdal::readOGR(dsn = "COG-UK/Maps/", layer = "NUTS_Level_1_(January_2018)_Boundaries") %>%  # Load shapefile
  broom::tidy(region="nuts118nm") %>% # Convert shapefile to dataframe
  mutate(id = recode(id, # recode from NUTS1 categories in consortium_uk to NUTS1 names in map
                                            "East Midlands (England)" = "East_Midlands",
                                            "East of England"= "East_Of_England" ,     
                                            "London" = "Greater_London",               
                                            "North East (England)"= "North_East",     
                                            "North West (England)"= "North_West",     
                                            "Northern Ireland" = "Northern_Ireland",        
                                            "South East (England)" = "South_East",    
                                            "South West (England)" = "South_West",  
                                            "West Midlands (England)" = "West_Midlands",
                                            "Yorkshire and The Humber" = "Yorkshire_And_The_Humber")) %>% 
  dplyr::rename("NUTS1" = "id") %>% 
  write_rds(str_c("COG-UK/mapdata.rds"))

mapdata
```
### Antigenic and map
```{r geo_map_antigenic_alias, eval=FALSE, include=FALSE}
# del243-244 sample IDs
del_22289_6_samples <- 
  deletions %>% 
  filter(
    (ref_start == 22289 & length == 6) 
  ) %$% samples 

# Antigenic deletion del243-244 22289-22294 (6nt) by region 
del_22289_6_regions <- 
  consortium_uk %>% 
  filter(!is.na(NUTS1)) %>%
  filter(sequence_name %in% del_22289_6_samples) %>% 
  dplyr::count(epi_week, lineage, NUTS1, name = "n_sequences_lineage", .drop = FALSE) %>% 
  mutate(variant = "del243-244", .before = 1)

sequences_by_week_regions <- 
  consortium_uk %>% 
  filter(!is.na(NUTS1)) %>%
  dplyr::count(epi_week, lineage, NUTS1, name = "n", .drop = FALSE) # count total sequences per epiweek/lineage/NUTS1

escape_mutations <- 
  database_genome %>%
  filter(gene == "S" & !is.na(escape)) %$% 
  mutation # filter escape mutations from database

antigenic_mutations <- 
  mutations_uk %>% 
  filter(!is.na(NUTS1)) %>% 
  filter(variant %in% escape_mutations) %>% 
  filter(sequence_name != "England/NEWC-2729532/2021") %>% # remove Delta outlier from January 2021
  dplyr::count(variant, epi_week, lineage, NUTS1, name = "n_sequences_lineage", .drop = FALSE) # count specific variant carry a specific mutation per epiweek and NUTS1

antigenic_mutations <- bind_rows(antigenic_mutations,del_22289_6) # bind with deletion data

antigenic_mutations_lineages_all <- 
  inner_join(antigenic_mutations, sequences_by_week_lineages) %>% 
  mutate(percentage = ifelse(n==0, 0, n_sequences_lineage  / n * 100)) # calculate proportion

antigenic_mutations_lineages_all$variant <- as.factor(antigenic_mutations_lineages_all$variant)

# antigenic_mutations_lineages_all %>% mutate(variant, fct_expand(variant, "All"))
antigenic_mutations_lineages_all$epi_week <- as.character(antigenic_mutations_lineages_all$epi_week)
antigenic_mutations_lineages_all$epi_week <- as.numeric(antigenic_mutations_lineages_all$epi_week)
antigenic_mutations_lineages_all <- dplyr::inner_join(antigenic_mutations_lineages_all, epi_lookup)
antigenic_mutations_lineages_all <- dplyr::rename(antigenic_mutations_lineages_all, "Count" = "n_sequences_lineage")
antigenic_mutations_lineages_all <- dplyr::rename(antigenic_mutations_lineages_all, "Proportion" = "percentage")
antigenic_mutations_lineages_all <- antigenic_mutations_lineages_all %>% 
  mutate(lineage = fct_other(lineage, keep = vui_voc %$% levels(lineage))) %>%
  filter(!is.na(NUTS1) & !is.na(lineage)) 

antigenic_mutations_lineages_all %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/antigenic_mutations_lineages_all.rds"))

```

## ISARIC
### Alias
```{r isaric_alias, eval=FALSE, include=FALSE}
library(jsonlite)
alias_key <- fromJSON("https://raw.githubusercontent.com/cov-lineages/pango-designation/master/pango_designation/alias_key.json")

alias_key %<>% 
  keep(~ length(.x) == 1) %>% # drop recombinants
  purrr::discard(~ .x == "") # drop top level lineages

# TODO mutate full lineage in initial consortium read instead
consortium_full <- 
  consortium_uk %>% 
  mutate(lineage_full = lineage, .after = lineage)

mutations_full <- 
  mutations_uk %>% 
  mutate(lineage_full = lineage, .after = lineage)

for (i in 1:length(alias_key)) {
  consortium_full <<- 
    consortium_full %>% 
    mutate(lineage_full = str_replace(lineage_full, str_c("^", names(alias_key)[i], "(?=\\.)"), str_c(alias_key[[i]])))
  
  mutations_full <<- 
    mutations_full %>% 
    mutate(lineage_full = str_replace(lineage_full, str_c("^", names(alias_key)[i], "(?=\\.)"), str_c(alias_key[[i]])))
}
```
### Filter
```{r isaric}
# source("COG-UK/out_frame_del.R")
# source("COG-UK/wuhan_ref_aa.R")

message("Reading ISARIC list file ", params$isaric_csv)
isaric_list <- read_csv(params$isaric_csv)

# iterate through isaric_list row by row
isaric_dfr <-
  isaric_list %>%
  pmap_dfr(function(...) {
    current <- tibble(...) # current row of isaric_list
    
    output <- tibble()
    
    if (is.na(current$Mutation)) { # if no mutations then search consortium 
      if (!is.na(current$Lineage)) {
        
        # filter by lineage and wildcard
        if (str_ends(current$Lineage, fixed("*"))) { # filter sublineages if wildcard
          lineage_prefix <- str_sub(current$Lineage, 1, nchar(current$Lineage) - 1)
          
          output <-
            consortium_uk %>%
            filter(if_any(c(lineage, lineage_full), ~ str_starts(.x, fixed(lineage_prefix)))) %>%   # use fixed because dot is regex special character
            select(sequence_name, cog_id, sample_date, lineage, lineage_full)
          
        } else { # no wildcard - filter exact lineage
          output <-
            consortium_uk %>%
            filter(lineage_full == current$Lineage |
                     lineage == current$Lineage) %>% 
            select(sequence_name, cog_id, sample_date, lineage, lineage_full)
        }
        
        if(!is.na(current$Lineage_filter_out)){
          filters <- str_split(current$Lineage_filter_out, fixed("|"))
          # TODO (no examples at present)
        }
      } 
    } else { # filter deletion/insertion/mutation
     gene_mutation <- 
       str_split(current$Mutation, ":") %>% 
       unlist # split gene:mutation

      if(str_starts(gene_mutation[2], "del|ins")){ # deletion or insertion - look up consortium
        output <- consortium_uk
      } else{ # mutation
        output <- mutations_uk
      }

      # filter by lineage
      if(!is.na(current$Lineage)){
        if (str_ends(current$Lineage, fixed("*"))) { # filter sublineages if wildcard
          lineage_prefix <- str_sub(current$Lineage, 1, nchar(current$Lineage) - 1)

          output %<>%
            filter(if_any(c(lineage, lineage_full), ~ str_starts(.x, fixed(lineage_prefix))))
        } else { # no wildcard - filter exact lineage
          output %<>%
            filter(lineage == current$Lineage)
        }
      }

      # filter out lineage
      if(!is.na(current$Lineage_filter_out)){
        excludes <- 
          current$Lineage_filter_out %>% 
          str_split(fixed("|")) %>% 
          unlist
        
        walk(excludes, function(x){
          if(str_ends(x, fixed("*"))){ # if wildcard
            lineage_prefix <- str_sub(x, 1, nchar(x) - 1)

            output <<-
              output %>%
              filter(if_all(c(lineage, lineage_full), ~ !str_starts(.x, fixed(lineage_prefix))))

          } else { # else exact lineage
            output <<-
              output %>%
              filter(if_all(c(lineage, lineage_full), ~ .x != x))
          }
        })
        
      }

      if(str_starts(gene_mutation[2], "del")){ # deletion - look up consortium 
        #TODO calculate genome coordinates from aa positions
        #TODO in frame only?
        #TODO gene name
        
        dels <-
          deletions %>% 
          filter(between(ref_start, 22283, 22294)) %>% 
          mutate(gene = "S", variant = str_c("del_", ref_start, "_", length)) %>% 
          select(-ref_start, -length)

        # del_22289_6 is del243-244
        # S:del241-243 is del_22283_9
        # S:del242-244 is del_22286_9
        # 22283, 22286, 22289 and 22292 ( to 22294 ?)
        
        output %<>% 
          select(sequence_name, cog_id, sample_date, lineage, lineage_full) %>% 
          inner_join(dels, by = c("sequence_name" = "samples"))
      } else if(gene_mutation[1] == "S" & str_starts(gene_mutation[2], "ins")){ # insertion - look up consortium
        # Spike genomic coordinates 21563..25384 
        # TODO in frame only
        
        ins_samples <- 
          insertions %>% 
          # filter(str_length(insertion) %% 3 == 0) %>% 
          filter(ref_start >= 21563 & ref_start < 25384) %>%  # Spike coordinates 21563 to 25384 
          filter(!str_detect(insertion, "N")) %>% # exclude any insertions with uncalled nucleotides
          mutate(gene = "S", variant = str_c("ins_", ref_start, "_", insertion), .keep = "unused") 

        output %<>% 
          select(sequence_name, cog_id, sample_date, lineage, lineage_full) %>% 
          inner_join(ins_samples, by = c("sequence_name" = "samples"))
      } else { # mutation - look up mutations
          
          if(str_ends(gene_mutation[2], "X")){ # mutation wildcard
            output %<>% filter(gene == gene_mutation[1] & position == parse_number(gene_mutation[2]))
          } else { # exact match of mutation
            output %<>% filter(gene == gene_mutation[1] & variant == gene_mutation[2])
          }

        output %<>% select(sequence_name, cog_id, sample_date, lineage, lineage_full, gene, variant)
     }

    }
    
    output %>% mutate(query_id = current$ID)
  })# %>% distinct

isaric_dfr
```
### Compare
```{r isaric_compare}
# list isaric TSV files
isaric_files <- list.files(pattern = "isaric_.*_cumulative\\.tsv") 
  
# extract dates from filenames  
isaric_dates <-
  isaric_files %>% 
  str_extract("\\d{4}-\\d{2}-\\d{2}") %>% 
  parse_date

# get most recent date
isaric_previous <- isaric_dates[isaric_dates < params$dataset_date]
isaric_latest <- NULL
if(length(isaric_previous > 0)){ # previous datasets exist
  message("Reading most recent ISARIC cumulative file")
  isaric_recent <- 
    isaric_previous %>% 
    max %>% 
    grep(isaric_files) %>% 
    isaric_files[.] %>% 
    print %>%
    read_tsv() %>% 
    separate_rows(query_id, sep = ",") %>% 
    mutate(query_id = as.numeric(query_id)) 
  
  isaric_latest <- 
    anti_join(isaric_dfr, isaric_recent, by = c("cog_id", "query_id"))
}

isaric_latest
```

### Collapse
```{r isaric_collapse}
collapse_isaric <- function(isaric_hits){
  isaric_hits %>% 
  mutate(gene_variant = str_c(gene, ":", variant), .keep = "unused") %>% 
  group_by(cog_id, sample_date, lineage) %>% 
  summarise(mutations = toString(str_c(gene_variant)), query_id = toString(query_id), .groups = "drop") %>% 
  arrange(desc(sample_date), lineage, cog_id)
}

if(!is.null(isaric_latest)){
  isaric_latest_collapse <- 
    isaric_latest %>% 
    collapse_isaric %T>% 
    write_tsv(str_c("isaric_", params$dataset_date, "_latest.tsv") %T>% message("Writing ", .))
  
  isaric_latest_collapse
}

isaric_dfr_collapse <- 
  isaric_dfr %>% 
  collapse_isaric %T>% 
  write_tsv(str_c("isaric_", params$dataset_date, "_cumulative.tsv") %T>% message("Writing ", .))

isaric_dfr_collapse
```
## Ronapreve plot
```{r ronopreve_plot}
source("mab_upset_regeneron.R")
ronapreve_upset <- generate_upset()
ronapreve_upset_28 <- generate_upset(filter_date = sample_date_28)

png(filename=str_c("COG-UK/", params$dataset_date, "/Ronapreve.png"), width=1800, height=975, type = "cairo-png")
ronapreve_upset
dev.off()

png(filename = str_c("COG-UK/", params$dataset_date, "/Ronapreve_28.png"), width=1800, height=975, type = "cairo-png")
ronapreve_upset_28
dev.off()

# ronapreve_upset
# ronapreve_upset_28

```

## Spike profiles for table/plots
```{r spike_profiles}
source("spike_profiles.R")
viruses <- virus_profiles(mutation_df = mutations_uk)
spike_tab <- spike_profiles_nations(viruses)
write_rds(viruses, str_c("COG-UK/", params$dataset_date, "/spike_viruses.rds"))
write_rds(spike_tab, str_c("COG-UK/", params$dataset_date, "/spike_table.rds"))
```
# RDS check
```{r rds_check}
# TODO Check that RDS files can be read
# filedata <- map(filenames, function(x){print(x); read_rds(x)} )
```

## Done
```{r success}
message("PIPELINE COMPLETED")
```