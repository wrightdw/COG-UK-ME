---
title:  "COG-UK Mutations"
output: html_notebook
params: 
  latest:           TRUE # TRUE to copy latest files on CLIMB to working directory, overrides dataset_date with today()
  dataset_date:     "" # if empty, defaults to today's date, otherwise enter date string
  spike_csv:        "spike_escape_info.csv"
  spike_extra_csv:  "spike_escape_extra.csv"
  tcell_csv:        "tcell_long.csv"
  deletions_tsv:    "cog.deletions.tsv"
  predictions_tsv:  "Prediction_from_Morten.txt"
  spike_fasta:      "sequence.fasta"
  vui_voc_csv:      "VUI and VOC.csv"
  remdesivir_dir:   "Remdesivir Mutants" 
  isaric_csv:       "Isaric_list.csv"
  insertions_tsv:   "cog.insertions.tsv"
  functional_csv:   "tcell_functional_mutations.csv"
---
# Setup
```{r setup}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(magrittr))
library(wesanderson)
library(RColorBrewer)
suppressPackageStartupMessages(library(lubridate))
library(fuzzyjoin)
library(htmltools)
suppressPackageStartupMessages(library(jsonlite))
# also require seqinr - loaded later on to avoid name clash of dplyr count function
library(UpSetR)
```
```{r climb}
Sys.setenv(TZ="Europe/London")

if(params$latest){ # copy today's files to working directory on CLIMB, stop if process run previously or today's files not available yet
  
  # check files exist
  params$dataset_date <- today()
  latest_dir <- "/cephfs/covid/bham/results/msa/latest"
  consortium_csv <- str_c("cog_global_", params$dataset_date, "_consortium.csv")
  consortium_today_msa <- file.path(latest_dir, "metadata", consortium_csv)
  
  if(!file.exists(consortium_csv) && # file not already copied
     file.exists(consortium_today_msa)){ # MSA file exists
    
    # copy consortium and deletions to working directory
    message("Copying latest consortium and deletions files")
    file.copy(consortium_today_msa, getwd())
    
    # deletions and insertions files not named by date so overwrite previous
    file.copy(file.path(latest_dir, "cog", params$deletions_tsv), getwd(), overwrite = TRUE) 
    file.copy(file.path(latest_dir, "cog", params$insertions_tsv), getwd(), overwrite = TRUE) 
  } else {
    stop(str_c(consortium_today_msa, " does not exist or already copied")) # terminate script
  }  
  
} else {
  if(params$dataset_date == ""){
    params$dataset_date <- today()
  } else {
    params$dataset_date %<>% as.Date
  }
  
  consortium_csv <- str_c("cog_global_", params$dataset_date, "_consortium.csv")
}

dir.create(str_c("COG-UK/", params$dataset_date))
```

# Consortium
## Read
```{r consortium_read, include=FALSE}
message("Reading ", consortium_csv)
consortium_uk <- 
  read_csv((consortium_csv), col_types = cols(.default = col_character())) %>% 
  filter(country == "UK" & !is.na(adm1) & adm1 %in% (c("England", "Scotland", "Wales", "Northern_Ireland"))) %>% # exclude Crown dependencies and British Overseas Territories
  select(-gisaid_id, -submission_org_code, -root_sample_id, -(adm2:travel_history), NUTS1,
         -lineages_version, -country, 
         -received_date, -collection_date, -published_date, -starts_with("scorpio"), 
         -lineage_conflict, -lineage_ambiguity_score, -sequencing_org_code, -submission_user
         ) %>% # remove unused columns
  relocate(NUTS1,.after = adm1) %>% 
  type_convert 

# Epidemic week / Sunday date conversion
epi_lookup <-
  tibble(
    epi_date = seq(from = ymd("2020-01-26"), to = consortium_uk %$% max(sample_date), by = "week"),
    epi_week = seq(consortium_uk %$% min(epi_week), consortium_uk %$% max(epi_week))
  ) 
# %T>% # lookup table of epi_week and Sunday date
#   write_rds(str_c("COG-UK/", params$dataset_date, "/epi_lookup.rds"))

epi_levels <- min(consortium_uk$epi_week):max(consortium_uk$epi_week) %>% as.character

consortium_uk %<>% 
  inner_join(epi_lookup) %>% 
  relocate(epi_date, .after = epi_week) %>% 
  mutate(across(c(epi_week, adm1, NUTS1), as_factor)) %>%
  mutate(epi_week = fct_expand(epi_week, epi_levels) %>% fct_inseq) # expand factor levels to include any missing weeks

 # Temporary fix - exclude duplicate Delta sequences with incorrect dates in April 2020
dodgy_delta <- 
  consortium_uk %>% 
  filter(lineage == "B.1.617.2" & epi_week %in% c(16, 17))

consortium_uk %<>% anti_join(dodgy_delta)

consortium_uk
```
## 28 days
```{r consortium_constants, include=FALSE}
sample_date_28 <- max(consortium_uk$sample_date) - days(27) # calculate 28 day period up to and including latest sample date
message("28 days date: ", sample_date_28)
```
## Alias
```{r consortium_alias, include=FALSE}
message("Looking up PANGO designation lineage alias key on GitHub")
# reconstruct lineage full names from alias JSON
alias_key <- fromJSON("https://raw.githubusercontent.com/cov-lineages/pango-designation/master/pango_designation/alias_key.json")

alias_key %<>% 
  keep(~ length(.x) == 1) %>% # drop recombinants
  purrr::discard(~ .x == "") # drop top level lineages

# copy lineage column
consortium_uk %<>% 
  mutate(lineage_full = lineage, .after = lineage)

# overwrite aliases with full lineage names
for (i in 1:length(alias_key)) {
  consortium_uk <<- 
    consortium_uk %>% 
    mutate(lineage_full = str_replace(lineage_full, str_c("^", names(alias_key)[i], "(?=\\.)"), str_c(alias_key[[i]])))
}

consortium_uk
```
## Write
```{r consortium_write}
mutations_uk <- 
  consortium_uk %>% 
  select(sequence_name, cog_id, sample_date, epi_week, epi_date, lineage, lineage_full, adm1, mutations) %>% 
  distinct # get rid of identical variant calls

message("Writing consortium_uk.rds")
consortium_uk %<>% 
  select(-mutations) %>% 
  distinct %T>% # remove duplicates
  write_rds(str_c("COG-UK/", params$dataset_date, "/consortium_uk.rds"))

consortium_uk
```
# Mutations
```{r mutations_consortium}
mutations_uk %<>%    
  separate_rows(mutations, sep = '\\|') %>% 
  separate(mutations, into = c("gene", "variant"), sep = ':') %>% 
  drop_na() %>%
  filter(gene != "synSNP") %>%
  mutate(position = parse_number(variant)) %>% 
  mutate(across(c(gene, position, variant), as_factor)) %T>% 
  write_rds(str_c("COG-UK/", params$dataset_date, "/mutations_uk.rds"))

# exclude duplicate delta variants with incorrect dates in April 2020
dodgy_delta_mutations <- 
  mutations_uk %>% 
  filter(lineage == "B.1.617.2" & epi_week %in% c(16, 17))

mutations_uk
```
## Mutation / REF counts
```{r mutations_refs}
#### UK ### 
genes_positions <- 
  mutations_uk %>% 
  distinct(gene, position) # gene / position combinations actually found in mutations

sequences_by_week <- 
  consortium_uk %>% 
  dplyr::count(epi_week, epi_date, name = "n_sequences")

positions_by_week <- 
  mutations_uk %>%
  dplyr::count(epi_week, epi_date, gene, position, .drop = FALSE, name = "n_variant_sequences") # count all possible epi_week/gene/position combinations 

reference_counts <- 
  positions_by_week %>%
  inner_join(genes_positions) %>% # remove gene / position combinations not found in mutations
  inner_join(sequences_by_week) %>% 
  mutate(n = n_sequences - n_variant_sequences, variant = "WT", .keep = "unused") %>% # calculate reference / other
  filter(n > 0) %>%  # remove zero WT entries (where all sequences are variants for an epi_week / position combo)
  mutate(adm1 = "UK")

mutation_counts <- 
  mutations_uk %>%
  dplyr::count(epi_week, epi_date, gene, position, variant) %>% 
  mutate(adm1 = "UK")

#### Nations ####
sequences_by_week_nations <-
  consortium_uk %>%
  dplyr::count(epi_week, epi_date, adm1, name = "n_sequences")

positions_by_week_nations <-
  mutations_uk %>%
  dplyr::count(epi_week, epi_date, gene, position, adm1, .drop = FALSE, name = "n_variant_sequences") # count all possible epi_week/gene/position/nation combinations

reference_counts_nations <- 
  positions_by_week_nations %>%
  inner_join(genes_positions) %>% # remove gene / position combinations not found in mutations
  inner_join(sequences_by_week_nations) %>% 
  mutate(n = n_sequences - n_variant_sequences, variant = "WT", .keep = "unused") %>% # calculate reference / other
  filter(n > 0) # remove zero WT entries (where all sequences are variants for an epi_week / position combo)

mutation_counts_nations <- 
  mutations_uk %>%
  dplyr::count(epi_week, epi_date, gene, position, variant, adm1)

mutation_reference_counts <- 
  bind_rows(mutation_counts, reference_counts, mutation_counts_nations, reference_counts_nations) %>% 
  mutate(across(variant, as_factor)) %T>% 
  write_rds(str_c("COG-UK/", params$dataset_date, "/mutation_reference_counts.rds"))

mutation_reference_counts
```
## Total sequences per epidemic week
```{r consortium_counts, eval=FALSE, include=FALSE}
n_uk <- 
  consortium_uk %>% 
  # filter(sample_date >= 2020-11-13) %>% 
  # filter(epi_week < 50) %>%
  group_by(epi_week) %>%
  summarise(sequences = n(), D614G = sum(d614g == "G"), A222V = sum(a222v == "V"), 
            N439K = sum(n439k == "K"), N501Y = sum(n501y == "Y"), DEL_69_70 = sum(del_21765_6 == "del")) #%>%
            # mutate_at(vars(D614G:DEL_69_70), cumsum) # cumulative counts
            # mutate_at(vars(sequences:DEL_69_70), cumsum) # cumulative counts to normalise against cumulative sequences

n_uk
```

```{r eval=FALSE, include=FALSE}
n_uk %>% 
  select(-epi_week) %>% 
  summarise_all(funs(sum))
```

```{r eval=FALSE, include=FALSE}
n_uk_28 <- 
  consortium_uk %>% 
  filter(sample_date >= sample_date_28) %>%
  group_by(epi_week) %>%
  summarise(sequences = n(), D614G = sum(d614g == "G"), A222V = sum(a222v == "V"), 
            N439K = sum(n439k == "K"), N501Y = sum(n501y == "Y"), DEL_69_70 = sum(del_21765_6 == "del"))
n_uk_28
```
```{r eval=FALSE, include=FALSE}
n_uk_28 %>% 
  select(-epi_week) %>% 
  summarise_all(funs(sum))
```

```{r eval=FALSE, include=FALSE}
theme_set(theme_classic() + theme(legend.position = "none"))

pal <- wes_palette("Cavalcanti1", type = "discrete")
update_geom_defaults("point", list(color = pal[1]))
update_geom_defaults("line", list(color = pal[1]))

 ggplot(n_uk, aes(x = epi_week, y = sequences)) + 
  geom_line() + geom_point() + labs(x = "Epidemic week", y = "Sequences", title = "Sequences per Week")

 ggsave("Sequences.png")
```
```{r eval=FALSE, include=FALSE}
pal <- brewer.pal(n = 5, name = "Set1")
update_geom_defaults("point", list(color = pal[2]))
update_geom_defaults("line", list(color = pal[2]))

 ggplot(n_uk, aes(x = epi_week, y = D614G / sequences)) + 
  geom_line() + geom_point() + labs(x = "Epidemic week", y = "D614G (normalised)", title = "D614G") + ylim(0,1)
 ggsave("D614G.png")

```

```{r eval=FALSE, include=FALSE}
update_geom_defaults("point", list(color = pal[1]))
update_geom_defaults("line", list(color = pal[1]))

 ggplot(n_uk, aes(x = epi_week, y = A222V / sequences)) + 
  geom_line() + geom_point() + labs(x = "Epidemic week", y = "A222V (normalised)", title = "A222V") + ylim(0,1)
 ggsave("A222V.png")

```
```{r eval=FALSE, include=FALSE}
update_geom_defaults("point", list(color = pal[4]))
update_geom_defaults("line", list(color = pal[4]))

 ggplot(n_uk, aes(x = epi_week, y = N439K / sequences)) + 
  geom_line() + geom_point() + labs(x = "Epidemic week", y = "N439K (normalised)", title = "N439K") + ylim(0,1)
 ggsave("N439K.png")

```

```{r eval=FALSE, include=FALSE}
update_geom_defaults("point", list(color = pal[5]))
update_geom_defaults("line", list(color = pal[5]))

 ggplot(n_uk, aes(x = epi_week, y = N501Y / sequences)) + 
  geom_line() + geom_point() + labs(x = "Epidemic week", y = "N501Y (normalised)", title = "N501Y") + ylim(0,1)
 ggsave("N501Y.png")

```
```{r eval=FALSE, include=FALSE}
update_geom_defaults("point", list(color = pal[3]))
update_geom_defaults("line", list(color = pal[3]))

 ggplot(n_uk, aes(x = epi_week, y = DEL_69_70 / sequences)) + 
  geom_line() + geom_point() + labs(x = "Epidemic week", y = "Deletion 69-70 (normalised)", title = "Deletion 69-70") + ylim(0,1)
ggsave("DEL_69_70.png")
```
```{r eval=FALSE, include=FALSE}
n_uk_long <- 
  n_uk %>% 
  select(-c(sequences, D614G)) %>% 
  gather(key = "variant", value = "seq_raw", -epi_week) 
n_uk_long
```
```{r eval=FALSE, include=FALSE}
n_uk_long_norm <- 
  n_uk %>% 
  mutate_at(vars(D614G:DEL_69_70), funs((. / sequences) * 100)) %>%
  select(-c(sequences, D614G)) %>% 
  gather(key = "variant", value = "seq_norm", -epi_week) 
n_uk_long_norm
```

```{r eval=FALSE, include=FALSE}
theme_set(theme_classic())
n_uk_long %>% 
  ggplot(aes(x = epi_week, y = seq_raw)) + 
  geom_line(aes(color = variant)) + geom_point(aes(color = variant), size = 0.25) +
  labs(x = "Epidemic week", y = "Sequences", title = "Variant Viral Sequences per Week")  +  
  # ylim(0,100) + 
  theme(legend.title = element_blank()) + scale_color_manual(values = pal) 
ggsave("variants_overlay.png")
```
```{r eval=FALSE, include=FALSE}
theme_set(theme_classic())
n_uk_long_norm %>% 
ggplot(aes(x = epi_week, y = seq_norm)) + 
  geom_line(aes(color = variant)) + geom_point(aes(color = variant), size = 0.25) +
  labs(x = "Epidemic week", y = "% Sequences (normalised)", title = "Variant Viral Sequences per Week (Normalised)")  +  
  # ylim(0,100) + 
  theme(legend.title = element_blank()) + scale_color_manual(values = pal) 
ggsave("variants_overlay_norm.png")
```


```{r eval=FALSE, include=FALSE}
consortium_uk %>% 
  dplyr::count(n501y, del_21765_6)
```

```{r eval=FALSE, include=FALSE}
consortium_uk %>%  
  filter(sample_date >= sample_date_28) %>% 
  dplyr::count(n501y, del_21765_6)

```
```{r eval=FALSE, include=FALSE}
consortium_uk %>%  
  dplyr::count(n439k, del_21765_6)

```
```{r eval=FALSE, include=FALSE}
consortium_uk %>%  
  filter(sample_date >= sample_date_28) %>% 
  dplyr::count(n439k, del_21765_6)

```
```{r eval=FALSE, include=FALSE}

consortium_uk %>% 
  filter(n501y == "Y" & del_21765_6 == "del")  %>% 
  dplyr::count(lineage) %>% 
  arrange(desc(n))
```
```{r eval=FALSE, include=FALSE}

consortium_uk %>% 
  filter(sample_date >= sample_date_28 & n501y == "Y" & del_21765_6 == "del")  %>% 
  dplyr::count(lineage) %>% 
  arrange(desc(n))
```
```{r eval=FALSE, include=FALSE}
consortium_uk %>% 
  filter(n439k == "K" & del_21765_6 == "del")  %>% 
  dplyr::count(lineage) %>% 
  arrange(desc(n))
```
```{r eval=FALSE, include=FALSE}

consortium_uk %>% 
  filter(sample_date >= sample_date_28 & n439k == "K" & del_21765_6 == "del")  %>% 
  dplyr::count(lineage) %>% 
  arrange(desc(n))
```
```{r eval=FALSE, include=FALSE}
mutations %>% 
  filter(country == "UK" & gene == "S") %>% 
  summarise(n(), n_distinct(sequence_name))
```
```{r eval=FALSE, include=FALSE}
mutations %>% filter(country == "UK" & gene == "S") %>% 
  dplyr::count(variant) %>% 
  filter(n >1) %>% 
  summarise(sum(n))
```

```{r eval=FALSE, include=FALSE}
mutations %>% 
  filter(country == "UK" & gene == "S") %>% 
  dplyr::count(variant) %>% filter(n >100) %>% 
  summarise(sum(n))
```
```{r eval=FALSE, include=FALSE}
 # awk '/S:P681H/
 #  && /S:N501Y/
 #   && /orf1ab:T1001I/
 #   && /orf1ab:A1708D/
 #   && /orf1ab:I2230T/
 #   && /S:A570D/
 #   && /S:T716I/
 #   && /S:S982A/
 #   && /S:D1118H/
 #   && /ORF8:Q27*/
 #   && /ORF8:R52I/
 #   && /ORF8:Y73C/
 #   && /N:D3L/
 #   && /N:S235F/ { print;}' /cephfs/covid/bham/results/phylogenetics/20201215/metadata/cog_global_2020-12-20_mutations.csv
 # 

 # awk '/S:P681H/  && /S:N501Y/ && /orf1ab:T1001I/   && /orf1ab:A1708D/   && /orf1ab:I2230T/   && /S:A570D/   && /S:T716I/   && /S:S982A/   && /S:D1118H/ && /ORF8:Q27*/   && /ORF8:R52I/   && /ORF8:Y73C/   && /N:D3L/   && /N:S235F/ { print;}' cog_global_2020-12-20_mutations.csv 
 # 
 # 
 #  awk '/S:P681H/  && /S:N501Y/ && /orf1ab:T1001I/   && /orf1ab:A1708D/   && /orf1ab:I2230T/   && /S:A570D/   && /S:T716I/   && /S:S982A/   && /S:D1118H/ && /ORF8:Q27*/   && /ORF8:R52I/   && /ORF8:Y73C/   && /N:D3L/   && /N:S235F/ { print;}' cog_global_2020-12-21_mutations.csv > mutations_v_020-12-21.csv


mutations_v <- mutations %>% filter(country == "UK" & lineage == "B.1.1.7"
                     & sample_date >= "2020-11-24"
                     & (
  (gene == "S" & variant == "P681H") | 
  (gene == "S" & variant == "N501Y") | 
  (gene == "orf1ab" & variant == "T1001I") | 
  (gene == "orf1ab" & variant == "A1708D") | 
  (gene == "orf1ab" & variant == "I2230T") | 
  (gene == "S" & variant == "A570D") | 
  (gene == "S" & variant == "T716I") | 
  (gene == "S" & variant == "S982A") | 
  (gene == "S" & variant == "D1118H") | 
  (gene == "ORF8" & variant == "Q27*") |  
  (gene == "ORF8" & variant == "R52I") |
  (gene == "ORF8" & variant == "Y73C") | 
  (gene == "N" & variant == "D3L") | 
  (gene == "N" & variant == "S235F") 
  )) %>% dplyr::count(sequence_name, lineage) %>% filter(n == 14) #%>% select(-n)

mutations_v
```

```{r eval=FALSE, include=FALSE}
mutations %>% filter(country == "UK" 
                     # & sample_date >= "2020-11-13" 
                     & (
  (gene == "S" & variant == "K417N") | 
  (gene == "S" & variant == "E484K") | 
  (gene == "S" & variant == "N501Y") 
  )) %>% dplyr::count(sequence_name) %>% filter(n == 3)


```
```{r cluster5, eval=FALSE, include=FALSE}
# Cluster 5 is Y453F, 69-70del, I692V and M1229I
# 
mutations %>% filter(country == "UK" 
                     # & sample_date >= "2020-11-13" 
                     & (
  (gene == "S" && variant == "Y453F") | 
  (gene == "S" & variant == "I692V") | 
  (gene == "S" & variant == "M1229I") 
  )) %>% dplyr::count(sequence_name) %>% filter(n == 3)


```
# Deletions
```{r deletions}
deletions <- 
  read_tsv(params$deletions_tsv) %>% 
  separate_rows(samples, sep = '\\|')

message("Writing deletions.rds")
deletions %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/deletions.rds"))
```
# Insertions
```{r}
insertions <- 
  read_tsv(params$insertions_tsv) %>% 
  separate_rows(samples, sep = '\\|')

message("Writing insertions.rds")
insertions %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/insertions.rds"))
```

# Database
```{r database_genome}
# mutations_s_uk <- 
#   mutations_uk %>% 
#   filter(gene == "S") %>% 
#   select(-gene) %>% 
#   mutate(across(c(variant, position), fct_drop)) # drop non-spike mutations from factor levels

lineage_distinct <- 
  mutations_uk %>% 
  group_by(gene, position, variant) %>% 
  summarise(n_lineages = n_distinct(lineage), .groups = "drop") 

lineages <- 
  mutations_uk %>% 
  distinct(gene, position, variant, lineage) %>% 
  group_by(gene, position, variant) %>% 
  arrange(gene, position, variant, lineage, .by_group = TRUE) %>% 
  summarise(lineages = toString(lineage), .groups = "drop")

## UK and nations
# All sample dates
variants_uk <-
  mutations_uk %>% 
  group_by(gene, position, variant) %>% 
  summarise(UK = n(), earliest = min(sample_date), .groups = "drop")

variants_nations <- 
  mutations_uk %>% 
  dplyr::count(gene, position, variant, adm1) %>% 
  pivot_wider(names_from = adm1, values_from = n)

# Sample dates in last 28 days
variants_uk_28 <- 
  mutations_uk %>% 
  filter(sample_date >= sample_date_28) %>% 
  dplyr::count(gene, position, variant, name = "UK_28")

variants_nations_28 <-
  mutations_uk %>% 
    filter(sample_date >= sample_date_28) %>% 
    dplyr::count(gene, position, variant, adm1) %>% 
    pivot_wider(names_from = adm1, values_from = n) %>% 
    rename_with(~paste0(., "_28"), .cols = c(England, Northern_Ireland, Scotland, Wales))

database_genome <- 
  read_csv(params$spike_csv, col_types = cols(.default = col_character())) %>%
  type_convert %>%
  mutate(across(c(mutation, position), as_factor)) %>% 
  mutate(anchor = str_c("<a href='", doi, "'target='_blank'>", citation,"</a>"), .keep = "unused") %>% # hyperlink to citation DOI
  group_by(position, mutation) %>% 
  summarise(escape = escape %>% unique %>% sort %>% toString, 
            anchor = anchor %>% unique %>% str_c(collapse = "<br>"), # line breaks between hyperlinks
            mab = mab %>% any,
            plasma = plasma %>% any,
            vaccine_sera = vaccine_sera %>% any,
            support = support %>% unique %>% toString,
            domain = domain %>% unique %>% toString, 
            .groups = "drop") %>% 
  mutate(gene = factor("S"), .before = position)

join_cols <- c("mutation" = "variant", "position" = "position", "gene" = "gene")

database_genome %<>% 
  full_join(lineage_distinct, by = join_cols) %>% 
  full_join(lineages, by = join_cols) %>% 
  full_join(variants_uk,  by = join_cols) %>% 
  full_join(variants_nations,  by = join_cols) %>% 
  full_join(variants_uk_28,  by = join_cols) %>% 
  full_join(variants_nations_28,  by = join_cols) 

database_genome %<>%
  rename(
    `# Global Lineages associated with` = n_lineages, 
    `Global Lineages` = lineages, 
    
    `numSeqs UK` = UK,
    `numSeqs Eng` = England,
    `numSeqs NI` = Northern_Ireland,
    `numSeqs Scotland` = Scotland,
    `numSeqs Wales` = Wales,

    `numSeqs UK 28 days` = UK_28,
    `numSeqs Eng 28 days` = England_28,
    `numSeqs Scotland 28 days` = Scotland_28,
    `numSeqs Wales 28 days` = Wales_28, 
    `numSeqs NI 28 days` = Northern_Ireland_28) %>% 
  mutate(across(starts_with( c("numSeqs", "#") ), ~replace_na(.x, 0L))) %>% 
  mutate(across(c(gene, position, mutation), as.character)) %>% 
  mutate(across(position, as.integer)) %>% 
  arrange(gene, position, mutation) %>% 
  mutate(across(c(support, domain, gene, mutation), as_factor)) %>% 
  mutate(support = fct_relevel(support, "lower", "medium", "high"))

database_genome %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/database_genome.rds"))
```
## nsp12
```{r nsp12, eval=FALSE, include=TRUE}
mutations_uk %>% 
  mutate(across(position, as.character)) %>% 
  mutate(across(position, as.numeric)) %>% 
  filter(gene == "orf1ab" & between(position, 4393, 5324)) %>% 
  mutate(nsp12_variant = str_c(str_sub(variant, 1, 1), position - 4392, str_sub(variant, -1, -1) ) ) %>% 
  group_by(gene, variant, nsp12_variant) %>% 
  summarise(sequences = n_distinct(sequence_name)) %>% 
  ungroup %>%  
  slice_max(sequences, n = 15) %T>% write_csv("nsp12_top15.csv")
```

# Therapeutics
```{r therapeutics}

rem_data <- 
  fs::dir_ls(params$remdesivir_dir, glob = "*.csv") %>% # get file names
  map_dfr(read_csv) 

rem_data %<>% 
  rename(gene = ORF) %>%
  rename_with(~str_c(.x, "_nsp12"), c(position, residue, mutation)) %>% 
  mutate(gene = recode(gene, "orf1b" = "orf1ab"),
         position = position_nsp12 + 4392, .after = gene) %>% 
  mutate(variant = str_c(str_sub(mutation_nsp12, 1, 1), position, str_sub(mutation_nsp12, -1, -1) ), .after = position )

mutations_rem_uk <- 
  mutations_uk %>% 
  filter(gene == "orf1ab") %>% 
  mutate(across(position, as.character)) %>%
  mutate(across(position, as.numeric)) %>%
  mutate(across(c(variant), fct_drop)) %>% 
  semi_join(rem_data)

variants_rem_uk <-
  mutations_rem_uk %>%
  group_by(position, variant) %>%
  summarise(UK = n(), earliest = min(sample_date), .groups = "drop")

# Sample dates in last 28 days
variants_rem_uk_28 <-
  mutations_rem_uk %>%
  filter(sample_date >= sample_date_28) %>%
  dplyr::count(position, variant, name = "UK_28")

rem_data %<>%  
  mutate(anchor = str_c("<a href='https://", doi, "'target='_blank'>", citation,"</a>"), .keep = "unused") %>%   # hyperlink to citation DOI
  left_join(variants_rem_uk) %>% 
  left_join(variants_rem_uk_28) %>% 
  rename(
    `numSeqs UK` = UK,
    `numSeqs UK 28 days` = UK_28) %>% 
  mutate(across(starts_with( c("numSeqs", "#") ), ~replace_na(.x, 0L))) 

rem_data %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/therapeutics.rds"))
```

# T cell
## Epitopes
```{r tcell}
tcell <- read_csv(params$tcell_csv,
                  col_types = cols(
                          `Start position` = col_integer(),
                          `End position` = col_integer(),
                          `Supporting references` = col_integer()
                  ))

predictions <- read_tsv(params$predictions_tsv)

predictions %<>%
  rename(
    position = X1,
    mutation = X2,
    Epitope = X3,
    `Start position` = X5,
    `End position` = X6,
    CD4_CD8 = X7,
    HLA_prediction = X8) %>%
  select(-(starts_with("X"))) %>%
  mutate(gene = "S", .before = 1)

tcell %<>%
  # mutate (gene = recode(ORF,
  #                       "Spike" = "S",
  #                       "Nucleocapsid" = "N",
  #                       "Membrane" = "M",
  #                       "Envelope" = "E"),
  #         .before = 1,
  #         .keep = "unused") %>%
  mutate(HLA_prediction = str_replace(HLA, "\\*", "")) %>%
  mutate(HLA_prediction = str_replace(HLA_prediction, "^DRB1", "DRB1_")) # %>%

nested_html <- function(summary_var){
  summary_var %>%
    unique %>%
    map(function(i) div(i, class = "nested-row")) %>%
    div(class = "nested-container") %>%
    as.character()
}

container_html <- function(summary_var){
  summary_var %>%
    map(function(i) div(HTML(i), class = "cell-row")) %>%
    div(class = "cell-container") %>%
    as.character()
}

database_tcell <-
  database_genome %>%
  filter(gene == "S") %>%
  # select(-gene) %>%
  select(gene,
         position, mutation, `numSeqs UK`, `numSeqs UK 28 days`) %>%
  # filter(`numSeqs UK` > 0) %>% # filter zero counts from predicted antibodies not observed in mutations
  fuzzy_inner_join(
    tcell,
    by = c(
      # "gene" = "gene",
      "position" = "Start position",
      "position" = "End position"),
    match_fun = list(
      # `==`,
      `>=`, `<=`))

database_tcell_predictions <-
  database_tcell %>%
  left_join(predictions) %>%
  select(-HLA_prediction) %>%
  mutate(across(c(gene, mutation, Epitope, CD4_CD8, HLA, assay), as_factor))

database_tcell_predictions



# tcell <- read_csv(params$tcell_csv,
#                   col_types = cols(
#                           `Start position` = col_integer(),
#                           `End position` = col_integer(),
#                           `Supporting references` = col_integer()
#                   ))
# 
# predictions <- read_tsv(params$predictions_tsv) 
# 
# predictions %<>%
#   rename(
#     position = X1, 
#     mutation = X2, 
#     Epitope = X3, 
#     `Start position` = X5, 
#     `End position` = X6, 
#     CD4_CD8 = X7,
#     HLA_prediction = X8) %>% 
#   select(-(starts_with("X")))
# 
# tcell %<>%
#   mutate(HLA_prediction = str_replace(HLA, "\\*", "")) %>%
#   mutate(HLA_prediction = str_replace(HLA_prediction, "^DRB1", "DRB1_"))
# 
# nested_html <- function(summary_var){
#   summary_var %>% 
#     unique %>% 
#     map(function(i) div(i, class = "nested-row")) %>% 
#     div(class = "nested-container") %>% 
#     as.character()
# }
# 
# container_html <- function(summary_var){
#   summary_var %>% 
#     map(function(i) div(HTML(i), class = "cell-row")) %>% 
#     div(class = "cell-container") %>% 
#     as.character()
# }
# 
# database_tcell <-
#   database_genome %>% 
#   filter(gene == "S") %>% 
#   select(-gene) %>% 
#   select(position, mutation, `numSeqs UK`, `numSeqs UK 28 days`) %>% 
#   # filter(`numSeqs UK` > 0) %>% # filter zero counts from predicted antibodies not observed in mutations
#   fuzzy_inner_join(
#     tcell,
#     by = c("position" = "Start position",
#            "position" = "End position"),
#     match_fun = list(`>=`, `<=`))
# 
# database_tcell_predictions <- 
#   database_tcell %>% 
#   left_join(predictions) %>% 
#   select(-HLA_prediction) %>% 
#   mutate(across(c(mutation, Epitope, CD4_CD8, HLA, assay), as_factor)) 
# 
# database_tcell_predictions %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/database_tcell_predictions.rds"))

```
## Functional
```{r functional}
functional <- 
  read_csv(params$functional_csv) 

functional %<>% 
  mutate (gene = recode(ORF, 
                        "Spike" = "S", 
                        "Nucleocapsid" = "N",
                        "Membrane" = "M",
                        "Envelope" = "E"), 
          .before = 1,
          .keep = "unused") %>% 
  mutate(HLA_prediction = str_replace(HLA, "\\*", "")) %>%
  mutate(HLA_prediction = str_replace(HLA_prediction, "^DRB1", "DRB1_"))  

# functional_spike <- 
#   functional %>% 
  # filter(gene == "S") %>% 
  # select(-gene) %>%

database_genome_functional <-
  database_genome %>%
  select(gene, position, mutation, `numSeqs UK`, `numSeqs UK 28 days`) %>% 
  inner_join(functional)

database_functional_predictions <-
  database_genome_functional %>% 
  left_join(predictions) %>% 
  select(-HLA_prediction) %>% 
  mutate(across(c(gene, mutation, Epitope, CD4_CD8, HLA, assay), as_factor))

database_functional_predictions

bind_rows(database_tcell_predictions, database_functional_predictions) %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/database_tcell_predictions.rds"))


# mutations_func_uk <- 
#   mutations_uk %>% 
#   mutate(across(position, as.character)) %>%
#   mutate(across(position, as.numeric)) %>%
#   mutate(across(c(variant), fct_drop)) %>% 
#   semi_join(functional)
# 
# variants_func_uk <-
#   mutations_func_uk %>%
#   group_by(gene, position, variant) %>%
#   summarise(UK = n(), earliest = min(sample_date), .groups = "drop")
# 
# # Sample dates in last 28 days
# variants_func_uk_28 <-
#   mutations_func_uk %>%
#   filter(sample_date >= sample_date_28) %>%
#   dplyr::count(gene, position, variant, name = "UK_28")
# 
# functional %<>%  
#   mutate(anchor = str_c("<a href='https://", doi, "'target='_blank'>", citation,"</a>"), .keep = "unused") %>%   # hyperlink to citation DOI
#   left_join(variants_func_uk) %>% 
#   left_join(variants_func_uk_28) %>% 
#   rename(
#     `numSeqs UK` = UK,
#     `numSeqs UK 28 days` = UK_28) %>% 
#   mutate(across(starts_with( c("numSeqs", "#") ), ~replace_na(.x, 0L))) 
# 
# 
# functional %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/functional.rds"))

```

```{r eval=FALSE, include=FALSE}
consortium_v <- 
  consortium_uk %>% 
  filter(n501y == "Y" & 
         del_21765_6 == "del" &
         sample_date >= "2020-11-24" &
         lineage == "B.1.1.7"
        )
consortium_v
```
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  summarise(n_distinct(variant))
```
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  dplyr::count(variant) %>% 
  filter(n == 1) 
```
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  dplyr::count(variant) %>% 
  filter(n >= 100) 
```

```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  dplyr::count(variant) %>% 
  filter(n >= 5) %>% 
  arrange(desc(n))
```

### Table 1
```{r table_1}
database_genome %>% 
  slice_max(`numSeqs UK`, n = 15) %>% 
  select(mutation, `numSeqs UK`, `numSeqs UK 28 days`, `numSeqs Eng 28 days`, `numSeqs Scotland 28 days`, `numSeqs Wales 28 days`, `numSeqs NI 28 days`)
```
```{r appendix, eval=FALSE, include=FALSE}
database_genome %>% 
  filter(`numSeqs UK` >= 5) %>% 
  arrange(desc(`numSeqs UK`)) %>% 
  select(mutation, `numSeqs UK`, `numSeqs UK 28 days`, `numSeqs Eng 28 days`, `numSeqs Scotland 28 days`, `numSeqs Wales 28 days`, `numSeqs NI 28 days`) %T>% write_csv("appendix.csv")
```


```{r setdiff, eval=FALSE, include=FALSE}
setdiff(
consortium_uk %>% filter(d614g == "G") %>% select(sequence_name),
mutations_s_uk %>% filter(variant == "D614G") %>% select(sequence_name)
)
```
### Lineages
```{r lineage_counts}
n_uk_lineages <- 
  consortium_uk %>% 
  # filter(sample_date >= sample_date_28) %>% 
  group_by(lineage) %>%
  summarise(sequences = n(), 
            D614G = sum(d614g == "G"), 
            A222V = sum(a222v == "V"), 
            N439K = sum(n439k == "K"), 
            N501Y = sum(n501y == "Y"), 
            Y453F = sum(y453f == "F"),
            DEL_69_70 = sum(del_21765_6 == "del"), 
            N439K_DEL_69_70 = sum(n439k == "K" & del_21765_6 == "del"), 
            N501Y_DEL_69_70 = sum(n501y == "Y" & del_21765_6 == "del"),
            Y453F_DEL_69_70 = sum(y453f == "F" & del_21765_6 == "del")
  )

n_uk_lineages
```
#### B.1
```{r eval=FALSE, include=FALSE}
n_uk_lineages %>% 
  filter(lineage == "B.1" |str_detect(lineage, "^B\\.1\\.")) %>% 
  select(-lineage) %>% 
  summarise_all(funs(sum))
```

```{r eval=FALSE, include=FALSE}
n_uk_lineages %>% 
  filter(lineage == "B.1" |str_detect(lineage, "^B\\.1\\.")) %>% 
  mutate(lineage_top = "B.1") 
```
#### B.1.177
```{r eval=FALSE, include=FALSE}
n_uk_lineages %>% 
  filter(lineage == "B.1.177" | str_detect(lineage, "^B\\.1\\.177\\.")) %>% 
  select(-lineage) %>% 
  summarise_all(funs(sum))
```
#### B.1.141
```{r eval=FALSE, include=FALSE}
n_uk_lineages %>% filter(lineage == "B.1.141" | str_detect(lineage, "^B\\.1\\.141\\.")) %>% select(-lineage) %>% summarise_all(funs(sum))
```
#### B.1.258

```{r eval=FALSE, include=FALSE}
n_uk_lineages %>% filter(lineage == "B.1.258" | str_detect(lineage, "^B\\.1\\.258\\.")) %>% select(-lineage) %>% summarise_all(funs(sum))
```
#### B.1.1
```{r eval=FALSE, include=FALSE}
n_uk_lineages %>% filter(lineage == "B.1.1" | str_detect(lineage, "B\\.1\\.1\\.")) %>% select(-lineage) %>% summarise_all(funs(sum))
```

#### B.1.1.7
```{r eval=FALSE, include=FALSE}
n_uk_lineages %>% filter(lineage == "B.1.1.7" | str_detect(lineage, "B\\.1\\.1\\.7\\.")) %>% select(-lineage) %>% summarise_all(funs(sum))
```


#### B.1.1.70
```{r eval=FALSE, include=FALSE}
n_uk_lineages %>% filter(lineage == "B.1.1.70" | str_detect(lineage, "B\\.1\\.1\\.70\\.")) %>% select(-lineage) %>% summarise_all(funs(sum))

```

#### B.1.351
```{r eval=FALSE, include=FALSE}
n_uk_lineages %>% filter(lineage == "B.1.351" | str_detect(lineage, "B\\.1\\.351\\.")) %>% select(-lineage) %>% summarise_all(funs(sum))
```

#### B.1.1.298
```{r eval=FALSE, include=FALSE}
n_uk_lineages %>% filter(lineage == "B.1.1.298" | str_detect(lineage, "B\\.1\\.1\\.298\\.")) %>% select(-lineage) %>% summarise_all(funs(sum))
```
#### E484K
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  dplyr::count(lineage)
```
#### E484K 28 Days
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(sample_date >= sample_date_28) %>% 
  dplyr::count(lineage)
```
#### E484K / B.1.351 Summary
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(lineage == "B.1.351" | str_detect(lineage, "B\\.1\\.1\\.351\\.")) %>% 
  summarise("n_E484K_B.1.351" = n_distinct(sequence_name))
```
#### E484K / B.1.351 Summary 28 Days
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(lineage == "B.1.351" | str_detect(lineage, "B\\.1\\.1\\.351\\.")) %>% 
  filter(sample_date >= sample_date_28) %>% 
  summarise("n_28_E484K_B.1.351 " = n_distinct(sequence_name))
```
#### E484K / B.1.1.248
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(lineage == "B.1.1.248" | str_detect(lineage, "B\\.1\\.1\\.248\\.")) %>% summarise("n_E484K_B.1.1.248" = n_distinct(sequence_name))

```
#### E484K / B.1.1.248 28 Days
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(lineage == "B.1.1.248" | str_detect(lineage, "B\\.1\\.1\\.248\\.")) %>% 
  filter(sample_date >= sample_date_28) %>% 
  summarise("n_E484K_B.1.1.248" = n_distinct(sequence_name))
```

#### E484K / B.1.1.7
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(lineage == "B.1.1.7" | str_detect(lineage, "B\\.1\\.1\\.7\\.")) %>% summarise("n_E484K_B.1.1.7" = n_distinct(sequence_name))
```
#### E484K / B.1.1.7 28 Days
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(lineage == "B.1.1.7" | str_detect(lineage, "B\\.1\\.1\\.7\\.")) %>% 
  filter(sample_date >= sample_date_28) %>% 
  summarise("n_E484K_B.1.1.7" = n_distinct(sequence_name))
```

#### E484K / B.1.1
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(lineage == "B.1.1" | str_detect(lineage, "B\\.1\\.1\\.")) %>% summarise("n_E484K_B.1.1" = n_distinct(sequence_name))
```
#### E484K / B.1.1 28 Days
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(sample_date >= sample_date_28) %>% 
  filter(lineage == "B.1.1" | str_detect(lineage, "B\\.1\\.1\\.")) %>% summarise("n_E484K__28_B.1.1" = n_distinct(sequence_name))
```
#### N501Y + E484K / B.1.351 Summary
```{r eval=FALSE, include=FALSE}
intersect(
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(lineage == "B.1.351" | str_detect(lineage, "B\\.1\\.1\\.351\\.")) %>% 
  distinct(sequence_name),
  
consortium_uk %>% 
  filter(n501y == "Y") %>% 
  filter(lineage == "B.1.351" | str_detect(lineage, "B\\.1\\.1\\.351\\.")) %>% 
  distinct(sequence_name)
)
```

#### E484K + N501Y / B.1.351
```{r eval=FALSE, include=FALSE}
intersect(
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(lineage == "B.1.351" | str_detect(lineage, "B\\.1\\.1\\.351\\.")) %>% 
  filter(sample_date >= sample_date_28) %>% 
  distinct(sequence_name),
  
consortium_uk %>% 
  filter(n501y == "Y") %>% 
  filter(lineage == "B.1.351" | str_detect(lineage, "B\\.1\\.1\\.351\\.")) %>% 
  filter(sample_date >= sample_date_28) %>% 
  distinct(sequence_name)
)
```
### Escape Mutations
```{r escape, eval=FALSE, include=FALSE}
escape <- 
  read_csv("list_escape_2.csv", col_names = "mutation")

database_genome %>% 
  right_join(escape) %>% 
  select(mutation, `numSeqs UK`:`numSeqs Wales 28 days`) %T>% 
  write_csv("escape_counts.csv")
```

### Escape mutations sample names
```{r escape_ids, eval=FALSE, include=FALSE}
escape_t4 <- 
c(
"G446V",
"L452R",
"E484Q",
"K444R",
"E484K",
"Y508H",
"N440K",
"L455F",
"A831V",
"A475V",
"F490S",
"V483A",
"R346K",
"K378N",
"K444N",
'G446S',
"N450D",
"K150R",
"R346S",
"K150T",
"V445A",
"G446A",
"Y449H",
"E484A",
"Y453F", "N439K"
)  

lapply(escape_t4,  function(x){
    mutations_s_uk %>% 
        filter(variant == x) %>% 
        distinct(sequence_name) %T>% {{.} %$% 
        write_lines(sequence_name, paste0(x, ".txt"))}
})
```
## Antigenic
### Antigenic mutations by lineage
Would you be able to prepare a file with all the antigenic mutations (filtered from Willâ€™s antigenic table) that have accumulated on the top of B.1.1.7 (so non lineage defining mutations) with numbers of sequences per week? We would like to prepare a heat map like the attached picture.

```{r antigenic_mutations, eval=FALSE, include=FALSE}
antigenic <- 
  antigenic_mutations_lineages() %T>% 
  write_rds(str_c("COG-UK/", params$dataset_date, "/antigenic_mutations_lineages.rds"))

antigenic
```
### Antigenic heatmap
```{r antigenic_heatmap, eval=FALSE, include=FALSE}
suppressPackageStartupMessages(library(ComplexHeatmap))
suppressPackageStartupMessages(library(circlize))

# horz_heat_original <- read.table("horz_heat.csv", row.names = 1, header = TRUE, sep = ",", stringsAsFactors = FALSE)

horz_heat <-
  antigenic_mutations_lineages() %>% 
  filter(lineage == "B.1.1.7" & variant != "N501Y") %>% 
  select(-lineage) %>% 
  inner_join(database_genome %>% 
               select(position, mutation, mab, plasma, vaccine_sera, support, domain) %>% 
               add_row(position = 243, mutation = "del243-244", mab = TRUE, plasma = NA, vaccine_sera = NA, support = "lower", domain = "NTD"), 
             by = c("variant" = "mutation")) %>%   
  mutate(across(where(is.logical), ~na_if(.x, FALSE))) %>%
  arrange(position, variant) %>% 
  mutate(across(domain, as_factor)) %>% 
  select(-position) %>% 
  rename(confidence = support) %>% 
  column_to_rownames("variant")

input <- data.matrix(horz_heat)

# define colour heatmap for frequency
col_fun = colorRamp2(c( 0, 0.015, 0.5, 2), c("white", "darkolivegreen1","darkolivegreen3","forestgreen"))

# annotation row
row_ha = rowAnnotation(
  Effect_mab = horz_heat$mab,
  Effect_plasma = horz_heat$plasma,
  Effect_vaccine = horz_heat$vaccine_sera,
  confidence = horz_heat$confidence,
  na_col = 'white',
  col = list(
    confidence = c(
      "lower" = "lightgoldenrod",
      "medium" = "lightgoldenrod3",
      "high" = "lightgoldenrod4"
    ),
    Effect_mab = c("TRUE" = "black"),
    Effect_plasma = c("TRUE" = "black"),
    Effect_vaccine = c("TRUE" = "black")
  ),
  annotation_legend_param = list(confidence = list (at = c(
    "high", "medium", "lower"
  )))
)

# domain
row_ha2 = rowAnnotation(domain = (horz_heat$domain),
                        col = list(
                          domain = c(
                            "FP" = "seashell2",
                            "NTD" = "navajowhite",
                            "RBD" = "pink",
                            "RBM" = "plum1",
                            "SP" = "lightblue1"
                          )
                        ))

# remove x from name of columns (epiweek)
# colnames(horz_heat) <- gsub("X","",colnames(horz_heat))

# pdf("heatmap.pdf", height = 10)
png("heatmap.png", height = 800, type = "cairo-png")
hm <- Heatmap(
  subset(input, select = -c(mab:domain)),
  name = "Percentage %",
  column_title = "Antigenic mutations in lineage B.1.1.7",
  use_raster = TRUE,
  cluster_columns = FALSE,
  cluster_rows = FALSE,
  row_order = order((horz_heat$domain)),
  row_split = (horz_heat$domain),
  column_names_rot = 0,
  row_gap = unit(2, "mm"),
  border = TRUE,
  width = ncol(input) * unit(1.8, "mm"),
  height = nrow(input) * unit(1.8, "mm"),
  col = col_fun,
  na_col = 'white',
  column_names_gp = grid::gpar(fontsize = 4),
  row_names_gp = grid::gpar(fontsize = 4),
  right_annotation = row_ha,
  left_annotation = row_ha2
)
hm
dev.off()
hm

# RBD1_class<-c(403, 405, 406, 408, 409, 414, 415, 416, 417, 420, 421, 449, 453, 455, 456, 457, 458, 459, 460, 473, 474, 475, 476, 477, 484, 486, 487, 489, 490, 492, 493, 494, 495, 496, 498, 500, 501, 502, 503, 504, 505)
# RBD2_class<-c(338, 339, 342, 343, 346, 351, 368, 371, 372, 373, 374, 403, 405, 406, 417, 436, 444, 445, 446, 447, 448, 449, 450, 452, 453, 455, 456, 470, 472, 473, 475, 478, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505)
# RBD3_class<-c(333, 334, 335, 337, 339, 340, 341, 342, 343, 344, 345, 346, 354, 356, 357, 358, 359, 360, 361, 438, 439, 440, 441, 442, 443, 446, 499, 500)
# RBD4_class<-c(369, 370, 371, 372, 374, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 390, 430, 431)
# NTD_class<-c(15, 18, 19, 22, 28, 74, 77, 80, 123, 136, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 157, 158, 164, 244, 246, 247, 248, 249, 250, 251, 252, 253, 255, 257, 258)

# horz_heat$RBD1 <- ifelse(horz_heat$position %in% RBD1_class, TRUE, NA)
# horz_heat$RBD2 <- ifelse(horz_heat$position %in% RBD2_class, TRUE, NA)
# horz_heat$RBD3 <- ifelse(horz_heat$position %in% RBD3_class, TRUE, NA)
# horz_heat$RBD4 <- ifelse(horz_heat$position %in% RBD4_class, TRUE, NA)
# horz_heat$NTD.1 <- ifelse(horz_heat$position %in% NTD_class, TRUE, NA)

# col_fun = colorRamp2(c( 0, 0.015, 0.5, 2), c("white", "darkolivegreen1","darkolivegreen3","forestgreen"))
# 
# row_ha= rowAnnotation(Effect_mab = horz_heat[,20], Effect_plasma = horz_heat [,21], Effect_vaccine= horz_heat [,22], confidence = horz_heat[,23],
#                         na_col = 'white', col= list(
#                         confidence = c("lower" = "lightgoldenrod", "medium" = "lightgoldenrod3", "high" = "lightgoldenrod4"),
#                         Effect_mab = c("TRUE" = "black"),
#                         Effect_plasma = c("TRUE" ="black"),
#                         Effect_vaccine = c("TRUE" = "black")),
#                       annotation_legend_param = list(confidence = list (at = c("high", "medium", "lower")))
#                       )
#                       
# row_ha2=rowAnnotation(domain = (horz_heat[,24]), Ab_class1 = (horz_heat[,30]),Ab_class2 = (horz_heat[,31]),Ab_class3 = (horz_heat[,32]),Ab_class4 = (horz_heat[,33]),Ab_classe5 = (horz_heat[,34]),
#                       na_col = 'white',
#                       width = ncol(horz_heat)*unit(0.8, "mm"),
#                       col=list(
#                       domain = c("FP" ="seashell2", "NTD"= "navajowhite", "RBD" = "pink", "RBM" = "plum1","SP"= "lightblue1"),
#                       Ab_class1 =c ("TRUE" = "lightgreen"),
#                       Ab_class2 =c("TRUE" = "goldenrod1"),
#                       Ab_class3 =c("TRUE" = "cornflowerblue"),
#                       Ab_class4 =c("TRUE" = "tomato"),
#                       Ab_class5 =c("TRUE" = "magenta")),
#                       show_legend = c(domain = FALSE, Ab_class1 = FALSE,Ab_class2 = FALSE,Ab_class3 = FALSE,Ab_class4 = FALSE,Ab_class5 = FALSE)
#                       )
#                       
# colnames(input)<-gsub("X","",colnames(input))
# 
# Heatmap(input[,2:18], name = "Percentage %", column_title = "Antigenic mutations on the top of B.1.1.7", use_raster = TRUE,cluster_columns = FALSE,
#         row_order = order((horz_heat[,24])),
#         row_split = (horz_heat[,24]),
#         column_names_rot=0,
#         row_gap = unit(2, "mm"),  border = TRUE,
#         width = ncol(input)*unit(1.8, "mm"),
#                height = nrow(input)*unit(1.8, "mm"),
#         col=col_fun,
#         na_col = 'white' ,
#               column_names_gp = grid::gpar(fontsize = 4),
#         row_names_gp = grid::gpar(fontsize = 4),
#         right_annotation = row_ha,
#         left_annotation = row_ha2
#         )

```
### ggseqlogo
```{r ggseqlogo}
wt <-
  mutation_reference_counts %>% 
  filter(gene == "S" & variant == "WT" & adm1 == "UK") %>%
  group_by(position) %>% 
  summarise(`numSeqs UK` = sum(n)) %>% 
  mutate(position = fct_drop(position) %>% fct_expand(1:1274 %>% as.character) %>% fct_inseq) %>% 
  complete(position) %>% 
  mutate(across(`numSeqs UK`, ~replace_na(.x, n_distinct(consortium_uk$sequence_name))))

library(seqinr) # NB seqinr also has a count function!
spike_sequence <- 
  read.fasta(params$spike_fasta, seqonly = TRUE) %>% 
  str_extract_all(boundary("character")) %>% 
  flatten_chr() %>% 
  c("*") # append stop codon

wt %<>% 
  add_column(AA = spike_sequence) %>% 
  mutate(across(position, as.character)) %>% 
  mutate(across(position, as.integer)) %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/wt.rds"))

wt %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/wt.rds"))
```


### mydata
```{r eval=FALSE, include=FALSE}
# library(tidyverse)
# library(magrittr)

mydata <- read_csv("mydata.csv") 

names <- 
  c("MA0018.2",
    "MA0031.1",
    "MA0139.1",
    "MA0158.1")

df <- names %>% 
    purrr::set_names() %>%
    map(function(i) 
      gather(mydata, "key", "value", starts_with(i)) %$% as.integer(value) %>% array(dim = c(4, length(.)/4))
    ) %>% as.list 

df
```

## VUI and VOC
### VUI and VOC defining mutations
```{r vui_voc}
vui_voc <-
  read_csv(params$vui_voc_csv) %>% 
  filter(non_syn == "aa" & gene == "S" & lineage != "B.1.617") %>% # B.1.617 no longer used - reassigned to clades
  select(-gene, -details_gene, -non_syn) %>% 
  mutate(across(lineage, as_factor)) %>% 
  mutate(across(lineage, ~fct_relevel(.x, sort)))

vui_voc %T>% write_rds(str_c("COG-UK/", "vui_voc.rds"))
```

### VUI and VOC plot
```{r lineages_plot, eval=FALSE, include=TRUE}
lineages_weeks_nations <-
  consortium_uk %>% dplyr::count(lineage, epi_week, adm1)

lineages_weeks_uk <-
  lineages_weeks_nations %>% 
  group_by(lineage, epi_week) %>% 
  summarise(across(n, sum), .groups = "drop") %>% 
  mutate(adm1 = "UK", .after = epi_week) %>% 
  bind_rows(lineages_weeks_nations) %>% 
  arrange(lineage, adm1, epi_week)
    
# lineages_weeks_uk %T>% 
#   write_rds(str_c("COG-UK/", params$dataset_date, "/lineages_weeks_uk.rds"))

lineages_weeks_uk %>%
  filter(adm1 == "UK" & lineage %in% levels(vui_voc$lineage) & lineage != "B.1.1.7") %>%
  ggplot(aes(x=epi_week, y=n, group=lineage, color=lineage)) + 
  geom_line() + 
  geom_point() +
  scale_x_discrete(drop = FALSE) + # include all epi_week factor levels
  theme_classic()

```
### Constellations UpSet plot
```{r upset, eval=FALSE, include=FALSE}
mutations_s_uk_wide <-
  mutations_s_uk %>% 
  filter(lineage %in% levels(vui_voc$lineage)) %>% 
  filter(lineage %in% c("B.1.1.7", "B.1.351", "P.1")) %>% 
  mutate(logical_true = TRUE) %>% 
  pivot_wider(names_from = variant, values_from = logical_true, id_cols = c(sequence_name, variant), values_fill = FALSE)

mutations_s_uk_wide
```
### VUI/VOC/other
```{r vui_voc_other}
# sequences with B.617.2.x, AY.4.x and AY.4.2.x converted to parent lineage (N.B. contains duplicate sequences for Delta!)
consortium_uk_delta_parent <-
  bind_rows(
    # convert AY.x sublineages  to parent B.1.617.2
    consortium_uk %>%
      mutate(lineage = gsub("AY\\..*", "B.1.617.2", lineage)), 
  
    # filter AY.4 and sublineages then convert AY.4.x sublineages to parent AY.4 
    consortium_uk %>% 
      filter(lineage == "AY.4" | str_starts(lineage, fixed("AY.4."))) %>% 
      mutate(lineage = "AY.4"),
  
    # filter AY.4.2 and sublineages then convert any AY.4.2 sublineages to parent AY.4.2
    consortium_uk %>% 
      filter(lineage == "AY.4.2" | str_starts(lineage, fixed("AY.4.2."))) %>% 
      mutate(lineage = "AY.4.2"),
    
    # Delta non-AY.4
    consortium_uk %>% filter(( lineage == "B.1.617.2" | str_starts(lineage_full, fixed("B.1.617.2.")))
                             & lineage != "AY.4" 
                             & !str_starts(lineage, fixed("AY.4."))) %>% 
      mutate(lineage = "Delta_minus_AY.4"),
    
    # Delta non-AY.4.2
    consortium_uk %>% filter(( lineage == "B.1.617.2" | str_starts(lineage_full, fixed("B.1.617.2.")))
                             & lineage != "AY.4.2" 
                             & !str_starts(lineage, fixed("AY.4.2."))) %>% 
      mutate(lineage = "Delta_minus_AY.4.2")
  ) 

# count sequences by day
lineages_days_uk_all <- 
  bind_rows(
    consortium_uk_delta_parent %>% 
      dplyr::count(lineage, sample_date, adm1, name = "n_day"),
    
    consortium_uk_delta_parent %>% 
      dplyr::count(lineage, sample_date, name = "n_day") %>% 
      mutate(adm1 = "UK") %>% 
      mutate(across(adm1, as_factor))
  )

# by week
lineages_weeks_uk_all <- bind_rows(
 consortium_uk_delta_parent %>% 
   dplyr::count(lineage, epi_date, adm1, name = "n_week"),
 
 consortium_uk_delta_parent %>% dplyr::count(lineage, epi_date, name = "n_week") %>% 
   mutate(adm1 = "UK") %>% 
   mutate(across(adm1, as_factor))
)
 
lineages_days_uk_all %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/lineages_days_uk_all.rds"))
lineages_weeks_uk_all %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/lineages_weeks_uk_all.rds"))
```
## GISAID
```{r gisaid, eval=FALSE, include=TRUE}
# GISAID Delta sequences
gisaid <- 
  read_csv("6_seqmuts_ale.txt", 
           col_names = 
              c("sequence_name",
              "gisaid_id",
              "lineage", 
              "sample_date",
              "epi_week",
              "country",
              "region",
              "mutations")
  ) %>% 
  drop_na(sample_date) %>% # exclude sequences with missing sample date
  distinct

epi_levels_gisaid <- 
  min(gisaid$epi_week):max(gisaid$epi_week) %>% as.character

gisaid %<>% 
  mutate(across(c(epi_week), as_factor)) %>%
  mutate(epi_week = fct_expand(epi_week, epi_levels_gisaid) %>% fct_inseq) # expand factor levels to include any missing weeks


# All genes mutations and deletions
mutations_gisaid <-
  gisaid %>% 
  separate_rows(mutations, sep = '\\|') %>% 
  filter(mutations != "") %>% # trailing '|' generates empty string
  separate(mutations, into = c("gene", "variant"), sep = ':') %>% 
  distinct 

# S gene mutations and deletions
mutations_s_all_gisaid <- 
  mutations_gisaid %>% 
  filter(gene == "S") %>% 
  mutate(position = parse_number(variant))

# S gene del243-244
dels_s_gisaid <- 
  mutations_s_all_gisaid %>% 
  filter(str_detect(variant, "del") & (position == 243)) %>% 
  semi_join(mutations_s_all_gisaid %>% # sequences with both del243 and del244
              filter(str_detect(variant, "del") & (position == 244)),
            by = c("sequence_name", "gisaid_id", "lineage", 
                   "sample_date", "epi_week", "country", "region", "gene")) %>% 
  mutate(variant = "del243-244")
  
# defining mutations of delta variant
defining_delta <- 
        vui_voc %>% 
        filter(lineage == "B.1.617.2") %$% 
        mutation

# S gene mutations minus defining plus del243-244
mutations_s_gisaid <- 
  mutations_s_all_gisaid %>% 
  filter(!str_detect(variant, "del")) %>%  # remove deletions
  filter(!(variant %in% defining_delta)) %>% # remove Delta defining mutations
  bind_rows(dels_s_gisaid)  # bind del243-244

mutations_s_gisaid
#   mutate(across(c(gene, position, variant), as_factor)) %T>% 

```
### GISAID antigenic
```{r eval=FALSE, include=TRUE}

sequences_by_week_gisaid <- 
    gisaid %>% 
    dplyr::count(epi_week, name = "n_sequences_lineage")

# S gene escape mutations
escape_mutations <-
  database_genome %>%
  filter(!is.na(escape)) %$% 
  mutation 
  
antigenic_mutations_gisaid <- 
    mutations_s_gisaid %>% 
    filter(variant %in% escape_mutations | variant == "del243-244") %>% 
    dplyr::count(variant, epi_week, sort = TRUE) 

antigenic_mutations_gisaid_all <- 
  inner_join(antigenic_mutations_gisaid, sequences_by_week_gisaid) %>% 
  mutate(percentage = n / n_sequences_lineage * 100 ) %>% 
   complete(epi_week, nesting(variant), fill = list(n = 0, n_sequences_lineage = 0, percentage = 0)) %>%
    mutate(epi_week = epi_week %>% as.character %>% as.integer)

first_occurrence_gisaid <- 
    antigenic_mutations_gisaid_all %>% 
    filter(n > 0) %$% 
    min(epi_week)

antigenic_mutations_gisaid_all %<>%
  filter(epi_week >= first_occurrence_gisaid) %>%
  inner_join(epi_lookup) %>% 
  pivot_wider(names_from = epi_date, values_from = percentage, names_sort = TRUE, values_fill = 0, id_cols = variant) 

png("gisaid_delta.png",width=750, height=1300, units="px", type = "cairo-png")
antibody_complex_heatmap(antigenic_mutations_gisaid_all)
dev.off()

antigenic_mutations_gisaid_all
```
## Geo
```{r geo, eval=FALSE, include=TRUE}
# TOPOJSON objectid
# 1 North East (England)
# 2 "North West (England)"
# 3 Yorkshire and The Humber
# 
# 4 East Midlands (England)
# 5 West Midlands (England)
# 6 East of England
# 
# 7 London
# 8 South East (England)
# 9 South West (England)
# 
# 10 Wales
# 11 Scotland
# 12 Northern Ireland
# 

NUTS1 <- c(
"North_East",               
"North_West",     
"Yorkshire_And_The_Humber",

"East_Midlands"            ,
"West_Midlands"            ,
"East_Of_England"          ,

"Greater_London"           ,
"South_East"               ,
"South_West"               ,

"Wales"        ,
"Scotland"      ,           
"Northern_Ireland"         
) 

NUTS1_objectid <- tibble(NUTS1, objectid = 1:length(NUTS1))

# regional counts for all variants with NUTS1 data
geo <- 
  consortium_uk %>% 
  filter(!is.na(NUTS1)) %>% 
  count(epi_week, NUTS1, .drop = FALSE) 

geo_variants <- 
  consortium_uk %>%
  filter(!is.na(NUTS1)) %>% 
  mutate(across(lineage, as_factor)) %>%
  mutate(lineage = fct_other(lineage, keep = vui_voc %$% levels(lineage))) %>% 
  dplyr::count(epi_week, NUTS1, lineage, name = "n_week", .drop = FALSE) 

geo_all <- 
  inner_join(geo, geo_variants) %>%
  mutate(across(epi_week, as.character)) %>% 
  mutate(across(epi_week, as.integer)) %>% 
  # filter(epi_week >= 39 & epi_week <= 80) %>% # first week VUIs and VOCs appear
  filter(epi_week >= 39) %>% # first week VUIs and VOCs appear
  mutate(Proportion = ifelse(n==0, 0, n_week / n)) %>%  # keep zero counts for rendering 
  select(-n) %>%
  inner_join(NUTS1_objectid) %>% 
  rename(Count = n_week) %T>%
  write_csv("nuts1.csv")

geo
geo_variants
geo_all
```
## ISARIC
### Alias
```{r isaric_alias, eval=FALSE, include=FALSE}
library(jsonlite)
alias_key <- fromJSON("https://raw.githubusercontent.com/cov-lineages/pango-designation/master/pango_designation/alias_key.json")

alias_key %<>% 
  keep(~ length(.x) == 1) %>% # drop recombinants
  purrr::discard(~ .x == "") # drop top level lineages

# TODO mutate full lineage in initial consortium read instead
consortium_full <- 
  consortium_uk %>% 
  mutate(lineage_full = lineage, .after = lineage)

mutations_full <- 
  mutations_uk %>% 
  mutate(lineage_full = lineage, .after = lineage)

for (i in 1:length(alias_key)) {
  consortium_full <<- 
    consortium_full %>% 
    mutate(lineage_full = str_replace(lineage_full, str_c("^", names(alias_key)[i], "(?=\\.)"), str_c(alias_key[[i]])))
  
  mutations_full <<- 
    mutations_full %>% 
    mutate(lineage_full = str_replace(lineage_full, str_c("^", names(alias_key)[i], "(?=\\.)"), str_c(alias_key[[i]])))
}
```
### Filter
```{r isaric}
# source("COG-UK/out_frame_del.R")
# source("COG-UK/wuhan_ref_aa.R")

message("Reading ISARIC list file ", params$isaric_csv)
isaric_list <- read_csv(params$isaric_csv)

# iterate through isaric_list row by row
isaric_dfr <-
  isaric_list %>%
  pmap_dfr(function(...) {
    current <- tibble(...) # current row of isaric_list
    
    output <- tibble()
    
    if (is.na(current$Mutation)) { # if no mutations then search consortium 
      if (!is.na(current$Lineage)) {
        
        # filter by lineage and wildcard
        if (str_ends(current$Lineage, fixed("*"))) { # filter sublineages if wildcard
          lineage_prefix <- str_sub(current$Lineage, 1, nchar(current$Lineage) - 1)
          
          output <-
            consortium_uk %>%
            filter(if_any(c(lineage, lineage_full), ~ str_starts(.x, fixed(lineage_prefix)))) %>%   # use fixed because dot is regex special character
            select(sequence_name, cog_id, sample_date, lineage, lineage_full)
          
        } else { # no wildcard - filter exact lineage
          output <-
            consortium_uk %>%
            filter(lineage_full == current$Lineage |
                     lineage == current$Lineage) %>% 
            select(sequence_name, cog_id, sample_date, lineage, lineage_full)
        }
        
        if(!is.na(current$Lineage_filter_out)){
          filters <- str_split(current$Lineage_filter_out, fixed("|"))
          # TODO (no examples at present)
        }
      } 
    } else { # filter deletion/insertion/mutation
     gene_mutation <- str_split(current$Mutation, ":") %>% unlist # split gene:mutation

      if(str_starts(gene_mutation[2], "del|ins")){ # deletion or insertion - look up consortium
        output <- consortium_uk
      } else{ # mutation
        output <- mutations_uk
      }

      # filter by lineage
      if(!is.na(current$Lineage)){
        if (str_ends(current$Lineage, fixed("*"))) { # filter sublineages if wildcard
          lineage_prefix <- str_sub(current$Lineage, 1, nchar(current$Lineage) - 1)

          output %<>%
            filter(if_any(c(lineage, lineage_full), ~ str_starts(.x, fixed(lineage_prefix))))
        } else { # no wildcard - filter exact lineage
          output %<>%
            filter(lineage == current$Lineage)
        }
      }

      # filter out lineage
      if(!is.na(current$Lineage_filter_out)){
        excludes <- 
          current$Lineage_filter_out %>% 
          str_split(fixed("|")) %>% 
          unlist
        
        walk(excludes, function(x){
          if(str_ends(x, fixed("*"))){ # if wildcard
            lineage_prefix <- str_sub(x, 1, nchar(x) - 1)

            output <<-
              output %>%
              filter(if_all(c(lineage, lineage_full), ~ !str_starts(.x, fixed(lineage_prefix))))

          } else { # else exact lineage
            output <<-
              output %>%
              filter(if_all(c(lineage, lineage_full), ~ .x != x))
          }
        })
        
      }

      if(str_starts(gene_mutation[2], "del")){ # deletion - look up consortium 
        #TODO calculate genome coordinates from aa positions
        #TODO in frame only?
        #TODO gene name
        
        dels <-
          deletions %>% 
          filter(between(ref_start, 22283, 22294)) %>% 
          mutate(gene = "S", variant = str_c("del_", ref_start, "_", length)) %>% 
          select(-ref_start, -length)

        # del_22289_6 is del243-244
        # S:del241-243 is del_22283_9
        # S:del242-244 is del_22286_9
        # 22283, 22286, 22289 and 22292 ( to 22294 ?)
        
        output %<>% 
          select(sequence_name, cog_id, sample_date, lineage, lineage_full) %>% 
          inner_join(dels, by = c("sequence_name" = "samples"))
      } else if(gene_mutation[1] == "S" & str_starts(gene_mutation[2], "ins")){ # insertion - look up consortium
        # Spike genomic coordinates 21563..25384 
        # TODO in frame only
        
        ins_samples <- 
          insertions %>% 
          # filter(str_length(insertion) %% 3 == 0) %>% 
          filter(ref_start >= 21563 & ref_start < 25384) %>%  # Spike coordinates 21563 to 25384 
          filter(!str_detect(insertion, "N")) %>% # exclude any insertions with uncalled nucleotides
          mutate(gene = "S", variant = str_c("ins_", ref_start, "_", insertion), .keep = "unused") 

        output %<>% 
          select(sequence_name, cog_id, sample_date, lineage, lineage_full) %>% 
          inner_join(ins_samples, by = c("sequence_name" = "samples"))
      } else { # mutation - look up mutations
          
          if(str_ends(gene_mutation[2], "X")){ # mutation wildcard
            output %<>% filter(gene == gene_mutation[1] & position == parse_number(gene_mutation[2]))
          } else { # exact match of mutation
            output %<>% filter(gene == gene_mutation[1] & variant == gene_mutation[2])
          }

        output %<>% select(sequence_name, cog_id, sample_date, lineage, lineage_full, gene, variant)
     }

    }
    
    output %>% mutate(query_id = current$ID)
  })# %>% distinct

isaric_dfr
```
### Compare
```{r isaric_compare}
# list isaric TSV files
isaric_files <- list.files(pattern = "isaric_.*_cumulative\\.tsv") 
  
# extract dates from filenames  
isaric_dates <-
  isaric_files %>% 
  str_extract("\\d{4}-\\d{2}-\\d{2}") %>% 
  parse_date

# get most recent date
isaric_previous <- isaric_dates[isaric_dates < params$dataset_date]
isaric_latest <- NULL
if(length(isaric_previous > 0)){ # previous datasets exist
  message("Reading most recent ISARIC cumulative file")
  isaric_recent <- 
    isaric_previous %>% 
    max %>% 
    grep(isaric_files) %>% 
    isaric_files[.] %>% 
    print %>%
    read_tsv() %>% 
    separate_rows(query_id, sep = ",") %>% 
    mutate(query_id = as.numeric(query_id)) 
  
  isaric_latest <- 
    anti_join(isaric_dfr, isaric_recent, by = c("cog_id", "query_id"))
}

isaric_latest
```

### Collapse
```{r isaric_collapse}
collapse_isaric <- function(isaric_hits){
  isaric_hits %>% 
  mutate(gene_variant = str_c(gene, ":", variant), .keep = "unused") %>% 
  group_by(cog_id, sample_date, lineage) %>% 
  summarise(mutations = toString(str_c(gene_variant)), query_id = toString(query_id), .groups = "drop") %>% 
  arrange(desc(sample_date), lineage, cog_id)
}

if(!is.null(isaric_latest)){
  isaric_latest_collapse <- 
    isaric_latest %>% 
    collapse_isaric %T>% 
    write_tsv(str_c("isaric_", params$dataset_date, "_latest.tsv") %T>% message("Writing ", .))
  
  isaric_latest_collapse
}

isaric_dfr_collapse <- 
  isaric_dfr %>% 
  collapse_isaric %T>% 
  write_tsv(str_c("isaric_", params$dataset_date, "_cumulative.tsv") %T>% message("Writing ", .))

isaric_dfr_collapse
```
## Ronapreve plot
```{r ronopreve_plot}
source("mab_upset_regeneron.R")
ronapreve_upset <- generate_upset()
ronapreve_upset_28 <- generate_upset(filter_date = sample_date_28)

png(filename=str_c("COG-UK/", params$dataset_date, "/Ronapreve.png"), width=1200, height=650, type = "cairo-png")
ronapreve_upset
dev.off()

png(filename = str_c("COG-UK/", params$dataset_date, "/Ronapreve_28.png"), width=1200, height=650, type = "cairo-png")
ronapreve_upset_28
dev.off()

# ronapreve_upset
# ronapreve_upset_28

```

## Done
```{r success}
message("PIPELINE COMPLETED")
```