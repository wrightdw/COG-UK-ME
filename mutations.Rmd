---
title:  "COG-UK Mutations"
output: html_notebook
params: 
  latest:           TRUE # TRUE to copy latest files on CLIMB to working directory, overrides dataset_date with today()
  dataset_date:     "" # if empty, defaults to today's date, otherwise enter date string
  spike_csv:        "spike_escape_info.csv"
  spike_extra_csv:  "spike_escape_extra.csv"
  tcell_csv:        "tcell_long.csv"
  deletions_tsv:    "cog.deletions.tsv"
  predictions_tsv:  "Prediction_from_Morten.txt"
  spike_fasta:      "sequence.fasta"
  vui_voc_csv:      "VUI and VOC.csv"
  remdesivir_dir:   "Remdesivir Mutants" 
  isaric_csv:       "Isaric_list.csv"
  insertions_tsv:   "cog.insertions.tsv"
  functional_csv:   "tcell_functional_mutations.csv"
---
# Setup
```{r setup}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(magrittr))
library(wesanderson)
library(RColorBrewer)
suppressPackageStartupMessages(library(lubridate))
library(fuzzyjoin)
library(htmltools)
suppressPackageStartupMessages(library(jsonlite))
# also require seqinr - loaded later on to avoid name clash of dplyr count function
library(UpSetR)
```
```{r climb}
Sys.setenv(TZ="Europe/London")

if(params$latest){ # copy today's files to working directory on CLIMB, stop if process run previously or today's files not available yet
  
  # check files exist
  params$dataset_date <- today()
  latest_dir <- "/cephfs/covid/bham/results/msa/latest"
  consortium_csv <- str_c("cog_global_", params$dataset_date, "_consortium.csv")
  consortium_today_msa <- file.path(latest_dir, "metadata", consortium_csv)
  
  if(!file.exists(consortium_csv) && # file not already copied
     file.exists(consortium_today_msa)){ # MSA file exists
    
    # copy consortium and deletions to working directory
    message("Copying latest consortium and deletions files")
    file.copy(consortium_today_msa, getwd())
    
    # deletions and insertions files not named by date so overwrite previous
    file.copy(file.path(latest_dir, "cog", params$deletions_tsv), getwd(), overwrite = TRUE) 
    file.copy(file.path(latest_dir, "cog", params$insertions_tsv), getwd(), overwrite = TRUE) 
  } else {
    stop(str_c(consortium_today_msa, " does not exist or already copied")) # terminate script
  }  
  
} else {
  if(params$dataset_date == ""){
    params$dataset_date <- today()
  } else {
    params$dataset_date %<>% as.Date
  }
  
  consortium_csv <- str_c("cog_global_", params$dataset_date, "_consortium.csv")
}

dir.create(str_c("COG-UK/", params$dataset_date))
```

# Consortium
## Read
```{r consortium_read, include=FALSE}
message("Reading ", consortium_csv)
consortium_uk <- 
  read_csv((consortium_csv), col_types = cols(.default = col_character())) %>% 
  filter(country == "UK" & !is.na(adm1) & adm1 %in% (c("England", "Scotland", "Wales", "Northern_Ireland"))) %>% # exclude Crown dependencies and British Overseas Territories
  select(-gisaid_id, -submission_org_code, -root_sample_id, -(adm2:travel_history), NUTS1,
         -lineages_version, -country, 
         -received_date, -collection_date, -published_date, -starts_with("scorpio"), 
         -lineage_conflict, -lineage_ambiguity_score, -sequencing_org_code, -submission_user
         ) %>% # remove unused columns
  relocate(NUTS1,.after = adm1) %>% 
  type_convert 

# Epidemic week / Sunday date conversion
epi_lookup <-
  tibble(
    epi_date = seq(from = ymd("2020-01-26"), to = consortium_uk %$% max(sample_date), by = "week"),
    epi_week = seq(consortium_uk %$% min(epi_week), consortium_uk %$% max(epi_week))
  ) 
# %T>% # lookup table of epi_week and Sunday date
#   write_rds(str_c("COG-UK/", params$dataset_date, "/epi_lookup.rds"))

epi_levels <- min(consortium_uk$epi_week):max(consortium_uk$epi_week) %>% as.character

consortium_uk %<>% 
  inner_join(epi_lookup) %>% 
  relocate(epi_date, .after = epi_week) %>% 
  mutate(across(c(epi_week, adm1, NUTS1), as_factor)) %>%
  mutate(epi_week = fct_expand(epi_week, epi_levels) %>% fct_inseq) # expand factor levels to include any missing weeks

 # Temporary fix - exclude duplicate Delta sequences with incorrect dates in April 2020
dodgy_delta <- 
  consortium_uk %>% 
  filter(lineage == "B.1.617.2" & epi_week %in% c(16, 17))

consortium_uk %<>% anti_join(dodgy_delta)

consortium_uk
```
## 28 days
```{r consortium_constants, include=FALSE}
sample_date_28 <- max(consortium_uk$sample_date) - days(27) # calculate 28 day period up to and including latest sample date
message("28 days date: ", sample_date_28)
```
## Alias
```{r consortium_alias, include=FALSE}
message("Looking up PANGO designation lineage alias key on GitHub")
# reconstruct lineage full names from alias JSON
alias_key <- fromJSON("https://raw.githubusercontent.com/cov-lineages/pango-designation/master/pango_designation/alias_key.json")

alias_key %<>% 
  keep(~ length(.x) == 1) %>% # drop recombinants
  purrr::discard(~ .x == "") # drop top level lineages

# copy lineage column
consortium_uk %<>% 
  mutate(lineage_full = lineage, .after = lineage)

# overwrite aliases with full lineage names
for (i in 1:length(alias_key)) {
  consortium_uk <<- 
    consortium_uk %>% 
    mutate(lineage_full = str_replace(lineage_full, str_c("^", names(alias_key)[i], "(?=\\.)"), str_c(alias_key[[i]])))
}

consortium_uk
```
## Write
```{r consortium_write}
mutations_uk <- 
  consortium_uk %>% 
  select(sequence_name, cog_id, sample_date, epi_week, epi_date, lineage, lineage_full, adm1, mutations) %>% 
  distinct # get rid of identical variant calls

message("Writing consortium_uk.rds")
consortium_uk %<>% 
  select(-mutations) %>% 
  distinct %T>% # remove duplicates
  write_rds(str_c("COG-UK/", params$dataset_date, "/consortium_uk.rds"))

consortium_uk
```
# Mutations
```{r mutations_consortium}
mutations_uk %<>%    
  separate_rows(mutations, sep = '\\|') %>% 
  separate(mutations, into = c("gene", "variant"), sep = ':') %>% 
  drop_na() %>%
  filter(gene != "synSNP") %>%
  mutate(position = parse_number(variant)) %>% 
  mutate(across(c(gene, position, variant), as_factor)) %T>% 
  write_rds(str_c("COG-UK/", params$dataset_date, "/mutations_uk.rds"))

# exclude duplicate delta variants with incorrect dates in April 2020
dodgy_delta_mutations <- 
  mutations_uk %>% 
  filter(lineage == "B.1.617.2" & epi_week %in% c(16, 17))

mutations_uk
```
## Mutation / REF counts
```{r mutations_refs}
#### UK ### 
genes_positions <- 
  mutations_uk %>% 
  distinct(gene, position) # gene / position combinations actually found in mutations

sequences_by_week <- 
  consortium_uk %>% 
  dplyr::count(epi_week, epi_date, name = "n_sequences")

positions_by_week <- 
  mutations_uk %>%
  dplyr::count(epi_week, epi_date, gene, position, .drop = FALSE, name = "n_variant_sequences") # count all possible epi_week/gene/position combinations 

reference_counts <- 
  positions_by_week %>%
  inner_join(genes_positions) %>% # remove gene / position combinations not found in mutations
  inner_join(sequences_by_week) %>% 
  mutate(n = n_sequences - n_variant_sequences, variant = "WT", .keep = "unused") %>% # calculate reference / other
  filter(n > 0) %>%  # remove zero WT entries (where all sequences are variants for an epi_week / position combo)
  mutate(adm1 = "UK")

mutation_counts <- 
  mutations_uk %>%
  dplyr::count(epi_week, epi_date, gene, position, variant) %>% 
  mutate(adm1 = "UK")

#### Nations ####
sequences_by_week_nations <-
  consortium_uk %>%
  dplyr::count(epi_week, epi_date, adm1, name = "n_sequences")

positions_by_week_nations <-
  mutations_uk %>%
  dplyr::count(epi_week, epi_date, gene, position, adm1, .drop = FALSE, name = "n_variant_sequences") # count all possible epi_week/gene/position/nation combinations

reference_counts_nations <- 
  positions_by_week_nations %>%
  inner_join(genes_positions) %>% # remove gene / position combinations not found in mutations
  inner_join(sequences_by_week_nations) %>% 
  mutate(n = n_sequences - n_variant_sequences, variant = "WT", .keep = "unused") %>% # calculate reference / other
  filter(n > 0) # remove zero WT entries (where all sequences are variants for an epi_week / position combo)

mutation_counts_nations <- 
  mutations_uk %>%
  dplyr::count(epi_week, epi_date, gene, position, variant, adm1)

mutation_reference_counts <- 
  bind_rows(mutation_counts, reference_counts, mutation_counts_nations, reference_counts_nations) %>% 
  mutate(across(variant, as_factor)) %T>% 
  write_rds(str_c("COG-UK/", params$dataset_date, "/mutation_reference_counts.rds"))

mutation_reference_counts
```
## Total sequences per epidemic week
```{r consortium_counts, eval=FALSE, include=FALSE}
n_uk <- 
  consortium_uk %>% 
  # filter(sample_date >= 2020-11-13) %>% 
  # filter(epi_week < 50) %>%
  group_by(epi_week) %>%
  summarise(sequences = n(), D614G = sum(d614g == "G"), A222V = sum(a222v == "V"), 
            N439K = sum(n439k == "K"), N501Y = sum(n501y == "Y"), DEL_69_70 = sum(del_21765_6 == "del")) #%>%
            # mutate_at(vars(D614G:DEL_69_70), cumsum) # cumulative counts
            # mutate_at(vars(sequences:DEL_69_70), cumsum) # cumulative counts to normalise against cumulative sequences

n_uk
```

```{r eval=FALSE, include=FALSE}
n_uk %>% 
  select(-epi_week) %>% 
  summarise_all(funs(sum))
```

```{r eval=FALSE, include=FALSE}
n_uk_28 <- 
  consortium_uk %>% 
  filter(sample_date >= sample_date_28) %>%
  group_by(epi_week) %>%
  summarise(sequences = n(), D614G = sum(d614g == "G"), A222V = sum(a222v == "V"), 
            N439K = sum(n439k == "K"), N501Y = sum(n501y == "Y"), DEL_69_70 = sum(del_21765_6 == "del"))
n_uk_28
```
```{r eval=FALSE, include=FALSE}
n_uk_28 %>% 
  select(-epi_week) %>% 
  summarise_all(funs(sum))
```

```{r eval=FALSE, include=FALSE}
theme_set(theme_classic() + theme(legend.position = "none"))

pal <- wes_palette("Cavalcanti1", type = "discrete")
update_geom_defaults("point", list(color = pal[1]))
update_geom_defaults("line", list(color = pal[1]))

 ggplot(n_uk, aes(x = epi_week, y = sequences)) + 
  geom_line() + geom_point() + labs(x = "Epidemic week", y = "Sequences", title = "Sequences per Week")

 ggsave("Sequences.png")
```
```{r eval=FALSE, include=FALSE}
pal <- brewer.pal(n = 5, name = "Set1")
update_geom_defaults("point", list(color = pal[2]))
update_geom_defaults("line", list(color = pal[2]))

 ggplot(n_uk, aes(x = epi_week, y = D614G / sequences)) + 
  geom_line() + geom_point() + labs(x = "Epidemic week", y = "D614G (normalised)", title = "D614G") + ylim(0,1)
 ggsave("D614G.png")

```

```{r eval=FALSE, include=FALSE}
update_geom_defaults("point", list(color = pal[1]))
update_geom_defaults("line", list(color = pal[1]))

 ggplot(n_uk, aes(x = epi_week, y = A222V / sequences)) + 
  geom_line() + geom_point() + labs(x = "Epidemic week", y = "A222V (normalised)", title = "A222V") + ylim(0,1)
 ggsave("A222V.png")

```
```{r eval=FALSE, include=FALSE}
update_geom_defaults("point", list(color = pal[4]))
update_geom_defaults("line", list(color = pal[4]))

 ggplot(n_uk, aes(x = epi_week, y = N439K / sequences)) + 
  geom_line() + geom_point() + labs(x = "Epidemic week", y = "N439K (normalised)", title = "N439K") + ylim(0,1)
 ggsave("N439K.png")

```

```{r eval=FALSE, include=FALSE}
update_geom_defaults("point", list(color = pal[5]))
update_geom_defaults("line", list(color = pal[5]))

 ggplot(n_uk, aes(x = epi_week, y = N501Y / sequences)) + 
  geom_line() + geom_point() + labs(x = "Epidemic week", y = "N501Y (normalised)", title = "N501Y") + ylim(0,1)
 ggsave("N501Y.png")

```
```{r eval=FALSE, include=FALSE}
update_geom_defaults("point", list(color = pal[3]))
update_geom_defaults("line", list(color = pal[3]))

 ggplot(n_uk, aes(x = epi_week, y = DEL_69_70 / sequences)) + 
  geom_line() + geom_point() + labs(x = "Epidemic week", y = "Deletion 69-70 (normalised)", title = "Deletion 69-70") + ylim(0,1)
ggsave("DEL_69_70.png")
```
```{r eval=FALSE, include=FALSE}
n_uk_long <- 
  n_uk %>% 
  select(-c(sequences, D614G)) %>% 
  gather(key = "variant", value = "seq_raw", -epi_week) 
n_uk_long
```
```{r eval=FALSE, include=FALSE}
n_uk_long_norm <- 
  n_uk %>% 
  mutate_at(vars(D614G:DEL_69_70), funs((. / sequences) * 100)) %>%
  select(-c(sequences, D614G)) %>% 
  gather(key = "variant", value = "seq_norm", -epi_week) 
n_uk_long_norm
```

```{r eval=FALSE, include=FALSE}
theme_set(theme_classic())
n_uk_long %>% 
  ggplot(aes(x = epi_week, y = seq_raw)) + 
  geom_line(aes(color = variant)) + geom_point(aes(color = variant), size = 0.25) +
  labs(x = "Epidemic week", y = "Sequences", title = "Variant Viral Sequences per Week")  +  
  # ylim(0,100) + 
  theme(legend.title = element_blank()) + scale_color_manual(values = pal) 
ggsave("variants_overlay.png")
```
```{r eval=FALSE, include=FALSE}
theme_set(theme_classic())
n_uk_long_norm %>% 
ggplot(aes(x = epi_week, y = seq_norm)) + 
  geom_line(aes(color = variant)) + geom_point(aes(color = variant), size = 0.25) +
  labs(x = "Epidemic week", y = "% Sequences (normalised)", title = "Variant Viral Sequences per Week (Normalised)")  +  
  # ylim(0,100) + 
  theme(legend.title = element_blank()) + scale_color_manual(values = pal) 
ggsave("variants_overlay_norm.png")
```


```{r eval=FALSE, include=FALSE}
consortium_uk %>% 
  dplyr::count(n501y, del_21765_6)
```

```{r eval=FALSE, include=FALSE}
consortium_uk %>%  
  filter(sample_date >= sample_date_28) %>% 
  dplyr::count(n501y, del_21765_6)

```
```{r eval=FALSE, include=FALSE}
consortium_uk %>%  
  dplyr::count(n439k, del_21765_6)

```
```{r eval=FALSE, include=FALSE}
consortium_uk %>%  
  filter(sample_date >= sample_date_28) %>% 
  dplyr::count(n439k, del_21765_6)

```
```{r eval=FALSE, include=FALSE}

consortium_uk %>% 
  filter(n501y == "Y" & del_21765_6 == "del")  %>% 
  dplyr::count(lineage) %>% 
  arrange(desc(n))
```
```{r eval=FALSE, include=FALSE}

consortium_uk %>% 
  filter(sample_date >= sample_date_28 & n501y == "Y" & del_21765_6 == "del")  %>% 
  dplyr::count(lineage) %>% 
  arrange(desc(n))
```
```{r eval=FALSE, include=FALSE}
consortium_uk %>% 
  filter(n439k == "K" & del_21765_6 == "del")  %>% 
  dplyr::count(lineage) %>% 
  arrange(desc(n))
```
```{r eval=FALSE, include=FALSE}

consortium_uk %>% 
  filter(sample_date >= sample_date_28 & n439k == "K" & del_21765_6 == "del")  %>% 
  dplyr::count(lineage) %>% 
  arrange(desc(n))
```
```{r eval=FALSE, include=FALSE}
mutations %>% 
  filter(country == "UK" & gene == "S") %>% 
  summarise(n(), n_distinct(sequence_name))
```
```{r eval=FALSE, include=FALSE}
mutations %>% filter(country == "UK" & gene == "S") %>% 
  dplyr::count(variant) %>% 
  filter(n >1) %>% 
  summarise(sum(n))
```

```{r eval=FALSE, include=FALSE}
mutations %>% 
  filter(country == "UK" & gene == "S") %>% 
  dplyr::count(variant) %>% filter(n >100) %>% 
  summarise(sum(n))
```
```{r eval=FALSE, include=FALSE}
 # awk '/S:P681H/
 #  && /S:N501Y/
 #   && /orf1ab:T1001I/
 #   && /orf1ab:A1708D/
 #   && /orf1ab:I2230T/
 #   && /S:A570D/
 #   && /S:T716I/
 #   && /S:S982A/
 #   && /S:D1118H/
 #   && /ORF8:Q27*/
 #   && /ORF8:R52I/
 #   && /ORF8:Y73C/
 #   && /N:D3L/
 #   && /N:S235F/ { print;}' /cephfs/covid/bham/results/phylogenetics/20201215/metadata/cog_global_2020-12-20_mutations.csv
 # 

 # awk '/S:P681H/  && /S:N501Y/ && /orf1ab:T1001I/   && /orf1ab:A1708D/   && /orf1ab:I2230T/   && /S:A570D/   && /S:T716I/   && /S:S982A/   && /S:D1118H/ && /ORF8:Q27*/   && /ORF8:R52I/   && /ORF8:Y73C/   && /N:D3L/   && /N:S235F/ { print;}' cog_global_2020-12-20_mutations.csv 
 # 
 # 
 #  awk '/S:P681H/  && /S:N501Y/ && /orf1ab:T1001I/   && /orf1ab:A1708D/   && /orf1ab:I2230T/   && /S:A570D/   && /S:T716I/   && /S:S982A/   && /S:D1118H/ && /ORF8:Q27*/   && /ORF8:R52I/   && /ORF8:Y73C/   && /N:D3L/   && /N:S235F/ { print;}' cog_global_2020-12-21_mutations.csv > mutations_v_020-12-21.csv


mutations_v <- mutations %>% filter(country == "UK" & lineage == "B.1.1.7"
                     & sample_date >= "2020-11-24"
                     & (
  (gene == "S" & variant == "P681H") | 
  (gene == "S" & variant == "N501Y") | 
  (gene == "orf1ab" & variant == "T1001I") | 
  (gene == "orf1ab" & variant == "A1708D") | 
  (gene == "orf1ab" & variant == "I2230T") | 
  (gene == "S" & variant == "A570D") | 
  (gene == "S" & variant == "T716I") | 
  (gene == "S" & variant == "S982A") | 
  (gene == "S" & variant == "D1118H") | 
  (gene == "ORF8" & variant == "Q27*") |  
  (gene == "ORF8" & variant == "R52I") |
  (gene == "ORF8" & variant == "Y73C") | 
  (gene == "N" & variant == "D3L") | 
  (gene == "N" & variant == "S235F") 
  )) %>% dplyr::count(sequence_name, lineage) %>% filter(n == 14) #%>% select(-n)

mutations_v
```

```{r eval=FALSE, include=FALSE}
mutations %>% filter(country == "UK" 
                     # & sample_date >= "2020-11-13" 
                     & (
  (gene == "S" & variant == "K417N") | 
  (gene == "S" & variant == "E484K") | 
  (gene == "S" & variant == "N501Y") 
  )) %>% dplyr::count(sequence_name) %>% filter(n == 3)


```
```{r cluster5, eval=FALSE, include=FALSE}
# Cluster 5 is Y453F, 69-70del, I692V and M1229I
# 
mutations %>% filter(country == "UK" 
                     # & sample_date >= "2020-11-13" 
                     & (
  (gene == "S" && variant == "Y453F") | 
  (gene == "S" & variant == "I692V") | 
  (gene == "S" & variant == "M1229I") 
  )) %>% dplyr::count(sequence_name) %>% filter(n == 3)


```
# Deletions
```{r deletions}
deletions <- 
  read_tsv(params$deletions_tsv) %>% 
  separate_rows(samples, sep = '\\|')

message("Writing deletions.rds")
deletions %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/deletions.rds"))
```
# Insertions
```{r}
insertions <- 
  read_tsv(params$insertions_tsv) %>% 
  separate_rows(samples, sep = '\\|')

message("Writing insertions.rds")
insertions %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/insertions.rds"))
```

# Database
```{r database_genome}
# mutations_s_uk <- 
#   mutations_uk %>% 
#   filter(gene == "S") %>% 
#   select(-gene) %>% 
#   mutate(across(c(variant, position), fct_drop)) # drop non-spike mutations from factor levels

lineage_distinct <- 
  mutations_uk %>% 
  group_by(gene, position, variant) %>% 
  summarise(n_lineages = n_distinct(lineage), .groups = "drop") 

lineages <- 
  mutations_uk %>% 
  distinct(gene, position, variant, lineage) %>% 
  group_by(gene, position, variant) %>% 
  arrange(gene, position, variant, lineage, .by_group = TRUE) %>% 
  summarise(lineages = toString(lineage), .groups = "drop")

## UK and nations
# All sample dates
variants_uk <-
  mutations_uk %>% 
  group_by(gene, position, variant) %>% 
  summarise(UK = n(), earliest = min(sample_date), .groups = "drop")

variants_nations <- 
  mutations_uk %>% 
  dplyr::count(gene, position, variant, adm1) %>% 
  pivot_wider(names_from = adm1, values_from = n)

# Sample dates in last 28 days
variants_uk_28 <- 
  mutations_uk %>% 
  filter(sample_date >= sample_date_28) %>% 
  dplyr::count(gene, position, variant, name = "UK_28")

variants_nations_28 <-
  mutations_uk %>% 
    filter(sample_date >= sample_date_28) %>% 
    dplyr::count(gene, position, variant, adm1) %>% 
    pivot_wider(names_from = adm1, values_from = n) %>% 
    rename_with(~paste0(., "_28"), .cols = c(England, Northern_Ireland, Scotland, Wales))

database_genome <- 
  read_csv(params$spike_csv, col_types = cols(.default = col_character())) %>%
  type_convert %>%
  mutate(across(c(mutation, position), as_factor)) %>% 
  mutate(anchor = str_c("<a href='", doi, "'target='_blank'>", citation,"</a>"), .keep = "unused") %>% # hyperlink to citation DOI
  group_by(position, mutation) %>% 
  summarise(escape = escape %>% unique %>% sort %>% toString, 
            anchor = anchor %>% unique %>% str_c(collapse = "<br>"), # line breaks between hyperlinks
            mab = mab %>% any,
            plasma = plasma %>% any,
            vaccine_sera = vaccine_sera %>% any,
            support = support %>% unique %>% toString,
            domain = domain %>% unique %>% toString, 
            .groups = "drop") %>% 
  mutate(gene = factor("S"), .before = position)

join_cols <- c("mutation" = "variant", "position" = "position", "gene" = "gene")

database_genome %<>% 
  full_join(lineage_distinct, by = join_cols) %>% 
  full_join(lineages, by = join_cols) %>% 
  full_join(variants_uk,  by = join_cols) %>% 
  full_join(variants_nations,  by = join_cols) %>% 
  full_join(variants_uk_28,  by = join_cols) %>% 
  full_join(variants_nations_28,  by = join_cols) 

database_genome %<>%
  rename(
    `# Global Lineages associated with` = n_lineages, 
    `Global Lineages` = lineages, 
    
    `numSeqs UK` = UK,
    `numSeqs Eng` = England,
    `numSeqs NI` = Northern_Ireland,
    `numSeqs Scotland` = Scotland,
    `numSeqs Wales` = Wales,

    `numSeqs UK 28 days` = UK_28,
    `numSeqs Eng 28 days` = England_28,
    `numSeqs Scotland 28 days` = Scotland_28,
    `numSeqs Wales 28 days` = Wales_28, 
    `numSeqs NI 28 days` = Northern_Ireland_28) %>% 
  mutate(across(starts_with( c("numSeqs", "#") ), ~replace_na(.x, 0L))) %>% 
  mutate(across(c(gene, position, mutation), as.character)) %>% 
  mutate(across(position, as.integer)) %>% 
  arrange(gene, position, mutation) %>% 
  mutate(across(c(support, domain, gene, mutation), as_factor)) %>% 
  mutate(support = fct_relevel(support, "lower", "medium", "high"))

database_genome %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/database_genome.rds"))
```
## nsp12
```{r nsp12, eval=FALSE, include=TRUE}
mutations_uk %>% 
  mutate(across(position, as.character)) %>% 
  mutate(across(position, as.numeric)) %>% 
  filter(gene == "orf1ab" & between(position, 4393, 5324)) %>% 
  mutate(nsp12_variant = str_c(str_sub(variant, 1, 1), position - 4392, str_sub(variant, -1, -1) ) ) %>% 
  group_by(gene, variant, nsp12_variant) %>% 
  summarise(sequences = n_distinct(sequence_name)) %>% 
  ungroup %>%  
  slice_max(sequences, n = 15) %T>% write_csv("nsp12_top15.csv")
```

# Therapeutics
```{r therapeutics}

rem_data <- 
  fs::dir_ls(params$remdesivir_dir, glob = "*.csv") %>% # get file names
  map_dfr(read_csv) 

rem_data %<>% 
  rename(gene = ORF) %>%
  rename_with(~str_c(.x, "_nsp12"), c(position, residue, mutation)) %>% 
  mutate(gene = recode(gene, "orf1b" = "orf1ab"),
         position = position_nsp12 + 4392, .after = gene) %>% 
  mutate(variant = str_c(str_sub(mutation_nsp12, 1, 1), position, str_sub(mutation_nsp12, -1, -1) ), .after = position )

mutations_rem_uk <- 
  mutations_uk %>% 
  filter(gene == "orf1ab") %>% 
  mutate(across(position, as.character)) %>%
  mutate(across(position, as.numeric)) %>%
  mutate(across(c(variant), fct_drop)) %>% 
  semi_join(rem_data)

variants_rem_uk <-
  mutations_rem_uk %>%
  group_by(position, variant) %>%
  summarise(UK = n(), earliest = min(sample_date), .groups = "drop")

# Sample dates in last 28 days
variants_rem_uk_28 <-
  mutations_rem_uk %>%
  filter(sample_date >= sample_date_28) %>%
  dplyr::count(position, variant, name = "UK_28")

rem_data %<>%  
  mutate(anchor = str_c("<a href='https://", doi, "'target='_blank'>", citation,"</a>"), .keep = "unused") %>%   # hyperlink to citation DOI
  left_join(variants_rem_uk) %>% 
  left_join(variants_rem_uk_28) %>% 
  rename(
    `numSeqs UK` = UK,
    `numSeqs UK 28 days` = UK_28) %>% 
  mutate(across(starts_with( c("numSeqs", "#") ), ~replace_na(.x, 0L))) 

rem_data %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/therapeutics.rds"))
```

# T cell
## Epitopes
```{r tcell}
tcell <- read_csv(params$tcell_csv,
                  col_types = cols(
                          `Start position` = col_integer(),
                          `End position` = col_integer(),
                          `Supporting references` = col_integer()
                  ))

predictions <- read_tsv(params$predictions_tsv)

predictions %<>%
  rename(
    position = X1,
    mutation = X2,
    Epitope = X3,
    `Start position` = X5,
    `End position` = X6,
    CD4_CD8 = X7,
    HLA_prediction = X8) %>%
  select(-(starts_with("X"))) %>%
  mutate(gene = "S", .before = 1)

tcell %<>%
  # mutate (gene = recode(ORF,
  #                       "Spike" = "S",
  #                       "Nucleocapsid" = "N",
  #                       "Membrane" = "M",
  #                       "Envelope" = "E"),
  #         .before = 1,
  #         .keep = "unused") %>%
  mutate(HLA_prediction = str_replace(HLA, "\\*", "")) %>%
  mutate(HLA_prediction = str_replace(HLA_prediction, "^DRB1", "DRB1_")) # %>%

nested_html <- function(summary_var){
  summary_var %>%
    unique %>%
    map(function(i) div(i, class = "nested-row")) %>%
    div(class = "nested-container") %>%
    as.character()
}

container_html <- function(summary_var){
  summary_var %>%
    map(function(i) div(HTML(i), class = "cell-row")) %>%
    div(class = "cell-container") %>%
    as.character()
}

database_tcell <-
  database_genome %>%
  filter(gene == "S") %>%
  # select(-gene) %>%
  select(gene,
         position, mutation, `numSeqs UK`, `numSeqs UK 28 days`) %>%
  # filter(`numSeqs UK` > 0) %>% # filter zero counts from predicted antibodies not observed in mutations
  fuzzy_inner_join(
    tcell,
    by = c(
      # "gene" = "gene",
      "position" = "Start position",
      "position" = "End position"),
    match_fun = list(
      # `==`,
      `>=`, `<=`))

database_tcell_predictions <-
  database_tcell %>%
  left_join(predictions) %>%
  select(-HLA_prediction) %>%
  mutate(across(c(gene, mutation, Epitope, CD4_CD8, HLA, assay), as_factor))

database_tcell_predictions



# tcell <- read_csv(params$tcell_csv,
#                   col_types = cols(
#                           `Start position` = col_integer(),
#                           `End position` = col_integer(),
#                           `Supporting references` = col_integer()
#                   ))
# 
# predictions <- read_tsv(params$predictions_tsv) 
# 
# predictions %<>%
#   rename(
#     position = X1, 
#     mutation = X2, 
#     Epitope = X3, 
#     `Start position` = X5, 
#     `End position` = X6, 
#     CD4_CD8 = X7,
#     HLA_prediction = X8) %>% 
#   select(-(starts_with("X")))
# 
# tcell %<>%
#   mutate(HLA_prediction = str_replace(HLA, "\\*", "")) %>%
#   mutate(HLA_prediction = str_replace(HLA_prediction, "^DRB1", "DRB1_"))
# 
# nested_html <- function(summary_var){
#   summary_var %>% 
#     unique %>% 
#     map(function(i) div(i, class = "nested-row")) %>% 
#     div(class = "nested-container") %>% 
#     as.character()
# }
# 
# container_html <- function(summary_var){
#   summary_var %>% 
#     map(function(i) div(HTML(i), class = "cell-row")) %>% 
#     div(class = "cell-container") %>% 
#     as.character()
# }
# 
# database_tcell <-
#   database_genome %>% 
#   filter(gene == "S") %>% 
#   select(-gene) %>% 
#   select(position, mutation, `numSeqs UK`, `numSeqs UK 28 days`) %>% 
#   # filter(`numSeqs UK` > 0) %>% # filter zero counts from predicted antibodies not observed in mutations
#   fuzzy_inner_join(
#     tcell,
#     by = c("position" = "Start position",
#            "position" = "End position"),
#     match_fun = list(`>=`, `<=`))
# 
# database_tcell_predictions <- 
#   database_tcell %>% 
#   left_join(predictions) %>% 
#   select(-HLA_prediction) %>% 
#   mutate(across(c(mutation, Epitope, CD4_CD8, HLA, assay), as_factor)) 
# 
# database_tcell_predictions %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/database_tcell_predictions.rds"))

```
## Functional
```{r functional}
functional <- 
  read_csv(params$functional_csv) 

functional %<>% 
  mutate (gene = recode(ORF, 
                        "Spike" = "S", 
                        "Nucleocapsid" = "N",
                        "Membrane" = "M",
                        "Envelope" = "E"), 
          .before = 1,
          .keep = "unused") %>% 
  mutate(HLA_prediction = str_replace(HLA, "\\*", "")) %>%
  mutate(HLA_prediction = str_replace(HLA_prediction, "^DRB1", "DRB1_"))  

# functional_spike <- 
#   functional %>% 
  # filter(gene == "S") %>% 
  # select(-gene) %>%

database_genome_functional <-
  database_genome %>%
  select(gene, position, mutation, `numSeqs UK`, `numSeqs UK 28 days`) %>% 
  inner_join(functional)

database_functional_predictions <-
  database_genome_functional %>% 
  left_join(predictions) %>% 
  select(-HLA_prediction) %>% 
  mutate(across(c(gene, mutation, Epitope, CD4_CD8, HLA, assay), as_factor))

database_functional_predictions

bind_rows(database_tcell_predictions, database_functional_predictions) %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/database_tcell_predictions.rds"))


# mutations_func_uk <- 
#   mutations_uk %>% 
#   mutate(across(position, as.character)) %>%
#   mutate(across(position, as.numeric)) %>%
#   mutate(across(c(variant), fct_drop)) %>% 
#   semi_join(functional)
# 
# variants_func_uk <-
#   mutations_func_uk %>%
#   group_by(gene, position, variant) %>%
#   summarise(UK = n(), earliest = min(sample_date), .groups = "drop")
# 
# # Sample dates in last 28 days
# variants_func_uk_28 <-
#   mutations_func_uk %>%
#   filter(sample_date >= sample_date_28) %>%
#   dplyr::count(gene, position, variant, name = "UK_28")
# 
# functional %<>%  
#   mutate(anchor = str_c("<a href='https://", doi, "'target='_blank'>", citation,"</a>"), .keep = "unused") %>%   # hyperlink to citation DOI
#   left_join(variants_func_uk) %>% 
#   left_join(variants_func_uk_28) %>% 
#   rename(
#     `numSeqs UK` = UK,
#     `numSeqs UK 28 days` = UK_28) %>% 
#   mutate(across(starts_with( c("numSeqs", "#") ), ~replace_na(.x, 0L))) 
# 
# 
# functional %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/functional.rds"))

```

```{r eval=FALSE, include=FALSE}
consortium_v <- 
  consortium_uk %>% 
  filter(n501y == "Y" & 
         del_21765_6 == "del" &
         sample_date >= "2020-11-24" &
         lineage == "B.1.1.7"
        )
consortium_v
```
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  summarise(n_distinct(variant))
```
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  dplyr::count(variant) %>% 
  filter(n == 1) 
```
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  dplyr::count(variant) %>% 
  filter(n >= 100) 
```

```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  dplyr::count(variant) %>% 
  filter(n >= 5) %>% 
  arrange(desc(n))
```

### Table 1
```{r table_1}
database_genome %>% 
  slice_max(`numSeqs UK`, n = 15) %>% 
  select(mutation, `numSeqs UK`, `numSeqs UK 28 days`, `numSeqs Eng 28 days`, `numSeqs Scotland 28 days`, `numSeqs Wales 28 days`, `numSeqs NI 28 days`)
```
```{r appendix, eval=FALSE, include=FALSE}
database_genome %>% 
  filter(`numSeqs UK` >= 5) %>% 
  arrange(desc(`numSeqs UK`)) %>% 
  select(mutation, `numSeqs UK`, `numSeqs UK 28 days`, `numSeqs Eng 28 days`, `numSeqs Scotland 28 days`, `numSeqs Wales 28 days`, `numSeqs NI 28 days`) %T>% write_csv("appendix.csv")
```


```{r setdiff, eval=FALSE, include=FALSE}
setdiff(
consortium_uk %>% filter(d614g == "G") %>% select(sequence_name),
mutations_s_uk %>% filter(variant == "D614G") %>% select(sequence_name)
)
```
### Lineages
```{r lineage_counts}
n_uk_lineages <- 
  consortium_uk %>% 
  # filter(sample_date >= sample_date_28) %>% 
  group_by(lineage) %>%
  summarise(sequences = n(), 
            D614G = sum(d614g == "G"), 
            A222V = sum(a222v == "V"), 
            N439K = sum(n439k == "K"), 
            N501Y = sum(n501y == "Y"), 
            Y453F = sum(y453f == "F"),
            DEL_69_70 = sum(del_21765_6 == "del"), 
            N439K_DEL_69_70 = sum(n439k == "K" & del_21765_6 == "del"), 
            N501Y_DEL_69_70 = sum(n501y == "Y" & del_21765_6 == "del"),
            Y453F_DEL_69_70 = sum(y453f == "F" & del_21765_6 == "del")
  )

n_uk_lineages
```
#### B.1
```{r eval=FALSE, include=FALSE}
n_uk_lineages %>% 
  filter(lineage == "B.1" |str_detect(lineage, "^B\\.1\\.")) %>% 
  select(-lineage) %>% 
  summarise_all(funs(sum))
```

```{r eval=FALSE, include=FALSE}
n_uk_lineages %>% 
  filter(lineage == "B.1" |str_detect(lineage, "^B\\.1\\.")) %>% 
  mutate(lineage_top = "B.1") 
```
#### B.1.177
```{r eval=FALSE, include=FALSE}
n_uk_lineages %>% 
  filter(lineage == "B.1.177" | str_detect(lineage, "^B\\.1\\.177\\.")) %>% 
  select(-lineage) %>% 
  summarise_all(funs(sum))
```
#### B.1.141
```{r eval=FALSE, include=FALSE}
n_uk_lineages %>% filter(lineage == "B.1.141" | str_detect(lineage, "^B\\.1\\.141\\.")) %>% select(-lineage) %>% summarise_all(funs(sum))
```
#### B.1.258

```{r eval=FALSE, include=FALSE}
n_uk_lineages %>% filter(lineage == "B.1.258" | str_detect(lineage, "^B\\.1\\.258\\.")) %>% select(-lineage) %>% summarise_all(funs(sum))
```
#### B.1.1
```{r eval=FALSE, include=FALSE}
n_uk_lineages %>% filter(lineage == "B.1.1" | str_detect(lineage, "B\\.1\\.1\\.")) %>% select(-lineage) %>% summarise_all(funs(sum))
```

#### B.1.1.7
```{r eval=FALSE, include=FALSE}
n_uk_lineages %>% filter(lineage == "B.1.1.7" | str_detect(lineage, "B\\.1\\.1\\.7\\.")) %>% select(-lineage) %>% summarise_all(funs(sum))
```


#### B.1.1.70
```{r eval=FALSE, include=FALSE}
n_uk_lineages %>% filter(lineage == "B.1.1.70" | str_detect(lineage, "B\\.1\\.1\\.70\\.")) %>% select(-lineage) %>% summarise_all(funs(sum))

```

#### B.1.351
```{r eval=FALSE, include=FALSE}
n_uk_lineages %>% filter(lineage == "B.1.351" | str_detect(lineage, "B\\.1\\.351\\.")) %>% select(-lineage) %>% summarise_all(funs(sum))
```

#### B.1.1.298
```{r eval=FALSE, include=FALSE}
n_uk_lineages %>% filter(lineage == "B.1.1.298" | str_detect(lineage, "B\\.1\\.1\\.298\\.")) %>% select(-lineage) %>% summarise_all(funs(sum))
```
#### E484K
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  dplyr::count(lineage)
```
#### E484K 28 Days
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(sample_date >= sample_date_28) %>% 
  dplyr::count(lineage)
```
#### E484K / B.1.351 Summary
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(lineage == "B.1.351" | str_detect(lineage, "B\\.1\\.1\\.351\\.")) %>% 
  summarise("n_E484K_B.1.351" = n_distinct(sequence_name))
```
#### E484K / B.1.351 Summary 28 Days
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(lineage == "B.1.351" | str_detect(lineage, "B\\.1\\.1\\.351\\.")) %>% 
  filter(sample_date >= sample_date_28) %>% 
  summarise("n_28_E484K_B.1.351 " = n_distinct(sequence_name))
```
#### E484K / B.1.1.248
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(lineage == "B.1.1.248" | str_detect(lineage, "B\\.1\\.1\\.248\\.")) %>% summarise("n_E484K_B.1.1.248" = n_distinct(sequence_name))

```
#### E484K / B.1.1.248 28 Days
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(lineage == "B.1.1.248" | str_detect(lineage, "B\\.1\\.1\\.248\\.")) %>% 
  filter(sample_date >= sample_date_28) %>% 
  summarise("n_E484K_B.1.1.248" = n_distinct(sequence_name))
```

#### E484K / B.1.1.7
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(lineage == "B.1.1.7" | str_detect(lineage, "B\\.1\\.1\\.7\\.")) %>% summarise("n_E484K_B.1.1.7" = n_distinct(sequence_name))
```
#### E484K / B.1.1.7 28 Days
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(lineage == "B.1.1.7" | str_detect(lineage, "B\\.1\\.1\\.7\\.")) %>% 
  filter(sample_date >= sample_date_28) %>% 
  summarise("n_E484K_B.1.1.7" = n_distinct(sequence_name))
```

#### E484K / B.1.1
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(lineage == "B.1.1" | str_detect(lineage, "B\\.1\\.1\\.")) %>% summarise("n_E484K_B.1.1" = n_distinct(sequence_name))
```
#### E484K / B.1.1 28 Days
```{r eval=FALSE, include=FALSE}
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(sample_date >= sample_date_28) %>% 
  filter(lineage == "B.1.1" | str_detect(lineage, "B\\.1\\.1\\.")) %>% summarise("n_E484K__28_B.1.1" = n_distinct(sequence_name))
```
#### N501Y + E484K / B.1.351 Summary
```{r eval=FALSE, include=FALSE}
intersect(
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(lineage == "B.1.351" | str_detect(lineage, "B\\.1\\.1\\.351\\.")) %>% 
  distinct(sequence_name),
  
consortium_uk %>% 
  filter(n501y == "Y") %>% 
  filter(lineage == "B.1.351" | str_detect(lineage, "B\\.1\\.1\\.351\\.")) %>% 
  distinct(sequence_name)
)
```

#### E484K + N501Y / B.1.351
```{r eval=FALSE, include=FALSE}
intersect(
mutations_s_uk %>% 
  filter(variant == "E484K") %>% 
  filter(lineage == "B.1.351" | str_detect(lineage, "B\\.1\\.1\\.351\\.")) %>% 
  filter(sample_date >= sample_date_28) %>% 
  distinct(sequence_name),
  
consortium_uk %>% 
  filter(n501y == "Y") %>% 
  filter(lineage == "B.1.351" | str_detect(lineage, "B\\.1\\.1\\.351\\.")) %>% 
  filter(sample_date >= sample_date_28) %>% 
  distinct(sequence_name)
)
```
### Escape Mutations
```{r escape, eval=FALSE, include=FALSE}
escape <- 
  read_csv("list_escape_2.csv", col_names = "mutation")

database_genome %>% 
  right_join(escape) %>% 
  select(mutation, `numSeqs UK`:`numSeqs Wales 28 days`) %T>% 
  write_csv("escape_counts.csv")
```

### Escape mutations sample names
```{r escape_ids, eval=FALSE, include=FALSE}
escape_t4 <- 
c(
"G446V",
"L452R",
"E484Q",
"K444R",
"E484K",
"Y508H",
"N440K",
"L455F",
"A831V",
"A475V",
"F490S",
"V483A",
"R346K",
"K378N",
"K444N",
'G446S',
"N450D",
"K150R",
"R346S",
"K150T",
"V445A",
"G446A",
"Y449H",
"E484A",
"Y453F", "N439K"
)  

lapply(escape_t4,  function(x){
    mutations_s_uk %>% 
        filter(variant == x) %>% 
        distinct(sequence_name) %T>% {{.} %$% 
        write_lines(sequence_name, paste0(x, ".txt"))}
})
```
## Antigenic
### Antigenic mutations by lineage
Would you be able to prepare a file with all the antigenic mutations (filtered from Will’s antigenic table) that have accumulated on the top of B.1.1.7 (so non lineage defining mutations) with numbers of sequences per week? We would like to prepare a heat map like the attached picture.

```{r antigenic_mutations, eval=FALSE, include=FALSE}
antigenic <- 
  antigenic_mutations_lineages() %T>% 
  write_rds(str_c("COG-UK/", params$dataset_date, "/antigenic_mutations_lineages.rds"))

antigenic
```
### Antigenic heatmap
```{r antigenic_heatmap, eval=FALSE, include=FALSE}
suppressPackageStartupMessages(library(ComplexHeatmap))
suppressPackageStartupMessages(library(circlize))

# horz_heat_original <- read.table("horz_heat.csv", row.names = 1, header = TRUE, sep = ",", stringsAsFactors = FALSE)

horz_heat <-
  antigenic_mutations_lineages() %>% 
  filter(lineage == "B.1.1.7" & variant != "N501Y") %>% 
  select(-lineage) %>% 
  inner_join(database_genome %>% 
               select(position, mutation, mab, plasma, vaccine_sera, support, domain) %>% 
               add_row(position = 243, mutation = "del243-244", mab = TRUE, plasma = NA, vaccine_sera = NA, support = "lower", domain = "NTD"), 
             by = c("variant" = "mutation")) %>%   
  mutate(across(where(is.logical), ~na_if(.x, FALSE))) %>%
  arrange(position, variant) %>% 
  mutate(across(domain, as_factor)) %>% 
  select(-position) %>% 
  rename(confidence = support) %>% 
  column_to_rownames("variant")

input <- data.matrix(horz_heat)

# define colour heatmap for frequency
col_fun = colorRamp2(c( 0, 0.015, 0.5, 2), c("white", "darkolivegreen1","darkolivegreen3","forestgreen"))

# annotation row
row_ha = rowAnnotation(
  Effect_mab = horz_heat$mab,
  Effect_plasma = horz_heat$plasma,
  Effect_vaccine = horz_heat$vaccine_sera,
  confidence = horz_heat$confidence,
  na_col = 'white',
  col = list(
    confidence = c(
      "lower" = "lightgoldenrod",
      "medium" = "lightgoldenrod3",
      "high" = "lightgoldenrod4"
    ),
    Effect_mab = c("TRUE" = "black"),
    Effect_plasma = c("TRUE" = "black"),
    Effect_vaccine = c("TRUE" = "black")
  ),
  annotation_legend_param = list(confidence = list (at = c(
    "high", "medium", "lower"
  )))
)

# domain
row_ha2 = rowAnnotation(domain = (horz_heat$domain),
                        col = list(
                          domain = c(
                            "FP" = "seashell2",
                            "NTD" = "navajowhite",
                            "RBD" = "pink",
                            "RBM" = "plum1",
                            "SP" = "lightblue1"
                          )
                        ))

# remove x from name of columns (epiweek)
# colnames(horz_heat) <- gsub("X","",colnames(horz_heat))

# pdf("heatmap.pdf", height = 10)
png("heatmap.png", height = 800, type = "cairo-png")
hm <- Heatmap(
  subset(input, select = -c(mab:domain)),
  name = "Percentage %",
  column_title = "Antigenic mutations in lineage B.1.1.7",
  use_raster = TRUE,
  cluster_columns = FALSE,
  cluster_rows = FALSE,
  row_order = order((horz_heat$domain)),
  row_split = (horz_heat$domain),
  column_names_rot = 0,
  row_gap = unit(2, "mm"),
  border = TRUE,
  width = ncol(input) * unit(1.8, "mm"),
  height = nrow(input) * unit(1.8, "mm"),
  col = col_fun,
  na_col = 'white',
  column_names_gp = grid::gpar(fontsize = 4),
  row_names_gp = grid::gpar(fontsize = 4),
  right_annotation = row_ha,
  left_annotation = row_ha2
)
hm
dev.off()
hm

# RBD1_class<-c(403, 405, 406, 408, 409, 414, 415, 416, 417, 420, 421, 449, 453, 455, 456, 457, 458, 459, 460, 473, 474, 475, 476, 477, 484, 486, 487, 489, 490, 492, 493, 494, 495, 496, 498, 500, 501, 502, 503, 504, 505)
# RBD2_class<-c(338, 339, 342, 343, 346, 351, 368, 371, 372, 373, 374, 403, 405, 406, 417, 436, 444, 445, 446, 447, 448, 449, 450, 452, 453, 455, 456, 470, 472, 473, 475, 478, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505)
# RBD3_class<-c(333, 334, 335, 337, 339, 340, 341, 342, 343, 344, 345, 346, 354, 356, 357, 358, 359, 360, 361, 438, 439, 440, 441, 442, 443, 446, 499, 500)
# RBD4_class<-c(369, 370, 371, 372, 374, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 390, 430, 431)
# NTD_class<-c(15, 18, 19, 22, 28, 74, 77, 80, 123, 136, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 157, 158, 164, 244, 246, 247, 248, 249, 250, 251, 252, 253, 255, 257, 258)

# horz_heat$RBD1 <- ifelse(horz_heat$position %in% RBD1_class, TRUE, NA)
# horz_heat$RBD2 <- ifelse(horz_heat$position %in% RBD2_class, TRUE, NA)
# horz_heat$RBD3 <- ifelse(horz_heat$position %in% RBD3_class, TRUE, NA)
# horz_heat$RBD4 <- ifelse(horz_heat$position %in% RBD4_class, TRUE, NA)
# horz_heat$NTD.1 <- ifelse(horz_heat$position %in% NTD_class, TRUE, NA)

# col_fun = colorRamp2(c( 0, 0.015, 0.5, 2), c("white", "darkolivegreen1","darkolivegreen3","forestgreen"))
# 
# row_ha= rowAnnotation(Effect_mab = horz_heat[,20], Effect_plasma = horz_heat [,21], Effect_vaccine= horz_heat [,22], confidence = horz_heat[,23],
#                         na_col = 'white', col= list(
#                         confidence = c("lower" = "lightgoldenrod", "medium" = "lightgoldenrod3", "high" = "lightgoldenrod4"),
#                         Effect_mab = c("TRUE" = "black"),
#                         Effect_plasma = c("TRUE" ="black"),
#                         Effect_vaccine = c("TRUE" = "black")),
#                       annotation_legend_param = list(confidence = list (at = c("high", "medium", "lower")))
#                       )
#                       
# row_ha2=rowAnnotation(domain = (horz_heat[,24]), Ab_class1 = (horz_heat[,30]),Ab_class2 = (horz_heat[,31]),Ab_class3 = (horz_heat[,32]),Ab_class4 = (horz_heat[,33]),Ab_classe5 = (horz_heat[,34]),
#                       na_col = 'white',
#                       width = ncol(horz_heat)*unit(0.8, "mm"),
#                       col=list(
#                       domain = c("FP" ="seashell2", "NTD"= "navajowhite", "RBD" = "pink", "RBM" = "plum1","SP"= "lightblue1"),
#                       Ab_class1 =c ("TRUE" = "lightgreen"),
#                       Ab_class2 =c("TRUE" = "goldenrod1"),
#                       Ab_class3 =c("TRUE" = "cornflowerblue"),
#                       Ab_class4 =c("TRUE" = "tomato"),
#                       Ab_class5 =c("TRUE" = "magenta")),
#                       show_legend = c(domain = FALSE, Ab_class1 = FALSE,Ab_class2 = FALSE,Ab_class3 = FALSE,Ab_class4 = FALSE,Ab_class5 = FALSE)
#                       )
#                       
# colnames(input)<-gsub("X","",colnames(input))
# 
# Heatmap(input[,2:18], name = "Percentage %", column_title = "Antigenic mutations on the top of B.1.1.7", use_raster = TRUE,cluster_columns = FALSE,
#         row_order = order((horz_heat[,24])),
#         row_split = (horz_heat[,24]),
#         column_names_rot=0,
#         row_gap = unit(2, "mm"),  border = TRUE,
#         width = ncol(input)*unit(1.8, "mm"),
#                height = nrow(input)*unit(1.8, "mm"),
#         col=col_fun,
#         na_col = 'white' ,
#               column_names_gp = grid::gpar(fontsize = 4),
#         row_names_gp = grid::gpar(fontsize = 4),
#         right_annotation = row_ha,
#         left_annotation = row_ha2
#         )

```
### ggseqlogo
```{r ggseqlogo}
wt <-
  mutation_reference_counts %>% 
  filter(gene == "S" & variant == "WT" & adm1 == "UK") %>%
  group_by(position) %>% 
  summarise(`numSeqs UK` = sum(n)) %>% 
  mutate(position = fct_drop(position) %>% fct_expand(1:1274 %>% as.character) %>% fct_inseq) %>% 
  complete(position) %>% 
  mutate(across(`numSeqs UK`, ~replace_na(.x, n_distinct(consortium_uk$sequence_name))))

library(seqinr) # NB seqinr also has a count function!
spike_sequence <- 
  read.fasta(params$spike_fasta, seqonly = TRUE) %>% 
  str_extract_all(boundary("character")) %>% 
  flatten_chr() %>% 
  c("*") # append stop codon

wt %<>% 
  add_column(AA = spike_sequence) %>% 
  mutate(across(position, as.character)) %>% 
  mutate(across(position, as.integer)) %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/wt.rds"))

wt %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/wt.rds"))
```


### mydata
```{r eval=FALSE, include=FALSE}
# library(tidyverse)
# library(magrittr)

mydata <- read_csv("mydata.csv") 

names <- 
  c("MA0018.2",
    "MA0031.1",
    "MA0139.1",
    "MA0158.1")

df <- names %>% 
    purrr::set_names() %>%
    map(function(i) 
      gather(mydata, "key", "value", starts_with(i)) %$% as.integer(value) %>% array(dim = c(4, length(.)/4))
    ) %>% as.list 

df
```

## VUI and VOC
### VUI and VOC defining mutations
```{r vui_voc}
vui_voc <-
  read_csv(params$vui_voc_csv) %>% 
  filter(non_syn == "aa" & gene == "S" & lineage != "B.1.617") %>% # B.1.617 no longer used - reassigned to clades
  select(-gene, -details_gene, -non_syn) %>% 
  mutate(across(lineage, as_factor)) %>% 
  mutate(across(lineage, ~fct_relevel(.x, sort)))

vui_voc %T>% write_rds(str_c("COG-UK/", "vui_voc.rds"))
```

### VUI and VOC plot
```{r lineages_plot, eval=FALSE, include=TRUE}
lineages_weeks_nations <-
  consortium_uk %>% dplyr::count(lineage, epi_week, adm1)

lineages_weeks_uk <-
  lineages_weeks_nations %>% 
  group_by(lineage, epi_week) %>% 
  summarise(across(n, sum), .groups = "drop") %>% 
  mutate(adm1 = "UK", .after = epi_week) %>% 
  bind_rows(lineages_weeks_nations) %>% 
  arrange(lineage, adm1, epi_week)
    
# lineages_weeks_uk %T>% 
#   write_rds(str_c("COG-UK/", params$dataset_date, "/lineages_weeks_uk.rds"))

lineages_weeks_uk %>%
  filter(adm1 == "UK" & lineage %in% levels(vui_voc$lineage) & lineage != "B.1.1.7") %>%
  ggplot(aes(x=epi_week, y=n, group=lineage, color=lineage)) + 
  geom_line() + 
  geom_point() +
  scale_x_discrete(drop = FALSE) + # include all epi_week factor levels
  theme_classic()

```
### Constellations UpSet plot
```{r upset, eval=FALSE, include=FALSE}
mutations_s_uk_wide <-
  mutations_s_uk %>% 
  filter(lineage %in% levels(vui_voc$lineage)) %>% 
  filter(lineage %in% c("B.1.1.7", "B.1.351", "P.1")) %>% 
  mutate(logical_true = TRUE) %>% 
  pivot_wider(names_from = variant, values_from = logical_true, id_cols = c(sequence_name, variant), values_fill = FALSE)

mutations_s_uk_wide
```
### VUI/VOC/other
```{r vui_voc_other}
# sequences with B.617.2.x, AY.4.x and AY.4.2.x converted to parent lineage (N.B. contains duplicate sequences for Delta!)
consortium_uk_delta_parent <-
  bind_rows(
    # convert AY.x sublineages  to parent B.1.617.2
    consortium_uk %>%
      mutate(lineage = gsub("AY\\..*", "B.1.617.2", lineage)), 
  
    # filter AY.4 and sublineages then convert AY.4.x sublineages to parent AY.4 
    consortium_uk %>% 
      filter(lineage == "AY.4" | str_starts(lineage, fixed("AY.4."))) %>% 
      mutate(lineage = "AY.4"),
  
    # filter AY.4.2 and sublineages then convert any AY.4.2 sublineages to parent AY.4.2
    consortium_uk %>% 
      filter(lineage == "AY.4.2" | str_starts(lineage, fixed("AY.4.2."))) %>% 
      mutate(lineage = "AY.4.2"),
    
    # Delta non-AY.4
    consortium_uk %>% filter(( lineage == "B.1.617.2" | str_starts(lineage_full, fixed("B.1.617.2.")))
                             & lineage != "AY.4" 
                             & !str_starts(lineage, fixed("AY.4."))) %>% 
      mutate(lineage = "Delta_minus_AY.4"),
    
    # Delta non-AY.4.2
    consortium_uk %>% filter(( lineage == "B.1.617.2" | str_starts(lineage_full, fixed("B.1.617.2.")))
                             & lineage != "AY.4.2" 
                             & !str_starts(lineage, fixed("AY.4.2."))) %>% 
      mutate(lineage = "Delta_minus_AY.4.2")
  ) 

# count sequences by day
lineages_days_uk_all <- 
  bind_rows(
    consortium_uk_delta_parent %>% 
      dplyr::count(lineage, sample_date, adm1, name = "n_day"),
    
    consortium_uk_delta_parent %>% 
      dplyr::count(lineage, sample_date, name = "n_day") %>% 
      mutate(adm1 = "UK") %>% 
      mutate(across(adm1, as_factor))
  )

# by week
lineages_weeks_uk_all <- bind_rows(
 consortium_uk_delta_parent %>% 
   dplyr::count(lineage, epi_date, adm1, name = "n_week"),
 
 consortium_uk_delta_parent %>% dplyr::count(lineage, epi_date, name = "n_week") %>% 
   mutate(adm1 = "UK") %>% 
   mutate(across(adm1, as_factor))
)
 
lineages_days_uk_all %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/lineages_days_uk_all.rds"))
lineages_weeks_uk_all %T>% write_rds(str_c("COG-UK/", params$dataset_date, "/lineages_weeks_uk_all.rds"))
```
## GISAID
```{r gisaid, eval=FALSE, include=TRUE}
# GISAID Delta sequences
gisaid <- 
  read_csv("6_seqmuts_ale.txt", 
           col_names = 
              c("sequence_name",
              "gisaid_id",
              "lineage", 
              "sample_date",
              "epi_week",
              "country",
              "region",
              "mutations")
  ) %>% 
  drop_na(sample_date) %>% # exclude sequences with missing sample date
  distinct

epi_levels_gisaid <- 
  min(gisaid$epi_week):max(gisaid$epi_week) %>% as.character

gisaid %<>% 
  mutate(across(c(epi_week), as_factor)) %>%
  mutate(epi_week = fct_expand(epi_week, epi_levels_gisaid) %>% fct_inseq) # expand factor levels to include any missing weeks


# All genes mutations and deletions
mutations_gisaid <-
  gisaid %>% 
  separate_rows(mutations, sep = '\\|') %>% 
  filter(mutations != "") %>% # trailing '|' generates empty string
  separate(mutations, into = c("gene", "variant"), sep = ':') %>% 
  distinct 

# S gene mutations and deletions
mutations_s_all_gisaid <- 
  mutations_gisaid %>% 
  filter(gene == "S") %>% 
  mutate(position = parse_number(variant))

# S gene del243-244
dels_s_gisaid <- 
  mutations_s_all_gisaid %>% 
  filter(str_detect(variant, "del") & (position == 243)) %>% 
  semi_join(mutations_s_all_gisaid %>% # sequences with both del243 and del244
              filter(str_detect(variant, "del") & (position == 244)),
            by = c("sequence_name", "gisaid_id", "lineage", 
                   "sample_date", "epi_week", "country", "region", "gene")) %>% 
  mutate(variant = "del243-244")
  
# defining mutations of delta variant
defining_delta <- 
        vui_voc %>% 
        filter(lineage == "B.1.617.2") %$% 
        mutation

# S gene mutations minus defining plus del243-244
mutations_s_gisaid <- 
  mutations_s_all_gisaid %>% 
  filter(!str_detect(variant, "del")) %>%  # remove deletions
  filter(!(variant %in% defining_delta)) %>% # remove Delta defining mutations
  bind_rows(dels_s_gisaid)  # bind del243-244

mutations_s_gisaid
#   mutate(across(c(gene, position, variant), as_factor)) %T>% 

```
### GISAID antigenic
```{r eval=FALSE, include=TRUE}

sequences_by_week_gisaid <- 
    gisaid %>% 
    dplyr::count(epi_week, name = "n_sequences_lineage")

# S gene escape mutations
escape_mutations <-
  database_genome %>%
  filter(!is.na(escape)) %$% 
  mutation 
  
antigenic_mutations_gisaid <- 
    mutations_s_gisaid %>% 
    filter(variant %in% escape_mutations | variant == "del243-244") %>% 
    dplyr::count(variant, epi_week, sort = TRUE) 

antigenic_mutations_gisaid_all <- 
  inner_join(antigenic_mutations_gisaid, sequences_by_week_gisaid) %>% 
  mutate(percentage = n / n_sequences_lineage * 100 ) %>% 
   complete(epi_week, nesting(variant), fill = list(n = 0, n_sequences_lineage = 0, percentage = 0)) %>%
    mutate(epi_week = epi_week %>% as.character %>% as.integer)

first_occurrence_gisaid <- 
    antigenic_mutations_gisaid_all %>% 
    filter(n > 0) %$% 
    min(epi_week)

antigenic_mutations_gisaid_all %<>%
  filter(epi_week >= first_occurrence_gisaid) %>%
  inner_join(epi_lookup) %>% 
  pivot_wider(names_from = epi_date, values_from = percentage, names_sort = TRUE, values_fill = 0, id_cols = variant) 

png("gisaid_delta.png",width=750, height=1300, units="px", type = "cairo-png")
antibody_complex_heatmap(antigenic_mutations_gisaid_all)
dev.off()

antigenic_mutations_gisaid_all
```
## Geo
```{r geo, eval=FALSE, include=TRUE}
# TOPOJSON objectid
# 1 North East (England)
# 2 "North West (England)"
# 3 Yorkshire and The Humber
# 
# 4 East Midlands (England)
# 5 West Midlands (England)
# 6 East of England
# 
# 7 London
# 8 South East (England)
# 9 South West (England)
# 
# 10 Wales
# 11 Scotland
# 12 Northern Ireland
# 

NUTS1 <- c(
"North_East",               
"North_West",     
"Yorkshire_And_The_Humber",

"East_Midlands"            ,
"West_Midlands"            ,
"East_Of_England"          ,

"Greater_London"           ,
"South_East"               ,
"South_West"               ,

"Wales"        ,
"Scotland"      ,           
"Northern_Ireland"         
) 

NUTS1_objectid <- tibble(NUTS1, objectid = 1:length(NUTS1))

# regional counts for all variants with NUTS1 data
geo <- 
  consortium_uk %>% 
  filter(!is.na(NUTS1)) %>% 
  count(epi_week, NUTS1, .drop = FALSE) 

geo_variants <- 
  consortium_uk %>%
  filter(!is.na(NUTS1)) %>% 
  mutate(across(lineage, as_factor)) %>%
  mutate(lineage = fct_other(lineage, keep = vui_voc %$% levels(lineage))) %>% 
  dplyr::count(epi_week, NUTS1, lineage, name = "n_week", .drop = FALSE) 

geo_all <- 
  inner_join(geo, geo_variants) %>%
  mutate(across(epi_week, as.character)) %>% 
  mutate(across(epi_week, as.integer)) %>% 
  # filter(epi_week >= 39 & epi_week <= 80) %>% # first week VUIs and VOCs appear
  filter(epi_week >= 39) %>% # first week VUIs and VOCs appear
  mutate(Proportion = ifelse(n==0, 0, n_week / n)) %>%  # keep zero counts for rendering 
  select(-n) %>%
  inner_join(NUTS1_objectid) %>% 
  rename(Count = n_week) %T>%
  write_csv("nuts1.csv")

geo
geo_variants
geo_all
```
## ISARIC
### Alias
```{r isaric_alias, eval=FALSE, include=FALSE}
library(jsonlite)
alias_key <- fromJSON("https://raw.githubusercontent.com/cov-lineages/pango-designation/master/pango_designation/alias_key.json")

alias_key %<>% 
  keep(~ length(.x) == 1) %>% # drop recombinants
  purrr::discard(~ .x == "") # drop top level lineages

# TODO mutate full lineage in initial consortium read instead
consortium_full <- 
  consortium_uk %>% 
  mutate(lineage_full = lineage, .after = lineage)

mutations_full <- 
  mutations_uk %>% 
  mutate(lineage_full = lineage, .after = lineage)

for (i in 1:length(alias_key)) {
  consortium_full <<- 
    consortium_full %>% 
    mutate(lineage_full = str_replace(lineage_full, str_c("^", names(alias_key)[i], "(?=\\.)"), str_c(alias_key[[i]])))
  
  mutations_full <<- 
    mutations_full %>% 
    mutate(lineage_full = str_replace(lineage_full, str_c("^", names(alias_key)[i], "(?=\\.)"), str_c(alias_key[[i]])))
}
```
### Filter
```{r isaric}
# source("COG-UK/out_frame_del.R")
# source("COG-UK/wuhan_ref_aa.R")

message("Reading ISARIC list file ", params$isaric_csv)
isaric_list <- read_csv(params$isaric_csv)

# iterate through isaric_list row by row
isaric_dfr <-
  isaric_list %>%
  pmap_dfr(function(...) {
    current <- tibble(...) # current row of isaric_list
    
    output <- tibble()
    
    if (is.na(current$Mutation)) { # if no mutations then search consortium 
      if (!is.na(current$Lineage)) {
        
        # filter by lineage and wildcard
        if (str_ends(current$Lineage, fixed("*"))) { # filter sublineages if wildcard
          lineage_prefix <- str_sub(current$Lineage, 1, nchar(current$Lineage) - 1)
          
          output <-
            consortium_uk %>%
            filter(if_any(c(lineage, lineage_full), ~ str_starts(.x, fixed(lineage_prefix)))) %>%   # use fixed because dot is regex special character
            select(sequence_name, cog_id, sample_date, lineage, lineage_full)
          
        } else { # no wildcard - filter exact lineage
          output <-
            consortium_uk %>%
            filter(lineage_full == current$Lineage |
                     lineage == current$Lineage) %>% 
            select(sequence_name, cog_id, sample_date, lineage, lineage_full)
        }
        
        if(!is.na(current$Lineage_filter_out)){
          filters <- str_split(current$Lineage_filter_out, fixed("|"))
          # TODO (no examples at present)
        }
      } 
    } else { # filter deletion/insertion/mutation
     gene_mutation <- str_split(current$Mutation, ":") %>% unlist # split gene:mutation

      if(str_starts(gene_mutation[2], "del|ins")){ # deletion or insertion - look up consortium
        output <- consortium_uk
      } else{ # mutation
        output <- mutations_uk
      }

      # filter by lineage
      if(!is.na(current$Lineage)){
        if (str_ends(current$Lineage, fixed("*"))) { # filter sublineages if wildcard
          lineage_prefix <- str_sub(current$Lineage, 1, nchar(current$Lineage) - 1)

          output %<>%
            filter(if_any(c(lineage, lineage_full), ~ str_starts(.x, fixed(lineage_prefix))))
        } else { # no wildcard - filter exact lineage
          output %<>%
            filter(lineage == current$Lineage)
        }
      }

      # filter out lineage
      if(!is.na(current$Lineage_filter_out)){
        excludes <- 
          current$Lineage_filter_out %>% 
          str_split(fixed("|")) %>% 
          unlist
        
        walk(excludes, function(x){
          if(str_ends(x, fixed("*"))){ # if wildcard
            lineage_prefix <- str_sub(x, 1, nchar(x) - 1)

            output <<-
              output %>%
              filter(if_all(c(lineage, lineage_full), ~ !str_starts(.x, fixed(lineage_prefix))))

          } else { # else exact lineage
            output <<-
              output %>%
              filter(if_all(c(lineage, lineage_full), ~ .x != x))
          }
        })
        
      }

      if(str_starts(gene_mutation[2], "del")){ # deletion - look up consortium 
        #TODO calculate genome coordinates from aa positions
        #TODO in frame only?
        #TODO gene name
        
        dels <-
          deletions %>% 
          filter(between(ref_start, 22283, 22294)) %>% 
          mutate(gene = "S", variant = str_c("del_", ref_start, "_", length)) %>% 
          select(-ref_start, -length)

        # del_22289_6 is del243-244
        # S:del241-243 is del_22283_9
        # S:del242-244 is del_22286_9
        # 22283, 22286, 22289 and 22292 ( to 22294 ?)
        
        output %<>% 
          select(sequence_name, cog_id, sample_date, lineage, lineage_full) %>% 
          inner_join(dels, by = c("sequence_name" = "samples"))
      } else if(gene_mutation[1] == "S" & str_starts(gene_mutation[2], "ins")){ # insertion - look up consortium
        # Spike genomic coordinates 21563..25384 
        # TODO in frame only
        
        ins_samples <- 
          insertions %>% 
          # filter(str_length(insertion) %% 3 == 0) %>% 
          filter(ref_start >= 21563 & ref_start < 25384) %>%  # Spike coordinates 21563 to 25384 
          filter(!str_detect(insertion, "N")) %>% # exclude any insertions with uncalled nucleotides
          mutate(gene = "S", variant = str_c("ins_", ref_start, "_", insertion), .keep = "unused") 

        output %<>% 
          select(sequence_name, cog_id, sample_date, lineage, lineage_full) %>% 
          inner_join(ins_samples, by = c("sequence_name" = "samples"))
      } else { # mutation - look up mutations
          
          if(str_ends(gene_mutation[2], "X")){ # mutation wildcard
            output %<>% filter(gene == gene_mutation[1] & position == parse_number(gene_mutation[2]))
          } else { # exact match of mutation
            output %<>% filter(gene == gene_mutation[1] & variant == gene_mutation[2])
          }

        output %<>% select(sequence_name, cog_id, sample_date, lineage, lineage_full, gene, variant)
     }

    }
    
    output %>% mutate(query_id = current$ID)
  })# %>% distinct

isaric_dfr
```
### Compare
```{r isaric_compare}
# list isaric TSV files
isaric_files <- list.files(pattern = "isaric_.*_cumulative\\.tsv") 
  
# extract dates from filenames  
isaric_dates <-
  isaric_files %>% 
  str_extract("\\d{4}-\\d{2}-\\d{2}") %>% 
  parse_date

# get most recent date
isaric_previous <- isaric_dates[isaric_dates < params$dataset_date]
isaric_latest <- NULL
if(length(isaric_previous > 0)){ # previous datasets exist
  message("Reading most recent ISARIC cumulative file")
  isaric_recent <- 
    isaric_previous %>% 
    max %>% 
    grep(isaric_files) %>% 
    isaric_files[.] %>% 
    print %>%
    read_tsv() %>% 
    separate_rows(query_id, sep = ",") %>% 
    mutate(query_id = as.numeric(query_id)) 
  
  isaric_latest <- 
    anti_join(isaric_dfr, isaric_recent, by = c("cog_id", "query_id"))
}

isaric_latest
```

### Collapse
```{r isaric_collapse}
collapse_isaric <- function(isaric_hits){
  isaric_hits %>% 
  mutate(gene_variant = str_c(gene, ":", variant), .keep = "unused") %>% 
  group_by(cog_id, sample_date, lineage) %>% 
  summarise(mutations = toString(str_c(gene_variant)), query_id = toString(query_id), .groups = "drop") %>% 
  arrange(desc(sample_date), lineage, cog_id)
}

if(!is.null(isaric_latest)){
  isaric_latest_collapse <- 
    isaric_latest %>% 
    collapse_isaric %T>% 
    write_tsv(str_c("isaric_", params$dataset_date, "_latest.tsv") %T>% message("Writing ", .))
  
  isaric_latest_collapse
}

isaric_dfr_collapse <- 
  isaric_dfr %>% 
  collapse_isaric %T>% 
  write_tsv(str_c("isaric_", params$dataset_date, "_cumulative.tsv") %T>% message("Writing ", .))

isaric_dfr_collapse
```
## Ronapreve plot
```{r ronopreve_plot}
source("mab_upset_regeneron.R")
ronapreve_upset <- generate_upset()
ronapreve_upset_28 <- generate_upset(filter_date = sample_date_28)

png(filename=str_c("COG-UK/", params$dataset_date, "/Ronapreve.png"), width=1200, height=650, type = "cairo-png")
ronapreve_upset
dev.off()

png(filename = str_c("COG-UK/", params$dataset_date, "/Ronapreve_28.png"), width=1200, height=650, type = "cairo-png")
ronapreve_upset_28
dev.off()

# ronapreve_upset
# ronapreve_upset_28

```

## Done
```{r success}
message("PIPELINE COMPLETED")
```